% Encoding: UTF-8

%%%%% Books %%%%%

@Book{Pell14e,
  author    = {Pellegrini, Alessandro},
  publisher = {Sapienza Università Editrice},
  title     = {Parallelization of Discrete Event Simulation Models},
  year      = {2015},
  isbn      = {978-88-98533-59-6},
  month     = nov,
  series    = {Studi e Ricerche},
  abstract  = {Simulation is a powerful technique to represent the evolution of real-world phenomena or systems over time. It has been extensively used in different research fields (from medicine to biology, from economy, to disaster rescue) to study the behaviour of complex systems during their evolution (symbiotic simulation) or before their actual realization (what-if analysis).
A traditional way to achieve high performance simulations is the employment of Parallel Discrete Event Simulation (PDES) techniques, which are based on the partitioning of the simulation model into Logical Processes (LPs) that can execute events in parallel on different CPUs and/or different CPU cores, and rely on synchronization mechanisms to achieve causally consistent execution of simulation events. As it is well recognized, the optimistic synchronization approach, namely the Time Warp protocol, which is based on rollback for recovering possible timestamp-order violations due to the absence of block-until-safe policies for event processing, is likely to favour speedup in general application/architectural contexts.
However, the optimistic PDES paradigm implicitly relies on a programming model that drifts from traditional sequential-style programming, given that there is no notion of global address space (fully accessible while processing events at any LP). Furthermore, there is the underlying assumption that the code associated with event handlers cannot execute unrecoverable operations given their speculative processing nature. Nevertheless, even though no unrecoverable action is ever executed by event handlers, some means to actually undo the action upon request needs to be devised and implemented within the software stack.
On the other hand, sequential-style programming is a very easy paradigm for the development of simulation code, given that it does not require the programmer to reason about memory partitioning (and therefore message passing) and speculative (concurrent) processing of the application.
In this thesis, we present methodological and technical innovations which will show how it is possible, by developing innovative runtime mechanisms, to allow a programmer to implement his simulation model in a fully sequential way, and have the underlying simulation framework to execute it in parallel according to speculative processing techniques. Some of the approaches we provide show applicability in either shared- or distributed-memory systems, while others will be specifically tailored to multi/many-core architectures.
We will clearly show, during the development of these supports, what is the effect on performance of these solutions, which will nevertheless be negligible, allowing a fruitful exploitation of the available computing power. In the end, we will highlight which are the clear benefits on the programming model that the developer will experience by relying on these innovative solutions.},
}


%%%%% Books Chapters %%%%%

@InCollection{Rug15,
  author    = {Rughetti, Diego and Di Sanzo, Pierangelo and Pellegrini, Alessandro and Ciciani, Bruno and Quaglia, Francesco},
  booktitle = {Transactional Memory. Foundations, Algorithms, Tools, and Applications},
  publisher = {Springer International Publishing},
  title     = {Tuning the Level of Concurrency in Software Transactional Memory: An Overview of Recent Analytical, Machine Learning and Mixed Approaches},
  year      = {2015},
  editor    = {Guerraoui, Rachid and Romano, Paolo},
  isbn      = {978-3-319-14719-2},
  pages     = {395--417},
  series    = {Lecture Notes in Computer Science},
  volume    = {8913},
  abstract  = {Synchronization transparency offered by Software Transactional Memory (STM) must not come at the expense of run-time efficiency, thus demanding from the STM-designer the inclusion of mechanisms properly oriented to performance and other quality indexes. Particularly, one core issue to cope with in STM is related to exploiting parallelism while also avoiding thrashing phenomena due to excessive transaction rollbacks, caused by excessively high levels of contention on logical resources, namely concurrently accessed data portions. A means to address run-time efficiency consists in dynamically determining the best-suited level of concurrency (number of threads) to be employed for running the application (or specific application phases) on top of the STM layer. For too low levels of concurrency, parallelism can be hampered. Conversely, over-dimensioning the concurrency level may give rise to the aforementioned thrashing phenomena caused by excessive data contention—an aspect which has reflections also on the side of reduced energy-efficiency. In this chapter we overview a set of recent techniques aimed at building “application-specific” performance models that can be exploited to dynamically tune the level of concurrency to the best-suited value. Although they share some base concepts while modeling the system performance vs the degree of concurrency, these techniques rely on disparate methods, such as machine learning or analytic methods (or combinations of the two), and achieve different tradeoffs in terms of the relation between the precision of the performance model and the latency for model instantiation. Implications of the different tradeoffs in real-life scenarios are also discussed.},
  doi       = {10.1007/978-3-319-14720-8_18},
}

@InCollection{Qua14,
  author    = {Quaglia, Francesco and Pellegrini, Alessandro and Vitali, Roberto},
  booktitle = {Modeling and Simulation-based Systems Engineering Handbook},
  publisher = {Crc Pr I Llc},
  title     = {Reshuffling {PDES} Platforms for Multi/Many-core Machines: a Perspective with focus on Load Sharing},
  year      = {2014},
  editor    = {Gianni, Daniele and D'Ambrogio, Andrea and Tolk, Andreas},
  isbn      = {978-1-4665-7145-7},
  month     = dec,
  pages     = {203--232},
  abstract  = {In this chapter, we discuss some key aspects related to the reorganization process of these platforms and present in detail a recent literature approach exactly tackling this issue. The presentation is also targeted at showing how the approach, which is based on the symmetric multithreading software programming paradigm, can be suited for a change in the perspective on how to exploit computing resources for PDES applications in a balanced and effective manner. This is achieved via an innovative load-sharing paradigm suited for PDES systems run on top of multicore machines.},
  doi       = {10.1201/b17902-10},
}

%%%%% Journal Articles %%%%%

@article{Mar23b,
  author = {Marotta, Romolo and Ianni, Mauro and Pellegrini, Alessandro and Quaglia, Francesco},
  title = {A Conflict-Resilient Lock-Free Linearizable Calendar Queue},
  journal = {ACM Transactions on Parallel Computing},
  abstract = {In the last two decades, great attention has been devoted to the design of non-blocking and linearizable data structures, which enable exploiting the scaled-up degree of parallelism in off-the-shelf shared-memory multi-core machines. In this context, priority queues are highly challenging. 
Indeed, concurrent attempts to extract the highest-priority item are prone to create detrimental thread conflicts that lead to abort/retry of the operations.
In this article, we present the first priority queue that jointly provides:
i) lock-freedom and linearizability; 
ii) conflict resiliency against concurrent extractions;
iii) adaptiveness to different contention profiles; and
iv) amortized constant-time access for both insertions and extractions. Beyond presenting our solution, we also provide proof of its correctness based on an assertional approach. 
Also, we present an experimental study on a 64-CPU machine, showing that our proposal provides performance improvements over state-of-the-art non-blocking priority queues. },
  year = {2024},
  volume = {11},
  issue = {1},
  month = mar,
  issn = {2329-4949},
  publisher = {ACM},
  series = {TOPC},
  doi    = {10.1145/3635163},
}

@article{Car23,
  author = {Carnà, Stefano and Marotta, Romolo and Pellegrini, Alessandro and Quaglia, Francesco},
  title = {Strategies and Software Support for the Management of Hardware Performance Counters},
  journal = {Software: Practice and Experience},
  abstract = {Hardware Performance Counters (HPCs) are facilities offered by most off-the-shelf CPU architectures. They are a vital support to post-mortem performance profiling and are exploited by standard tools such as Linux or Intel V-Tune. Nevertheless, an increasing number of application domains (e.g., simulation, task-based high-performance computing, or cybersecurity) are exploiting them to perform different activities, such as self-tuning, autonomic optimization, and\slash or system inspection. This repurposing of HPCs can be difficult, e.g., because of the overhead for extracting relevant information. This overhead might render any online or self-tuning activity ineffective. This article discusses various practical strategies to exploit HPCs beyond post-mortem profiling, suitable for different application contexts. The presented strategies are accompanied by a general primer on HPCs usage on Linux. We also provide reference x86 (both Intel and AMD) implementations targeting the Linux kernel, upon which we present an experimental assessment of the viability of our proposals.},
  year = {2023},
  month = jul,
  volume = {53},
  issue = {10},
  pages = {1928--1957},
  issn = {1097-024X},
  doi = {10.1002/spe.3236},
  publisher = {Wiley},
  series = {SPE},
}

@article{DeA23,
  author = {De Angelis, Emanuele and De Angelis, Guglielmo and Pellegrini, Alessandro and Proietti, Maurizio},
  title = {What Makes Test Programs Similar in Microservices Applications?},
  journal = {Journal of Systems and Software},
  abstract = {The emergence of microservice architecture calls for novel methodologies and technological frameworks that support the design, development, and maintenance of applications structured according to this new architectural style. In this paper, we consider the issue of designing suitable strategies for the governance of testing activities within the microservices paradigm. We focus on the problem of discovering implicit relations between test programs that help to avoid re-running all the available test suites each time one of its constituents evolves. We propose a dynamic analysis technique and its supporting framework that collects information about the invocations of local and remote APIs. Information on test program execution is obtained in two ways: instrumenting the test program code or running a symbolic execution engine. The extracted information is processed by a rule-based automated reasoning engine, which infers implicit similarities among test programs. We show that our analysis can be used to support the reduction of test suites. The proposed approach has been validated against two real-world microservice applications.},
  year = {2023},
  month = jan,
  volume = {201},
  pages = {111674},
  issn = {0164-1212},
  publisher = {Elsevier},
  series = {SPE},
  doi = {10.1016/j.jss.2023.111674},
}

@article{Pell22,
  author = {Pellegrini, Alessandro and Di~Sanzo, Pierangelo and Piccione, Andrea and Quaglia, Francesco},
  title = {Design and Implementation of a Fully-Transparent Partial Abort Support for Software Transactional Memory},
  journal = {Software: Practice and Experience},
  abstract = {Software Transactional Memory (STM) provides synchronization support to ensure atomicity and isolation when threads access shared data in concurrent applications. With STM, shared data accesses are encapsulated within transactions, which are automatically handled by the STM layer. Hence, programmers are not requested to use code-synchronization mechanisms explicitly, like locking.
In this article, we present our experience in designing and implementing a partial abort scheme for STM. The objective of our work is threefold: 1) enabling STM to undo only part of the transaction execution in the case of conflict, 2) designing a scheme that is fully transparent to programmers, thus also allowing to run existing STM applications without modifications, and 3) providing a scheme that can be easily integrated within existing STM runtime environments without altering their internal structure. The scheme that we designed is based on automated software instrumentation, which injects into the application capabilities to undo the required portions of transaction executions. Further, it can correctly undo also non-transactional operations executed on the stack and the heap during a transaction. This capability provides programmers with the advantage of writing transactional code without concerns about the side effects of aborted transactions on both shared and thread-private data. We integrated and evaluated our partial abort scheme within the TinySTM open-source library. We analyze the experimental results we achieved with common STM benchmark applications, focusing on the advantages and disadvantages of the proposed solutions for implementing our scheme's different components. Hence, we highlight the appropriate choices and possible solutions to improve partial abort schemes further.},
  year = {2022},
  month = jun,
  volume = {52},
  issue = {11},
  pages = {2456--2475},
  issn = {1097-024X},
  publisher = {Wiley},
  series = {SPE},
  doi = {10.1002/spe.3134},
}

@Article{Car22,
  author    = {Carnà, Stefano and Ferracci, Serena and Quaglia, Francesco and Pellegrini, Alessandro},
  title     = {Fight Hardware with Hardware: System-wide Detection and Mitigation of Side-Channel Attacks using Performance Counters},
  journal   = {Digital Threats: Research and Practice},
  year      = {2022},
  abstract  = {We present a kernel-level infrastructure that allows system-wide detection of malicious applications attempting to exploit cache-based side-channel attacks to break the process confinement enforced by standard operating systems. This infrastructure relies on hardware performance counters to collect information at runtime from all applications running on the machine. High-level detection metrics are derived from these measurements to maximize the likelihood of promptly detecting a malicious application. Our experimental assessment shows that we can catch a large family of side-channel attacks with a significantly reduced overhead in the system. We also discuss countermeasures that can be enacted once a process is suspected of carrying out a side-channel attack to increase the overall tradeoff between the system’s security level and the delivered performance under non-suspected process executions.},
  publisher = {ACM},
  series    = {DTRAP},
  doi       = {10.1145/3519601},
}

@Article{Mar22,
  author    = {Marotta, Romolo and Ianni, Mauro and Pellegrini, Alessandro and Quaglia, Francesco},
  title     = {NBBS: A Non-Blocking Buddy System for Multi-core Machines},
  journal   = {Transactions on Computers},
  year      = {2022},
  mon       = mar,
  abstract  = {Common implementations of core memory allocation components handle concurrent allocation/release requests by synchronizing threads via spin-locks. This approach is not prone to scale, a problem that has been addressed in the literature by introducing layered allocation services or replicating the core allocators—the bottom-most ones within the layered architecture. Both these solutions tend to reduce the pressure of actual concurrent accesses to each individual core allocator. In this article, we explore an alternative approach to scalability of memory allocation/release, which can be still combined with those literature proposals. We present a fully non-blocking buddy system, where threads performing concurrent allocations/releases do not undergo any spin-lock based synchronization. Our solution allows threads to proceed in parallel, and commit their allocations/releases unless a conflict is materialized while handling the allocator metadata—memory fragmentation and coalescing is also carried out in a fully non-blocking manner. Conflict detection relies in our solution on atomic Read-Modify-Write (RMW) machine instructions, guaranteed to execute atomically by the processor firmware. We also provide a proof of the correctness of our non-blocking buddy system and show the results of a comparative study that outlines the advantages of our solution with respect to the Linux-kernel buddy system, which is one of the most diffused and optimized buddy systems in the state of the art.},
  publisher = {IEEE},
  series    = {TC},
  doi       = {10.1109/TC.2021.3060393},
  volume    = 71,
  issue     = 3,
  pages     = {599--612},
}

@Article{Sil21,
  author    = {Silvestri, Emiliano and Pellegrini, Alessandro and Di~Sanzo, Pierangelo and Quaglia, Francesco},
  title     = {Effective Runtime Management of Tasks and Priorities in GNU OpenMP Applications},
  journal   = {Transactions on Computers},
  year      = {2022},
  month     = oct,
  abstract  = {OpenMP has become a reference standard for the design of parallel applications. This standard is evolving very fast, thus offering ever new opportunities to the application programmers. However, OpenMP runtime environments are often not fully aligned to the actual requirements imposed by the evolution of such standard. Among the main lacks, we find: (a) a limited capability to effectively cope with task priorities, and (b) the inadequacy in guaranteeing core properties while processing tasks such as the so called work-conservativeness---the ability of the OpenMP runtime environment to fully exploit the underlying multi-processor/multi-core machine through the avoidance of thread-blocking phases. In this article we present the design of extensions to the GNU OpenMP (GOMP) implementation, integrated into gcc, which allow the effective management of tasks and their priorities. Our proposal is based on a user-space library---modularly combined with the one already offered by GOMP---and an external kernel-level Linux module---offering the opportunity to exploit raising hardware facilities for the purpose of task/priority management. We also provide experimental results showing the effectiveness of our proposal, achieved by running either OpenMP common benchmarks or a new benchmark application (named Hashtag-Text) that we explicitly devised in order to stress the OpenMP runtime environment in relation to the above-mentioned task/priority management aspects.},
  publisher = {IEEE},
  series    = {TC},
  volume    = 71,
  issue     = 10,
  pages     = {2632--2645},
  doi       = {10.1109/TC.2021.3139463},
}

@Article{Gig21,
  author    = {Gigante, Gabriella and Palumbo, Roberto and Pascarella, Domenico and Pellegrini, Alessandro and Duca, Gabriella and Piera, Miquel Àngel and Ramos, Juan José},
  title     = {Support to Design for Air Traffic Management: An Approach with Agent-Based Modelling and Evolutionary Search},
  journal   = {International Journal of Aviation, Aeronautics, and Aerospace},
  year      = {2021},
  volume    = {8},
  number    = {1},
  abstract  = {To enhance Air Traffic Management (ATM) and meet the future traffic demand and environmental requirements, present ATM system is going to be modified (SESAR Joint Undertaking, 2017), designing new services to be integrated in future architecture considering the evolution of present fragmented structure of the airspace and the entanglement of air routes. Such a change process is complicated due to the nature of ATM, which is a large-scale Socio-Technical System (STS), typically involving a complex interaction between humans, machines and the environment. In such kind of systems, managing their evolution is a complex and difficult task since the social and technical implications of any proposed concept should be fully assessed before a choice is made whether or not to proceed with the related development. Often, simulation tools are also used to support the design of the concept itself by enabling what-if-analyses. However, these may be too effort and time consuming due to the exponential growth of the required analysis cases. A quite common mismatch between the performance evaluations in simulated conditions and those achieved in real life is represented by the partial assessment of human aspects that can be performed throughout the new concept lifecycle from its lowest maturity level up to “ready to market”.
The proposed work defines an approach to support the design of new ATM solutions, including the evaluation on human behaviour. The approach adopts a combined paradigm, which involves Agent-Based Modelling and Simulation (ABMS) to specify and analyse the ATM models, and Agent-based Evolutionary Search (AES) to optimize the design of the new solutions. A specific case study is used to demonstrate the effectiveness of the proposed approach. Transition from Direct Routing Airspace (DRA) to Free Routing Airspace (FRA), respectively described by Solution #32 and Solution #33 in the SESAR solutions catalogue (SESAR Joint Undertaking, 2017), is used for both validation and experimentation activities. In detail, the proposed experimentation case regards the design of sector collapsing/decollapsing configuration to optimize controller workloads. The achieved results are presented and discussed.},
  series    = {IJAAA},
  doi       = {10.15394/ijaaa.2021.1561},
}

@Article{Con21,
  author    = {Conoci, Stefano and Di Sanzo, Pierangelo and Pellegrini, Alessandro and Ciciani, Bruno and Quaglia, Francesco},
  title     = {On Power Capping and Performance Optimization of Multi-threaded Applications},
  journal   = {Concurrency and Computation: Practice and Experience},
  year      = {2021},
  month     = jan,
  volume    = {33},
  number    = {11},
  abstract  = {Multi-threaded applications facilitate the exploitation of the computing power of multicore architectures. On the other hand, these applications can become extremely energy-intensive, in contrast with the need for limiting the energy usage of computing systems.
In this article, we explore the design of techniques enabling multi-threaded applications to maximize their performance under a power cap. We consider two control parameters: the number of cores used by the application, and the core power state. We target the design of an auto-tuning power-capping technique with minimal intrusiveness and high portability, which is agnostic about the workload profile of the application. We investigate two different approaches for building the strategy for selecting the best configuration of the parameters under control, namely a heuristic approach and a model-based approach. Through an extensive experimental study, we evaluate the effectiveness of the proposed technique considering two different selection strategies, and we compare them with existing solutions.},
  publisher = {Wiley},
  series    = {CCPE},
  doi       = {10.1002/cpe.6205},
}

@article{DiS21,
  author = {Di Sanzo, Pierangelo and Avresky, Dimiter R. and Pellegrini, Alessandro},
  title = {Autonomic Rejuvenation of Cloud Applications as a Countermeasure to Software Anomalies},
  journal = {Software: Practice and Experience},
  abstract = {Failures in computer systems can be often tracked down to software anomalies of various kinds. In many scenarios, it could be difficult, unfeasible, or unprofitable to carry out extensive debugging activity to spot the causes of anomalies and remove them. In other cases, taking corrective actions may led to undesirable service downtime. In this article, we propose an alternative approach to cope with the problem of software anomalies in cloud-based applications, and we present the design of a distributed autonomic framework that implements our approach. It exploits the elastic capabilities of cloud infrastructures, and relies on machine learning models, proactive rejuvenation techniques and a new load balancing approach. By putting together all these elements, we show that it is possible to improve both availability and performance of applications deployed over heterogeneous cloud regions and subject to frequent failures. Overall, our study demonstrates the viability of our approach, thus opening the way towards it adoption, and encouraging further studies and practical experiences to evaluate and improve it.},
  year = {2021},
  month = jan,
  volume = {51},
  number = {1},
  pages = {46--71},
  issn = {1097-024X},
  publisher = {Wiley},
  series = {SPE},
  doi = {10.1002/spe.2908}
}

@Article{Pell20d,
  author    = {Pellegrini, Alessandro},
  title     = {Replication of Computational Results Report for “Green Simulation with Database Monte Carlo”},
  journal   = {ACM Transactions on Modeling and Computer Simulation},
  year      = {2020},
  issn      = {1049-3301},
  month     = {12},
  volume    = {31},
  number    = {1},
  abstract  = {This article presents the reproducibility results associated with the article ``Green Simulation with Database Monte Carlo'' by Mingbin Feng and
Jeremy Staum. The authors have uploaded their artifact to Zenodo, which ensures a long-term retention of the artifact. The artifact, which is based on a set of R scripts, allows to easily regenerate data for the figures and the tables, it completes successfully, and allows to reproduce all the experimental results in the article.
The article can thus receive the Artifacts Available, the Artifacts Evaluated---Functional, and the Results Reproduced badges.},
  publisher = {ACM},
  series    = {TOMACS},
  doi       = {10.1145/3426823},
}

@article{Pell20c,
  author = {Pellegrini, Alessandro and Di Sanzo, Pierangelo and Bevilacqua, Beatrice and Duca, Gabriella and Pascarella, Domenico and Palumbo, Roberto and Ramos, Juan José and Piera, Miquel Àngel and Gigante, Gabriella},
  title = {Simulation-based Evolutionary Optimization of Air Traffic Management},
  journal = {IEEE Access},
  abstract = {In the context of aerospace engineering, the optimization of processes often may require to solve multi-objective optimization problems, including mixed variables, multi-modal and non-differentiable quantities, possibly involving highly-expensive objective function evaluations. In Air Traffic Management (ATM), the optimization of procedures and protocols becomes even more complicated, due to the involvement of human controllers, which act as final decision points in the control chain.
In this article, we propose the use of computational intelligence techniques, such as Agent-Based Modelling and Simulation (ABMS) and Evolutionary Computing (EC), to design a simulation-based distributed architecture to optimize control plans and procedures in the context of ATM. We rely on Agent-Based fast-time simulations to carry out offline what-if analysis of multiple scenarios, also taking into account human-related decisions, during the strategic or pre-tactical phases. The scenarios are constructed using real-world traffic data traces, while multiple optimization variables governed by an EC algorithm allow to explore the search space to identify the best solutions. Our optimization approach relies on ad-hoc multi-objective performance metrics which allow to assess the goodness of the control of aircraft and air traffic regulations.
We present experimental results which prove the viability of our approach, comparing them with real-world data traces, and proving their meaningfulness from an Air Traffic Control perspective.},
  year = {2020},
  issn = {2169-3536},
  month = sep,
  volume = {8},
  pages = {161551--161570},
  publisher = {IEEE},
  series = {Access},
  doi = {10.1109/ACCESS.2020.3021192}
}

@Article{Mar20,
  author    = {Marotta, Romolo and Tiriticco, Davide and Di Sanzo, Pierangelo and Pellegrini, Alessandro and Ciciani, Bruno and Quaglia, Francesco},
  title     = {Mutable Locks: Combining the Best of Spin and Sleep Locks},
  journal   = {Concurrency and Computation: Practice and Experience},
  year      = {2020},
  volume    = {32},
  number    = {22},
  issn      = {1532-0634},
  month     = {6},
  abstract  = {In this article we present Mutable Locks, a synchronization construct with the same semantic of traditional locks (such as spin locks or sleep locks), but with a self-tuned optimized trade off between responsiveness and CPU-time usage during threads’ wait phases. Mutable locks tackle the need for efficient synchronization supports in the era of multi-core machines, where the run-time performance should be optimized while reducing resource usage. This goal should be achieved with no intervention by the programmers. Our proposal is intended for exploitation in generic concurrent applications, where scarce or no knowledge is available about the underlying software/hardware stack and the workload. This is an adverse scenario for static choices between spinning and sleeping, which is tackled by our mutable locks thanks to their hybrid waiting phase and self-tuning capabilities.},
  publisher = {Wiley},
  series    = {CCPE},
  doi       = {10.1002/CPE.5858}
}

@Article{Pri20,
  author    = {Principe, Matteo and Tocci, Tommaso and Di Sanzo, Pierangelo and Quaglia, Francesco and Pellegrini, Alessandro},
  title     = {A Distributed Shared-Memory Middleware for Speculative Parallel Discrete Event Simulation},
  journal   = {ACM Transactions on Modeling and Computer Simulation},
  year      = {2020},
  volume    = {30},
  number    = {2},
  issn      = {1049-3301},
  pages     = {11:1--11:26},
  month     = feb,
  abstract  = {The large diffusion of multi-core machines has pushed the research in the field of Parallel Discrete Event Simulation (PDES) towards new programming paradigms, based on the exploitation of shared memory. On the opposite side, the advent of Cloud computing—and the possibility to group together many (low-cost) virtual machines to form a distributed-memory cluster capable of hosting simulation applications—has raised the need to bridge shared-memory programming and seamless distributed execution. In this article, we present the design of a distributed middleware that transparently allows a PDES application coded for shared memory systems to run on clusters of (Cloud) resources. Our middleware is based on a synchronization protocol called Event & Cross State (ECS) Synchronization. It allows cross-simulation-object access by event handlers, thus representing a powerful tool for the development of various types of PDES applications. We also provide data for an experimental assessment of our middleware architecture, which has been integrated into the open source ROOT-Sim speculative PDES platform.},
  doi       = {10.1145/3373335},
  publisher = {ACM},
  series    = {TOMACS},
}

@article{Qua20,
  author = {Quaglia, Francesco and Theodoropoulos, Georgios and Pellegrini, Alessandro},
  title = {Editorial to the Special Issue on the Principles of Advanced Discrete Simulation (PADS)},
  journal = {Transactions on Modeling and Computer Simulations},
  year = {2020},
  month = mar,
  number = {5},
  pages = {8:1--8:2},
  volume = {69},
  doi = {10.1145/3381903}
}

@Article{DiS19,
  author    = {Di Sanzo, Pierangelo and Pellegrini, Alessandro and Sannicandro, Marco and Ciciani, Bruno and Quaglia, Francesco},
  title     = {Adaptive Model-based Scheduling in Software Transactional Memory},
  journal   = {IEEE Transactions on Computers},
  year      = {2020},
  volume    = {69},
  number    = {5},
  pages     = {621--632},
  issn      = {0018-9340},
  month     = {5},
  abstract  = {Software Transactional Memory (STM) stands as powerful concurrent programming paradigm, enabling atomicity and isolation while accessing shared data. On the downside, STM may suffer from performance degradation due to excessive conflicts among concurrent transactions, which cause waste of CPU-cycles and energy because of transaction aborts. An approach to cope with this issue consists of putting in place smart scheduling strategies which temporarily suspend the execution of some transaction in order to reduce the transaction conflict rate. In this article, we present an adaptive model-based transaction scheduling technique relying on a Markov Chain-based performance model of STM systems. Our scheduling technique is adaptive in a twofold sense: (i) it controls the execution of transactions depending on throughput predictions by the model as a function of the current system state, (ii) it re-tunes on-line the Markov Chain-based model to adapt it—and the outcoming transaction scheduling decisions—to dynamic variations of the workload. We have been able to achieve the latter target thanks to the fact that our performance model is extremely lightweight. In fact, to be recomputed, it requires a reduced set of input parameters, whose values can be estimated via a few on-line samples related to the current workload dynamics. We also present a scheduler that implements our adaptive technique, which we integrated within the open source TinySTM package. Further, we report the results of an experimental study based on the STAMP benchmark suite, which has been aimed at assessing both the accuracy of our performance model in predicting the actual system throughput and the advantages of the adaptive scheduling policy over literature techniques},
  doi       = {10.1109/TC.2019.2954139},
  publisher = {IEEE},
  series    = {TC},
}

@Article{Pell19,
  author    = {Pellegrini, Alessandro and Quaglia, Francesco},
  title     = {Cross-State Events: a New Approach to Parallel Discrete Event Simulation and its Speculative Runtime Support},
  journal   = {Journal of Parallel and Distributed Computing},
  year      = {2019},
  issn      = {0743-7315},
  month     = {10},
  pages     = {48--68},
  volume    = {132},
  abstract  = {We present a new approach to Parallel Discrete Event Simulation (PDES), where we enable the execution of so-called cross-state events. During their processing, the state of multiple concurrent simulation objects can be accessed in read/write mode, as opposed to classical partitioned accesses. This is done with no pre-declaration of this type of access by the programmer, hence also coping with non-determinism. In our proposal, cross-state events are supported by a speculative runtime environment fully transparently to the application code. This is done through an ad-hoc memory management architecture and an extension of the classical Time Warp synchronization protocol. This extension, named Event and Cross-State (ECS) synchronization, ensures causally-consistent speculative parallel execution of discrete event applications by allowing all events to observe the snapshot of the model execution trajectory that would have been observed in a timestamp-ordered execution of the same model. An experimental assessment of our proposal shows how it can significantly reduce the application development complexity, while also providing advantages in terms of performance},
  doi       = {10.1016/j.jpdc.2019.05.003},
  publisher = {Elsevier},
  series    = {JPDC},
}

@Article{Ian19,
  author    = {Ianni, Mauro and Pellegrini, Alessandro and Quaglia, Francesco},
  title     = {Anonymous Readers Counting: A Wait-free Multi-word Atomic Register Algorithm for Scalable Data Sharing on Multi-core Machines},
  journal   = {IEEE Transactions on Parallel and Distributed Systems},
  year      = {2019},
  issn      = {1045-9219},
  month     = {2},
  pages     = {286--299},
  volume    = {30},
  abstract  = {In this article we present Anonymous Readers Counting (ARC), a multi-word atomic (1,N) register algorithm for multi-core machines. ARC exploits Read-Modify-Write (RMW) instructions to coordinate the writer and reader threads in a wait-free manner and enables large-scale data sharing by admitting up to (2^32 - 2) concurrent readers on off-the-shelf 64-bits machines, as opposed to the most advanced RMW-based approach which is limited to 58 readers on the same kind of machines. Further, ARC avoids multiple copies of the register content when accessing it—this is a problem that affects classical register algorithms based on atomic read/write operations on single words. Thus it allows for higher scalability with respect to the register size. Moreover, ARC explicitly reduces the overall energy consumption, via a proper limitation of RMW instructions in case of read operations re-accessing a still-valid snapshot of the register content, and by showing constant time for read operations and amortized constant time for write operations. Our proposal has therefore a strong focus on real-world off-the-shelf architectures, allowing us to capture properties which benefit both performance and energy consumption. A proof of correctness of our register algorithm is also provided, together with experimental data for a comparison with literature proposals. Beyond assessing ARC on physical platforms, we carry out as well an experimentation on virtualized infrastructures, which shows the resilience of wait-free synchronization as provided by ARC with respect to CPU-steal times, proper of modern paradigms such as cloud computing. Finally, we discuss how to extend ARC for scenarios with multiple writers and multiple readers—the so called (M,N) register. This is achieved not by changing the operations (and their wait-free nature) executed along the critical path of the threads, rather only changing the ratio between the number of buffers keeping the register snapshots and the number of threads to coordinate, as well as the number of bits used for counting readers within a 64-bit mask accessed via RMW instructions—just depending on the target balance between the number of readers and the number of writers to be supported.},
  doi       = {10.1109/TPDS.2018.2865932},
  publisher = {IEEE},
  series    = {TPDS},
}

@Article{Cin17b,
  author    = {Cingolani, Davide and Pellegrini, Alessandro and Quaglia, Francesco},
  title     = {Transparently Mixing Undo Logs and Software Reversibility for State Recovery in Optimistic PDES},
  journal   = {ACM Transactions on Modeling and Computer Simulation},
  year      = {2017},
  issn      = {0885-7458},
  month     = may,
  number    = {2},
  pages     = {11:1--11:26},
  volume    = {27},
  abstract  = {The Time Warp synchronization protocol for Parallel Discrete Event Simulation (PDES) is universally considered a viable solution to exploit the intrinsic simulation model parallelism and to provide model execution speedup. Yet it leads the PDES system to execute events in an order that may generate causal inconsistencies that need to be recovered via rollback, which requires restoration of a previous (consistent) simulation state whenever a causality violation is detected. The rollback operation is so critical for the performance of a Time Warp system that it has been extensively studied in the literature for decades to find approaches suitable to optimize it. The proposed solutions can be roughly classified as based on either checkpointing or reverse computing. In this article, we explore the practical design and implementation of a fully new approach based on the runtime generation of so-called undo code blocks, which are blocks of instructions implementing the reverse memory side effects generated by the forward execution of the events. However, this is not done by recomputing the original values to be restored, as instead it occurs in reverse computing schemes. Hence, the philosophy undo code blocks rely on is similar in spirit to that of undo-logs (as a form of checkpointing). Nevertheless, they are not data logs (as instead checkpoints are); rather, they are logs of instructions. Our proposal is fully transparent, thanks to the reliance on static software instrumentation (targeting the x86 architecture and Linux systems). Also, as we show, it can be combined with classical checkpointing to further improve the runtime behavior of the state recoverability support as a function of the workload. We also present experimental results related to our implementation, which is released as free software and fully integrated into the open source ROOT-Sim package. Experimental data support the viability and effectiveness of our proposal.},
  doi       = {10.1145/3077583},
  publisher = {ACM Press},
  series    = {TOMACS},
}

@Article{Pell17b,
  author    = {Pellegrini, Alessandro and Quaglia, Francesco},
  title     = {A Fine-grain Time-sharing Time Warp System},
  journal   = {ACM Transactions on Modeling and Computer Simulation},
  year      = {2017},
  issn      = {0885-7458},
  month     = may,
  number    = {2},
  volume    = {27},
  abstract  = {Several techniques have been proposed to improve the performance of Parallel Discrete Event Simulation platforms relying on the Time Warp (optimistic) synchronization protocol. Among them we can mention optimized approaches for state restore, as well as techniques for load balancing or (dynamically) controlling the speculation degree, the latter being specifically targeted at reducing the incidence of causality errors leading to waste of computation. However, in state-of-the-art Time Warp systems, events’ processing is not preemptable, which may prevent the possibility to promptly react to the injection of higher priority (say, lower timestamp) events. Delaying the processing of these events may, in turn, give rise to higher incidence of incorrect speculation. In this article, we present the design and realization of a fine-grain time-sharing Time Warp system, to be run on multi-core Linux machines, which makes systematic use of event preemption in order to dynamically reassign the CPU to higher priority events/tasks. Our proposal is based on a truly dual mode execution, application versus platform, which includes a timer-interrupt-based support for bringing control back to platform mode for possible CPU reassignment according to very fine grain periods. The latter facility is offered by an ad-hoc timer-interrupt management module for Linux, which we release, together with the overall time-sharing support, within the open source ROOT-Sim platform. An experimental assessment based on the classical PHOLD benchmark and two real-world models is presented, which shows how our proposal effectively leads to the reduction of the incidence of causality errors, especially when running with higher degrees of parallelism.},
  doi       = {10.1145/3013528},
  publisher = {ACM Press},
  series    = {TOMACS},
}

@Article{Pell16b,
  author    = {Pellegrini, Alessandro and Peluso, Sebastiano and Quaglia, Francesco and Vitali, Roberto},
  title     = {Transparent Speculative Parallelization of Discrete Event Simulation Applications Using Global Variables},
  journal   = {International Journal of Parallel Programming},
  year      = {2016},
  issn      = {0885-7458},
  month     = dec,
  number    = {6},
  pages     = {1200--1247},
  volume    = {44},
  abstract  = {Parallelizing (compute-intensive) discrete event simulation (DES) applications is a classical approach for speeding up their execution and for making very large/complex simulation models tractable. This has been historically achieved via parallel DES (PDES) techniques, which are based on partitioning the simulation model into distinct simulation objects (somehow resembling objects in classical object-oriented programming), whose states are disjoint, which are executed concurrently and rely on explicit event-exchange (or event-scheduling) primitives as the means to support mutual dependencies and notification of their state updates. With this approach, the application developer is necessarily forced to reason about state separation across the objects, thus being not allowed to rely on shared information, such as global variables, within the application code. This implicitly leads to the shift of the user-exposed programming model to one where sequential-style global variable accesses within the application code are not allowed. In this article we remove this limitation by providing support for managing global variables in the context of DES code developed in ANSI-C, which gets automatically parallelized. Particularly, we focus on speculative (also termed optimistic) PDES systems that run on top of multi-core machines, where simulation objects can concurrently process their events with no guarantee of causal consistency and actual violations of causality rules are recovered through rollback/recovery schemes. In compliance with the nature of speculative processing, in our proposal global variables are transparently mapped to multi-versions, so as to avoid any form of safety predicate verification upon their updates. Consistency is ensured via the introduction of a new rollback/recovery scheme based on detecting global variables’ reads on non-correct versions. At the same time, efficiency in the execution is guaranteed by managing multi-version variables’ lists via non-blocking algorithms. Furthermore, the whole approach is fully transparent, being it based on automatized instrumentation of the application software (particularly ELF objects). Hence the programmer is exposed to the classical (and easy to code) sequential-style programming scheme while accessing any global variable. An experimental assessment of our proposal, based on a suite of case study applications, run on top of an off-the-shelf Linux machine equipped with 32 CPU-cores and 64 GB of RAM, is also presented.},
  doi       = {10.1007/s10766-016-0429-2},
  publisher = {Springer Verlag},
  series    = {IJPP},
}

@Article{DiS15,
  author    = {Di Sanzo, Pierangelo and Quaglia, Francesco and Ciciani, Bruno and Pellegrini, Alessandro and Didona, Diego and Romano, Paolo and Palmieri, Roberto and Peluso, Sebastiano},
  title     = {A Flexible Framework for Accurate Simulation of Cloud In-Memory Data Stores},
  journal   = {Simulation Modelling Practice and Theory},
  year      = {2015},
  issn      = {1569-190X},
  month     = jul,
  number    = {2},
  pages     = {219--238},
  volume    = {58},
  abstract  = {In-memory (transactional) data stores, also referred to as data grids, are recognized as a first-class data management technology for cloud platforms, thanks to their ability to match the elasticity requirements imposed by the pay-as-you-go cost model. On the other hand, determining how performance and reliability/availability of these systems vary as a function of configuration parameters, such as the amount of cache servers to be deployed, and the degree of in-memory replication of slices of data, is far from being a trivial task. Yet, it is an essential aspect of the provisioning process of cloud platforms, given that it has an impact on the amount of cloud resources that are planned for usage. To cope with the issue of predicting/analysing the behavior of different configurations of cloud in-memory data stores, in this article we present a flexible simulation framework offering skeleton simulation models that can be easily specialized in order to capture the dynamics of diverse data grid systems, such as those related to the specific (distributed) protocol used to provide data consistency and/or transactional guarantees. Besides its flexibility, another peculiar aspect of the framework lies in that it integrates simulation and machine-learning (black-box) techniques, the latter being used to capture the dynamics of the data-exchange layer (e.g. the message passing layer) across the cache servers. This is a relevant aspect when considering that the actual data-transport/networking infrastructure on top of which the data grid is deployed might be unknown, hence being not feasible to be modeled via white-box (namely purely simulative) approaches. We also provide an extended experimental study aimed at validating instances of simulation models supported by our framework against execution dynamics of real data grid systems deployed on top of either private or public cloud infrastructures. Particularly, our validation test-bed has been based on an industrial-grade open-source data grid, namely Infinispan by JBoss/Red-Hat, and a de-facto standard benchmark for NoSQL platforms, namely YCSB by Yahoo. The validation study has been conducted by relying on both public and private cloud systems, scaling the underlying infrastructure up to 100 (resp. 140) Virtual Machines for the public (resp. private) cloud case. Further, we provide some experimental data related to a scenario where our framework is used for on-line capacity planning and reconfiguration of the data grid system.},
  doi       = {10.1016/j.simpat.2015.05.011},
  publisher = {Elsevier},
  series    = {SIMPAT},
}

@Article{Pell14d,
  author    = {Pellegrini, Alessandro and Vitali, Roberto and Quaglia, Francesco},
  title     = {Autonomic State Management for Optimistic Simulation Platforms},
  journal   = {IEEE Transactions on Parallel and Distributed Systems},
  year      = {2015},
  issn      = {1045-9219},
  month     = jun,
  number    = {6},
  pages     = {1560--1569},
  volume    = {26},
  abstract  = {We present the design and implementation of an autonomic state manager (ASM) tailored for integration within optimistic parallel discrete event simulation (PDES) environments based on the C programming language and the executable and linkable format (ELF), and developed for execution on ×86_64 architectures. With ASM, the state of any logical process (LP), namely the individual (concurrent) simulation unit being part of the simulation model, is allowed to be scattered on dynamically allocated memory chunks managed via standard API (e.g., malloc/free). Also, the application programmer is not required to provide any serialization/ deserialization module in order to take a checkpoint of the LP state, or to restore it in case a causality error occurs during the optimistic run, or to provide indications on which portions of the state are updated by event processing, so to allow incremental checkpointing. All these tasks are handled by ASM in a fully transparent manner via (A) runtime identification (with chunk-level granularity) of the memory map associated with the LP state, and (B) runtime tracking of the memory updates occurring within chunks belonging to the dynamic memory map. The co-existence of the incremental and non-incremental log/restore modes is achieved via dual versions of the same application code, transparently generated by ASM via compile/link time facilities. Also, the dynamic selection of the best suited log/ restore mode is actuated by ASM on the basis of an innovative modeling/optimization approach which takes into account stability of each operating mode with respect to variations of the model/environmental execution parameters.},
  doi       = {10.1109/TPDS.2014.2323967},
  publisher = {IEEE Computer Society},
  series    = {TPDS},
}

@Article{Vit12e,
  author     = {Vitali, Roberto and Pellegrini, Alessandro and Quaglia, Francesco},
  title      = {Load sharing for optimistic parallel simulations on multi core machines},
  journal    = {SIGMETRICS Performance Evaluation Review},
  year       = {2012},
  issn       = {0163-5999},
  month      = aug,
  number     = {3},
  pages      = {2--11},
  volume     = {40},
  abstract   = {Parallel Discrete Event Simulation (PDES) is based on the partitioning of the simulation model into distinct Logical Processes (LPs), each one modeling a portion of the entire system, which are allowed to execute simulation events concurrently. This allows exploiting parallel computing architectures to speedup model execution, and to make very large models tractable. In this article we cope with the optimistic approach to PDES, where LPs are allowed to concurrently process their events in a speculative fashion, and rollback/ recovery techniques are used to guarantee state consistency in case of causality violations along the speculative execution path. Particularly, we present an innovative load sharing approach targeted at optimizing resource usage for fruitful simulation work when running an optimistic PDES environment on top of multi-processor/multi-core machines. Beyond providing the load sharing model, we also define a load sharing oriented architectural scheme, based on a symmetric multi-threaded organization of the simulation platform. Finally, we present a real implementation of the load sharing architecture within the open source ROme OpTimistic Simulator (ROOT-Sim) package. Experimental data for an assessment of both viability and effectiveness of our proposal are presented as well.},
  doi        = {10.1145/2425248.2425250},
  issue_date = {December 2012},
  numpages   = {10},
  publisher  = {ACM},
  series     = {PER},
}


%%%%% Conference Proceedings %%%%%


@inproceedings{Bau25,
  author    = {Bauco, Simone and De Angelis, Guglielmo and Marotta, Romolo and Pellegrini, Alessandro},
  title     = {A Model-Driven Platform for Software Applications on Heterogeneous Computing Environments},
  booktitle = {22nd {IEEE} International Conference on Software Architecture, {ICSA} 2025 - Companion},
  abstract  = {The rise of heterogeneous computing environments has significantly advanced the capabilities of high-performance concurrent applications. However, the design of applications for these environments requires ICT application experts to have a deep understanding of hardware aspects and often their related optimisation strategies. As a consequence, the effort in the development phase is strongly influenced by intricate technical hindrances rather than focusing on domain-specific issues. This work presents Domain, a software platform that supports ICT experts in taming the complexity of modern hardware environments. Specifically, Domain identifies a comprehensive socio-technical environment where classes of stakeholders cooperate in order to support the development of software applications for heterogeneous computing environments. Also, Domain proposes families of software assets that promote the adoption of domain-specific notations, their automatic refinement up to the generation of hardware-specific binaries, and the optimised execution of such binaries on the target hardware resources. The proposed software platform has been applied to a first case study in the domain of speculative stream processing on the Taxi and Limousine Commission Trip data records from the New York City area. },
  publisher = {IEEE},
  year      = {2025},
  month     = mar,
}


@InProceedings{Cal25,
  author    = {Caliandro, Pierciro and Ciccaglione, Matteo and Pepe, Andrea and Bianchi, Giuseppe and Pellegrini, Alessandro},
  title     = {VMORPH: A Virtualization/Metamorphic Framework for Binary Obfuscation and Intellectual Property Protection},
  booktitle = {Proceedings of the 2025 Italian Conference on Cybersecurity}, 
  abstract  = {In this paper, we analyse the effectiveness of combining obfuscation and metamorphism techniques to evade antivirus detection and protect intellectual property. We do so by introducing a new framework called VMORPH, which utilises jointly emulation and metamorphic techniques to thwart attempts at reconstructing the application's behaviour and accessing internal details or secrets. We assess the performance of VMORPH to determine its suitability for safeguarding the intellectual property of the application. The findings indicate a decrease in performance, which is still acceptable for securing applications. Additionally, we investigate the stealth capabilities of the proposed technique, which enhances its ability to bypass common static analysis techniques. Based on the results, we also suggest detection techniques that can be employed to mitigate the risk that this technique is used to evade antivirus detection.},
  year      = {2025},
  month     = feb,
  publisher = {CEUR-WS.org},
  series    = {ITASEC},
  location  = {Bologna, Italy},
}


@InProceedings{Del25,
  author    = {Dell'Orco, Danilo and Valeriani, Lorenzo and Bianchi, Giuseppe and Pellegrini, Alessandro and Merlo, Alessio},
  title     = {Challenging Antivirus against Elusive Android Malware over Time},
  booktitle = {Proceedings of the 2025 Italian Conference on Cybersecurity}, 
  year      = {2025},
  month     = feb,
  publisher = {CEUR-WS.org},
  series    = {ITASEC},
  location  = {Bologna, Italy},
}


@InProceedings{Mar24b,
  author    = {Marotta, Romolo and Pellegrini, Alessandro},
  booktitle = {Proceedings of the 2024 Winter Simulation Conference},
  title     = {Model-Driven Engineering for High-Performance Parallel Discrete Event Simulations on Heterogeneous Architectures},
  year      = {2024},
  month     = dec,
  publisher = {IEEE},
  series    = {WSC},
  abstract  = {Modern high-performance, large-scale simulations require significant computational power, memory, and storage, making heterogeneous architectures an attractive option. Yet, the presence of accelerators in heterogeneous architectures makes model development hard. Domain-specific languages (DSLs) have successfully simplified model development, but designing a DSL to target heterogeneous architectures can be burdensome. Model-driven engineering (MDE) can simplify the development of DSLs targeting heterogeneous architectures. In this paper, we present a model-driven approach targeting Parallel Discrete Event Simulations on heterogeneous architectures. We exercise our MDE-generated models using a state-of-the-art runtime environment for heterogeneous architectures, using a custom DSL as an example.},
  location  = {Orlando, FL, USA},
}

@InProceedings{And24,
  author    = {Andelfinger, Philipp and Pellegrini, Alessandro and Marotta, Romolo},
  title     = {Sampling Policies for Near-Optimal Device Choice in Parallel Simulations on CPU/GPU Platforms},
  booktitle = {Proceedings of the 28th IEEE/ACM International Symposium on Distributed Simulation and Real Time Applications},
  year      = {2024},
  month     = oct,
  publisher = {IEEE},
  series    = {DS-RT},
  abstract  = {Heterogeneous hardware platforms comprised of CPUs, GPUs, and other accelerators offer the opportunity to choose the best-suited device for executing a given scientific simulation in order to minimize execution time and energy consumption. To this end, the recently proposed “Follow the Leader” approach dynamically selects a suitable device based on runtime performance measurements during speculative discreteevent simulations. A currently active “leader” device is periodically challenged by a “follower” device in order to negotiate the new leader. The optimality of the device choices and the associated overhead depends critically on the challenge frequency and timing. Here, we explore policies to schedule challenges with the goal of attaining Pareto-optimal combinations of execution time and energy consumption. Several heuristics are first evaluated in an abstract fashion using a “meta-simulation” by mimicking the progress and energy consumption of an idealized co-execution. In this setting, we optimize the heuristics’ tuning parameters to assess their relative merits in near-optimal configurations when compared to challenge timings based on perfect knowledge. We find that under challenging stochastic workloads based on a class of mean-reverting random walks, the best heuristics can closely approximate the execution time and energy consumption achievable under an optimal device choice. Empirical support for this observation is given by measurements of a CPU/GPU co-execution of the Time Warp algorithm on physical hardware.},
  location  = {Urbino, Italy},
}

@InProceedings{Du24,
  author    = {Du, Xiaorui and Piccione, Andrea and Pimpini, Adriano and Bortoli, Stefano and Pellegrini, Alessandro and Knoll, Alois},
  title     = {Online Analytics with Local Operator Rebinding for Simulation Data Stream Processing},
  booktitle = {Proceedings of the 28th IEEE/ACM International Symposium on Distributed Simulation and Real Time Applications},
  year      = {2024},
  month     = oct,
  publisher = {IEEE},
  series    = {DS-RT},
  abstract  = {Leveraging multiple threads to process high volumes of simulation data is a prevalent strategy in modern streaming data processing systems. Statically binding operators to specific threads is the most common design employed due to its simplicity in implementation and initial system configuration. However, this approach often fails to effectively account for the inherently dynamic nature of simulation data, potentially leading to inefficient resource utilisation and processing bottlenecks. To address these limitations, we present a novel mechanism for stream-processing operator rebinding that enables lock-free, dynamic workload rebalancing between worker threads. The rebinding is driven by an autonomic policy that captures workload imbalance in the stream-processing pipeline when multiple queries are computed and reacts to it by moving computation around the different threads. We evaluate our proposal using data generated from large-scale traffic simulations on which multiple queries are executed. The volume and organisation of the data we feed to the stream-processing pipeline significantly change over time, providing excellent grounds to evaluate our rebinding policy. The evaluation confirms that the performance of stream processing pipelines can be greatly improved using local operator rebinding.},
  location  = {Urbino, Italy},
}


@InProceedings{Pic24,
  author    = {Piccione, Andrea and Pellegrini, Alessandro},
  booktitle = {Proceedings of the 2024 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
  title     = {Efficient Non-Blocking Event Management for Speculative Parallel~Discrete~Event~Simulation},
  year      = {2024},
  month     = jun,
  publisher = {ACM},
  series    = {SIGSIM-PADS '24},
  abstract  = {Parallel Discrete Event Simulation (PDES) is a modelling technique that takes advantage of concurrent computing resources. However, its asynchronous nature can present challenges for efficient execution. This paper proposes a new non-blocking management system for handling messages and anti-messages in Time Warp simulations. This approach exploits the benefits of non-blocking algorithms to surpass the limitations of existing blocking mechanisms, resulting in more efficient and scalable simulations. Specifically, the approach relies on efficient atomic fetch-and-add operations provided by modern computer architectures for evaluating and updating the status of the event.},
  doi       = {10.1145/3615979.3656053},
  location  = {Atlanta, GA, USA},
  badges    = {available,functional,reproduced},
}

@InProceedings{Mar24,
  author    = {Marotta, Romolo and Pellegrini, Alessandro and Andelfinger, Philipp},
  booktitle = {Proceedings of the 2024 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
  title     = {Follow the Leader: Alternating CPU/GPU Computations in PDES},
  year      = {2024},
  month     = jun,
  publisher = {ACM},
  series    = {SIGSIM-PADS '24},
  abstract  = {Despite the successes of graphics processing units (GPUs) in accelerating simulations in several research fields, their use is largely restricted to domain-specific workloads that consistently offer the large degree of inherent parallelism and computational intensity at which GPUs excel.
When targeting generic discrete-event simulations, whose dynamics can vary wildly over time, a static choice between a GPU-based and traditional CPU-based execution is likely to be suboptimal.
Here, we explore a parallel discrete-event (PDES) execution scheme for CPU-GPU platforms that aims to approximate an optimal dynamic device choice.
Starting from an intermediate model state, a current "leader" device running the simulation is periodically challenged by a brief concurrent run on another device starting from an intermediate model state.
Based on the gathered performance measurements, a forecasting scheme determines the leader for the next period.
The execution time and power consumption of this scheme hinge on 1) an efficient mechanism for providing the "follower" device with a consistent model state, and 2) robust performance forecasting to justify the device choices.
We present these building blocks, their implementation combining the existing CPU and GPU simulators ROOT-Sim and GPUTW, and measurement results demonstrating substantially reduced execution time without increasing energy consumption over a static device choice.},
  doi       = {10.1145/3615979.3656056},
  location  = {Atlanta, GA, USA},
  badges    = {available,functional,reproduced},
}

@InProceedings{DuX24,
  author    = {Du, Xiaorui and Piccione, Andrea and Pimpini, Adriano and Bortoli, Stefano and Knoll, Alois and Pellegrini, Alessandro},
  booktitle = {Proceedings of the 24th International Symposium on Cluster, Cloud and Grid Computing},
  title     = {HUILLY: A Non-Blocking Ingestion Buffer for Timestepped Simulation Analytics},
  year      = {2024},
  month     = may,
  publisher = {IEEE},
  series    = {CCGrid},
}


@InProceedings{DuX23,
  author    = {Du, Xiaorui and Pimpini, Adriano and Piccione, Andrea and Meng, Zhuoxiao and Siguenza-Torres, Anibal and Bortoli, Stefano and Knoll, Alois and Pellegrini, Alessandro},
  booktitle = {Proceedings of the 2023 Winter Simulation Conference},
  title     = {Autonomic Orchestration of In-situ and In-transit Data Analytics for Simulation Studies},
  year      = {2023},
  month     = dec,
  publisher = {IEEE},
  series    = {WSC},
  abstract  = {Modern parallel/distributed simulations can produce large amounts of data. The historical approach of performing analyses at the end of the simulation is unlikely to cope with modern, extremely large-scale analytics jobs. Indeed, the I/O subsystem can quickly become the global bottleneck. Similarly, processing on-the-fly the data produced by simulations can significantly impair the performance in terms of computational capacity and network load.
We present a methodology and reference architecture for constructing an autonomic control system to determine at runtime the best placement for data processing (on simulation nodes or a set of external nodes). This allows for a good tradeoff between the load on the simulation's critical path and the data communication system. Our preliminary experimentation shows that autonomic orchestration is crucial to improve the global performance of a data analysis system, especially when the simulation node's rate of data production varies during simulation.},
}

@InProceedings{Pic23c,
  author    = {Piccione, Andrea and Pellegrini, Alessandro},
  title     = {Practical Tie Breaking for Parallel/Distributed Simulations},
  booktitle = {Proceedings of the 27th IEEE/ACM International Symposium on Distributed Simulation and Real Time Applications},
  year      = {2023},
  month     = oct,
  publisher = {IEEE},
  series    = {DS-RT},
  abstract  = {In this paper, we discuss a tie-breaking strategy based on a bitwise comparison of event payload that allows parallel and distributed discrete-event simulations to observe a deterministic order in the execution of events, even in the presence of event ties. This approach provides practical usability whenever model-assisted tie-breaking is unavailable, thus ensuring that multiple simulation executions provide deterministic behaviour and repeatable results. Moreover, it ensures that the selected order of events is also consistent with sequential executions. We discuss the theory behind this strategy and experimentally show that the performance drop is imputable to event queue management when relying on tie-breaking strategies like the ones discussed in this work.},
  location  = {Singapore},
  note      = {Winner of the Best Paper Award},
}

@InProceedings{Mar23,
  author    = {Marotta, Romolo and Montesano, Federica and Pellegrini, Alessandro and Quaglia, Francesco},
  title     = {Incremental Checkpointing of Large State Simulation Models with Write-Intensive Events via Memory Update Correlation on Buddy Pages},
  booktitle = {Proceedings of the 27th IEEE/ACM International Symposium on Distributed Simulation and Real Time Applications},
  year      = {2023},
  month     = oct,
  publisher = {IEEE},
  series    = {DS-RT},
  abstract  = {Checkpointing techniques for speculative parallel simulation of discrete event models have been widely studied in the literature. However, there has been a very marginal attempt to exploit operating system page-protection services, which have instead been largely exploited in the context of checkpointing for fault tolerance. In this article, we discuss how these services can effectively manage simulation models with large states and write-intensive events on zones in the state layout. In particular, we present a solution where the correlation of write operations on buddy pages in the state layout can be exploited for achieving effective incremental checkpointing support, which allows scaling down the costs of operating system services. Our solution does not require any instrumentation of the simulation application code and is usable on any Posix-compliant operating system. We also discuss its integration within the USE (Ultimate-Share-Everything) open-source speculative simulation package and report some experimental data for its assessment.},
  location  = {Singapore},
  note      = {Shortlisted for the Best Paper Award},
}

@InProceedings{Pic23b,
  author    = {Piccione, Andrea and Andelfinger, Philipp and Pellegrini, Alessandro},
  booktitle = {Proceedings of the 2023 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
  title     = {Hybrid Speculative Synchronisation for Parallel Discrete Event Simulation},
  year      = {2023},
  month     = jun,
  publisher = {ACM},
  series    = {SIGSIM-PADS '23},
  abstract  = {Parallel discrete-event simulation (PDES) is a well-established family of methods to accelerate discrete-event simulations. However, the available algorithms vary substantially in the performance achievable for different simulation models, largely preventing generic solutions applicable by modellers without expert knowledge. For instance, in Time Warp, the processing elements execute events asynchronously and speculatively with high aggressiveness, leading to frequent and costly rollbacks if misspeculations occur often. In contrast, synchronous approaches such as the new Window Racer algorithm exhibit a more cautious form of speculation. In the present paper, we combine these two fundamentally different algorithms within a single runtime environment, allowing for a choice of the best algorithm for different model segments. We describe the architecture and the algorithmic considerations to support the efficient coexistence and interaction of the algorithms without violating the correctness of the simulation. Our experiments using a synthetic benchmark and an epidemics model show that the hybrid algorithm is less sensitive to its configuration and can deliver substantially higher performance in models with varying degrees of coupling among entities compared to each algorithm on its own.},
  doi       = {10.1145/3573900.3591124},
  location  = {Orlando, FL, USA},
  badges    = {available,reusable,reproduced},
}

@InProceedings{Pic23,
  author    = {Piccione, Andrea and Bernardinetti, Giorgio and Pellegrini, Alessandro and Bianchi, Giuseppe},
  title     = {Is Your Smartphone Really Safe? A Wake-up Call on Android Antivirus Software Effectiveness},
  booktitle = {Proceedings of the 2023 Italian Conference on Cybersecurity}, 
  abstract  = {A decade ago, researchers raised severe concerns about Android smartphones' security by extensively assessing and recognising the limitations of Android antivirus software. Considering the significant increase in the economic role of smartphones in recent years, we would expect that security measures are significantly improved by now. To test this assumption, we conducted a relatively extensive study to evaluate the effectiveness of off-the-shelf antivirus software in detecting malicious applications injected into legitimate Android applications.
We specifically repackaged seven widely used Android applications with 100 obfuscated malware instances. We submitted the 700 samples to the VirusTotal web portal, testing the effectiveness of the over 70 free and commercial antiviruses available in detecting them. 
For the obfuscation part, we intentionally employed publicly available tools that could be used by ``just” a tech-savvy adversary. We used a combination of well-known and novel (but still simple) obfuscation techniques. Surprisingly (or perhaps unsurprisingly?), our findings indicate that almost 76\% of the samples went utterly undetected. Even when our samples were detected, this occurred for a handful (never more than 4) of Android antivirus software available on VirusTotal. This lack of awareness of the effectiveness of Android antivirus is critical because the false sense of security given by antivirus software could prompt users to install applications from untrusted sources, allowing attackers to install a persistent threat within another application easily.},
  year      = {2023},
  month     = may,
  publisher = {CEUR-WS.org},
  series    = {ITASEC},
  location  = {Bari, Italy},
}

@InProceedings{And22,
  author    = {Andelfinger, Philipp and Piccione, Andrea and Pellegrini, Alessandro and Uhrmacher, Adelinde},
  title     = {Comparing Speculative Synchronization Algorithms for Continuous-Time Agent-Based Simulations},
  booktitle = {Proceedings of the 26th IEEE/ACM International Symposium on Distributed Simulation and Real Time Applications},
  year      = {2022},
  month     = sep,
  publisher = {IEEE},
  series    = {DS-RT},
  abstract  = {Continuous-Time agent-based models often represent tightly-coupled systems where agents' state transitions occur in close interaction with neighbouring agents. Without artificial discretization, the potential for near-instantaneous propagation of effects across the model challenges their parallel execution. Although existing algorithms can tackle the largely unpredictable nature of such simulations through speculative execution, they are subject to trade-offs concerning the degree of optimism, the probability and cost of rollbacks, and locality exploitation. This paper aims to understand the suitability of asynchronous and synchronous parallel simulation algorithms when executing continuous-time agent-based models with rate-driven stochastic transitions. We present extensive measurement results comparing optimized implementations under various configurations of a parametrizable simulation model of the epidemic spread of disease. Our results show that the amount of locality in the agent interactions is the decisive factor for the relative performance of the approaches. We identify remaining hurdles for higher simulation performance with the two classes of algorithms and outline potential refinements based on profiling results.},
  location  = {Alès, France},
  note      = {Winner of the Best Paper Award},
}

@InProceedings{Pim22b,
  author    = {Pimpini, Adriano and Piccione, Andrea and Pellegrini, Alessandro},
  title     = {On the Accuracy and Performance of Spiking Neural Network Simulations},
  booktitle = {Proceedings of the 26th IEEE/ACM International Symposium on Distributed Simulation and Real Time Applications},
  year      = {2022},
  month     = sep,
  publisher = {IEEE},
  series    = {DS-RT},
  abstract  = {Spiking Neural Networks (SNNs) are a class of Artificial Neural Networks that show a time behaviour that cannot be computed with single one-shot functions. Therefore, to study their evolution over time, simulations are typically employed. Typical simulation approaches rely on time stepped simulations, while more recent works have highlighted the opportunity to rely on Parallel Discrete Event Simulation (PDES) for improved accuracy. In particular, Speculative PDES has been shown to be a suitable simulation paradigm to deal with the peculiar temporal domain of SNNs. In this paper, we perform an experimental evaluation of these two different approaches, showing the implications on both simulation performance and accuracy. Our assessment showcases that Parallel Discrete Event Simulation can deliver good scaling on parallel architectures while offering more accurate results.},
  location  = {Alès, France},
  note      = {Shortlisted for the Best Paper Award},
}

@InProceedings{Pim22,
  author    = {Pimpini, Adriano and Piccione, Andrea and Ciciani, Bruno and Pellegrini, Alessandro},
  booktitle = {Proceedings of the 2022 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
  title     = {Speculative Distributed Simulation of Very Large Spiking Neural Networks},
  year      = {2022},
  month     = jun,
  publisher = {ACM},
  series    = {PADS},
  abstract  = {Spiking Neural Networks are a class of Artificial Neural Networks that closely mimic biological neural networks. They are particularly interesting because of their potential to advance research in several fields, both because of better insights on neural behaviour (benefiting medicine, neuroscience, psychology) and the potential in Artificial Intelligence. Their ability to run on a  low energy budget once implemented in hardware makes them even more appealing. However, because of their behaviour that evolves with time, when a hardware implementation is not available, their output cannot simply be computed with a one-shot function (however complex), but instead they need to be simulated.
Simulating Spiking Neural Networks is exceptionally costly, mainly due to their sheer size. Many current simulation methods have trouble scaling up on more powerful systems because of conservative synchronisation methods. Scalability is often offered through approximation of the actual results. In this paper, we present a modelling methodology and runtime-environment support adhering to the Time Warp synchronisation protocol, which enables speculative distributed simulation of Spiking Neural Network models with improved accuracy of the results. We discuss the methodological and technical aspects that will allow effective speculative simulation and present an experimental assessment on large virtualised environments, which shows the viability of simulating networks made of millions of neurons.},
  doi       = {10.1145/3518997.3531027},
  location  = {Atlanta, GA, USA},
  badges    = {available,reusable},
}

@InProceedings{DeA21b,
  author    = {De~Angelis, Emanuele and Pellegrini, Alessandro and Proietti, Maurizio},
  booktitle = {Proceedings of the 2021 IEEE International Symposium on Software Reliability Engineering Workshops},
  title     = {Automatic Extraction of Behavioral Features for Test Program Similarity Analysis},
  year      = {2021},
  month     = oct,
  publisher = {IEEE},
  series    = {ISSREW},
  abstract  = {We present a methodology for performing automatic extraction of behavioral features from test programs, that is, for collecting pieces of information about the test programs execution. These features are then exploited to carry out analysis and reasoning about test program similarity. The similarity information can be used to drive the execution of test campaigns, in the attempt to either reduce the time-to-test, or to increase the testing capabilities of a given test suite. Our methodology is embedded in the Hyperion analysis framework, which can be configured to define a wide range of test program similarity criteria.},
  location  = {Wuhan, China},
  doi       = {10.1109/ISSREW53611.2021.00054},
  pages     = {129--136},
}

@InProceedings{DeA21,
  author    = {De~Angelis, Emanuele and De~Angelis, Guglielmo and Pellegrini, Alessandro and Proietti, Maurizio},
  booktitle = {Proceedings of the 15th IEEE International Conference on Service Oriented Systems Engineering},
  title     = {Inferring Relations Among Test Programs in Microservices Applications},
  year      = {2021},
  month     = aug,
  publisher = {IEEE},
  pages     = {114--123},
  series    = {SOSE},
  abstract  = {The emergence of the microservices-oriented architectural style calls for novel methodologies and technological frameworks that support the design, development, and maintainance of applications structured according to that new style. In this paper, we consider the issue of designing suitable strategies for the governance and the automation of testing activities within the microservices paradigm. 
		We focus on the problem of discovering relations between test programs that help avoiding to re-run all the available test suites each time one of its constituents evolves. 
		We propose an analysis technique, based on symbolic execution of test programs, which is able to collect information about the invocations of local and remote APIs performed when running such programs.
		Symbolic execution enables the analysis of sets of executions corresponding to different input data, and hence it is also suitable for parametric test programs. 
		The information extracted by symbolic execution is processed by a rule-based automated reasoning engine, which infers dependencies and similarities among test programs. In particular, test programs are considered similar if they involve the same microservice instance, or they connect to the same remote API, or they locally activate overlapping APIs, or they raise similar kinds of errors.
		We show the viability of our approach by presenting a case study within the context of a real-world microservice application that implements an open-source educational platform.},
  location  = {Oxford, UK},
  doi       = {10.1109/SOSE52839.2021.00018},
  note      = {Winner of the Best Paper Award},
}

@InProceedings{Rab20,
  author    = {Rab, Maryan and Marotta, Romolo and Ianni, Mauro and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 24th IEEE/ACM International Symposium on Distributed Simulation and Real Time Applications},
  title     = {NUMA-Aware Non-Blocking Calendar Queue},
  year      = {2020},
  month     = sep,
  publisher = {IEEE},
  series    = {DS-RT},
  abstract  = {Modern computing platforms are based on multi-processor/multi-core technology. This allows running applications with a high degree of hardware parallelism. However, medium-to-high end machines pose a problem related to the asymmetric delays threads experience when accessing shared data. Specifically, Non-Uniform-Memory-Access (NUMA) is the dominating technology---thanks to its capability for scaled-up memory bandwidth---which however imposes asymmetric distances between CPU-cores and memory banks, making an access by a thread to data placed on a far NUMA node severely impacting performance. In this article, we tackle this problem in the context of shared event-pool management, a relevant aspect in many fields, like parallel discrete event simulation. Specifically, we present a NUMA-aware calendar queue, which also has the advantage of making concurrent threads coordinate via a non-blocking scalable approach. Our proposal is based on work deferring combined with dynamic re-binding of the calendar queue operations (insertions/extractions) to the best suited among the concurrent threads hosted by the underlying computing platform. This changes the locality of the operations by threads in a way positively reflected onto NUMA tasks at the hardware level. We report the results of an experimental study, demonstrating the capability of our solution to achieve the order of 15% better performance compared to state-of-the-art solutions already suited for multi-core environments.},
  location  = {Prague, Czech Republic},
}

@InProceedings{Pic20,
  author    = {Piccione, Andrea and Pellegrini, Alessandro},
  booktitle = {Proceedings of the 24th IEEE/ACM International Symposium on Distributed Simulation and Real Time Applications},
  title     = {Agent-based Modeling and Simulation for Emergency Scenarios: A Holistic Approach},
  year      = {2020},
  month     = sep,
  publisher = {IEEE},
  series    = {DS-RT},
  abstract  = {Agent-based Modeling and Simulation is a powerful technique which allows to study the interactions in complex systems, and allows to explore or even foresee the emergence of more complicated properties or behaviors related to the interaction among the simpler agents in the environment. In the context of emergency or crisis scenarios, Agent-based Modeling and Simulation can allow to effectively study emergency plans, with the goal of assessing their viability, also with respect to the number of possible fatalities. In this paper, we analyze Agent-based Modeling and Simulation for crisis scenarios from a methodological and empirical point of view, with the goal of identifying what are the behavioral parameters that a model should encompass, in order for the results of the simulation to be useful for emergency plan assessment and/or compilation. We also experimentally provide a characterization of the effects of such behavioral parameters.},
  location  = {Prague, Czech Republic},
}

@InProceedings{Con20,
  author    = {Conoci, Stefano and Ianni, Mauro and Marotta, Romolo and Pellegrini, Alessandro},
  booktitle = {Proceedings of the 2020 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
  title     = {Autonomic Power Management in Speculative Simulation Runtime Environments},
  year      = {2020},
  month     = jun,
  publisher = {ACM},
  series    = {PADS},
  abstract  = {While transitioning to exascale systems, it has become clear that power management plays a fundamental role to support a viable utilization of the underlying hardware, also performance-wise. To meet power restrictions imposed by future exascale supercomputers, runtime environments will be required to enforce self-tuning schemes to run dynamic workloads under an imposed power cap. Literature results show that, for a wide class of multi-threaded applications, tuning both the degree of parallelism and frequency/voltage of cores allows a more effective use of the budget, compared to techniques that use only one of these mechanisms in isolation.  
In this paper, we explore the issues associated with applying these techniques on speculative Time-Warp based simulation runtime environments. We discuss how the differences in two antithetical Time Warp-based simulation environments impact the obtained results. Our assessment confirms that the performance gains achieved through a proper allocation of the power budget can be significant. We also identify the research challenges that would make these form of self-tuning more broadly applicable.},
  doi       = {10.1145/3384441.3395980},
  location  = {Miami, FL, USA},
}

@InProceedings{Pri20b,
  author    = {Principe, Matteo and Piccione, Andrea and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 2020 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
  title     = {Approximated Rollbacks},
  year      = {2020},
  month     = jun,
  publisher = {ACM},
  series    = {PADS},
  abstract  = {A rollback operation in a speculative parallel discrete event simulator has traditionally targeted the perfect reconstruction of the state to be restored after a timestamp-order violation. This imposes that the rollback support entails specific capabilities and consequently pays given costs. In this article we propose approximated rollbacks, which allow a simulation object to perfectly realign its virtual time to the timestamp of the state to be restored, but lead the reconstructed state to be an approximation of what it should really be. The advantage is an important reduction of the cost for managing the state restore task in a rollback phase, as well as for managing the activities (i.e. state saving) that actually enable rollbacks to be executed. Our proposal is suited for stochastic simulations, and explores a tradeoff between the statistical representativeness of the outcome of the simulation run and the execution performance. We provide mechanisms that enable the application programmer to control this tradeoff, as well as simulation-platform level mechanisms that constitute the basis for managing approximate rollbacks in general simulation scenarios. A study on the aforementioned tradeoff is also presented.},
  doi       = {10.1145/3384441.3395984},
  location  = {Miami, FL, USA},
  badges    = {available,reusable,reproduced},
}

@InProceedings{Sil20,
  author    = {Silvesti, Emiliano and Milia, Cristian and Marotta, Romolo and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 2020 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
  title     = {Exploiting Inter-Processor-Interrupts for Virtual-Time Coordination in Speculative Parallel Discrete Event Simulation},
  year      = {2020},
  month     = jun,
  publisher = {ACM},
  series    = {PADS},
  abstract  = {Reducing the waste of resource usage (e.g., CPU-cycles) when a causality error occurs in speculative parallel discrete event simulation (PDES) is still a core objective. In this article,
we target this objective in the context of speculative PDES run on top of shared-memory machines. We propose an Operating System 
approach that is based on the exploitation of the Inter-Processor-Interrupt (IPI) facility offered by off-the-shelf hardware chip sets, which enables cross-CPU-core control of the execution flow of threads. As soon as a thread $T$ produces a new event placed in the past virtual time of a simulation object currently run by another thread $T'$, our IPI-based support allows $T$ to change the execution flow of $T'$---with very minimal delay---so to enable the early squash of the currently processed (and no longer consistent) event. Our solution is fully transparent to the application level code, and is coupled with a lightweight heuristic-based mechanism that determines the actual goodness of killing thread $T'$ via the IPI  (rather than skipping the IPI send) depending on the expected residual execution time of the incorrect event being processed. We integrated our proposal within the speculative open-source USE (Ultimate Share Everything) PDES package, and we report experimental results obtained by running various PDES models on top of two shared-memory hardware architectures equipped with 32 and 24 (48 Hyper-threads) CPU-cores, which demonstrate the effectiveness of our proposal.},
  doi       = {10.1145/3384441.3395985},
  location  = {Miami, FL, USA},
}

@InProceedings{Alt20,
  author    = {Altamura, Lorenzo and Conoci, Stefano and Pellegrini, Alessandro},
  booktitle = {15th International Conference on High Performance and Embedded Architecture and Compilation Workshops},
  title     = {Asymmetric Computation for Speculative Heterogeneous HPC},
  year      = {2020},
  month     = jan,
  series    = {HiPEAC},
  abstract  = {HPC applications on future exascale systems will demand for runtime environments able to transparently manage the complexity of the underlying heterogeneous hardware. In this abstract, we discuss a computation model for speculative HPC applications, able to deliver non-minimal performance increase and significant energy savings. This model can be easily adapted to multiple heterogeneous hardware families with minor effort, and it can autonomically and promptly reassign units of work to different hardware classes. Our design jointly targets performance and energy efficiency. We also provide a preliminary experimental evaluation of our design.},
  location  = {Bologna, Italy},
}

@InProceedings{Car19,
  author    = {Carnà, Stefano and Ferracci, Serena and De Santis, Emanuele and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 2019 Winter Simulation Conference},
  title     = {Hardware-assisted Incremental Checkpointing in Speculative Parallel Discrete Event Simulation},
  year      = {2019},
  month     = dec,
  publisher = {IEEE},
  series    = {WSC},
  abstract  = {Nowadays hardware platforms offer a plethora of innovative facities for profiling the execution of programs. Most of them have been exploited as tools for program characterization, thus being used as kind of program-external observers. In this article we take the opposite perspective where hardware profiling facilities are exploited to execute core functional tasks for the correct and efficient execution of speculative Parallel Discrete Event Simulation (PDES) applications. In more detail we exploit them—specifically, the ones offered by Intel x86-64 processors—to build a hardware-supported incremental checkpointing solution that enables the reduction of the event-execution cost in speculative PDES compared to the software-based counterpart. We integrated our solution in the open source ROOT-Sim runtime environment, thus making it available for exploitation.},
  location  = {Washington, DC, USA},
}

@InProceedings{Pic19,
  author    = {Piccione, Andrea and Principe, Matteo and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 2019 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
  title     = {An Agent-Based Simulation API for Speculative PDES Runtime Environments},
  year      = {2019},
  month     = jun,
  pages     = {83--94},
  publisher = {ACM},
  series    = {PADS},
  abstract  = {Agent-Based Modeling and Simulation (ABMS) is an effective paradigm to model systems exhibiting complex interactions, also with the goal of studying the emergent behavior of these systems. While ABMS has been effectively used in many disciplines, many successful models are still run only sequentially. Relying on simple and easy-to-use languages such as NetLogo limits the possibility to benefit from more effective runtime paradigms, such as speculative Parallel Discrete Event Simulation (PDES). In this paper, we discuss a semantically-rich API allowing to implement Agent-Based Models in a simple and effective way. We also describe the critical points which should be taken into account to implement this API in a speculative PDES environment, to scale up simulations on distributed massively-parallel clusters. We present an experimental assessment showing how our proposal allows to implement complicated interactions with a reduced complexity, while delivering a non-negligible performance increase.},
  doi       = {10.1145/3316480.3322890},
  location  = {Chicago, IL, USA},
  badges    = {available,reusable},
}

@InProceedings{Mar19,
  author    = {Marotta, Romolo and Ianni, Mauro and Scarselli, Andrea and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 19th International Symposium on Cluster, Cloud and Grid Computing},
  title     = {NBBS: A Non-blocking Buddy System for Multi-core Machines},
  year      = {2019},
  month     = may,
  pages     = {11--20},
  publisher = {IEEE Computer Society},
  series    = {CCGrid},
  abstract  = {Common implementations of core memory allocation components, like the Linux buddy system, handle concurrent allocation/release requests by synchronizing threads via spinlocks. This approach is not prone to scale, a problem that has been addressed in the literature by introducing layered allocation services or replicating the core allocators—the bottom most ones within the layered architecture. Both these solutions tend to reduce the pressure of actual concurrent accesses to each individual core allocator. In this article we explore an alternative approach to scalability of memory allocation/release, which can be still combined with those literature proposals. We present a fully non-blocking buddy-system, where threads performing concurrent allocations/releases do not undergo any spin-lock based synchronization. Our solution allows threads to proceed in parallel, and commit their allocations/releases unless a conflict is materialized while handling the allocator metadata. Conflict detection relies on atomic Read-Modify-Write (RMW) machine instructions. Beyond improving scalability and performance, our solution can also avoid wasting clock cycles for spin-lock operations by threads that could in principle carry out their memory allocations/releases in full concurrency.},
  doi       = {10.1109/CCGRID.2019.00011},
  location  = {Larnaca, Cyprus},
}

@InProceedings{Eco18,
  author    = {Economo, Simone and Silvestri, Emiliano and Di Sanzo, Pierangelo and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 24th International Conference on Parallel and Distributed Systems},
  title     = {Model-based Proactive Read-validation in Transaction Processing Systems},
  year      = {2018},
  month     = dec,
  pages     = {481--488},
  publisher = {IEEE Computer Society},
  series    = {ICPADS},
  abstract  = {Concurrency control protocols based on read-validation schemes allow transactions which are doomed to abort to still run until a subsequent validation check reveals them as invalid. These late aborts do not favor the reduction of wasted computation and can penalize performance. To counteract this problem, we present an analytical model that predicts the abort probability of transactions handled via read-validation schemes. Our goal is to determine what are the suited points—along a transaction lifetime—to carry out a validation check. This may lead to early aborting doomed transactions, thus saving CPU time. We show how to exploit the abort probability predictions returned by the model in combination with a threshold-based scheme to trigger read-validations. We also show how this approach can definitely improve performance—leading up to 14% better turnaround—as demonstrated by some experiments carried out with a port of the TPC-C benchmark to Software Transactional Memory},
  doi       = {10.1109/PADSW.2018.8644605},
  location  = {Singapore},
}

@InProceedings{Ian18b,
  author    = {Ianni, Mauro and Marotta, Romolo and Cingolani, Davide and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 2018 Winter Simulation Conference},
  title     = {Optimizing Simulation on Shared-Memory Platforms: the Smart Cities Case},
  year      = {2018},
  month     = dec,
  pages     = {1969--1980},
  publisher = {IEEE Computer Society},
  series    = {WSC},
  abstract  = {Modern advancements in computing architectures have been accompanied by new emergent paradigms to run Parallel Discrete Event Simulation models efficiently. Indeed, many new paradigms to effectively use the available underlying hardware have been proposed in the literature. Among these, the Share-Everything paradigm tackles massively-parallel shared-memory machines, in order to support speculative simulation by taking into account the limits and benefits related to this family of architectures. Previous results have shown how this paradigm outperforms traditional speculative strategies (such as data-separated Time Warp systems) whenever the granularity of executed events is small. In this paper, we show performance implications of this simulation-engine organization when the simulation models have a variable granularity. To this end, we have selected a traffic model, tailored for smart cities-oriented simulation. Our assessment illustrates the effects of the various tuning parameters related to the approach, opening to a higher understanding of this innovative paradigm.},
  doi       = {10.1109/WSC.2018.8632301},
  location  = {Gothenburg, Sweden},
}

@InProceedings{Mar18,
  author    = {Marotta, Romolo and Ianni, Mauro and Scarselli, Andrea and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {{IEEE} International Conference on Cluster Computing},
  title     = {A Non-blocking Buddy System for Scalable Memory Allocation on Multi-core Machines},
  year      = {2018},
  month     = sep,
  pages     = {164--165},
  publisher = {IEEE Computer Society},
  series    = {CLUSTER},
  abstract  = {In this short paper we tackle the issue of scalability of core memory allocators, which is an orthogonal optimization with respect to reducing the pressure to core allocators by (a), (b), or (c). In particular, our contribution is the design of a non-blocking (lock-free) allocator implementing the buddy-system specification, where concurrent allocations/dellocations are not coordinated via spin-locks, but by only relying on individual Read-Modify-Write (RMW) instructions executed along the critical path of allocation/deallocation operations. These instructions are exploited to detect whether concurrent requests have conflicted on the same portion of the allocator metadata},
  doi       = {10.1109/CLUSTER.2018.00034},
  location  = {Belfast, UK},
}

@InProceedings{Ian18,
  author    = {Ianni, Mauro and Marotta, Romolo and Cingolani, Davide and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 2018 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
  title     = {The Ultimate Share-Everything PDES System},
  year      = {2018},
  month     = may,
  pages     = {73--84},
  publisher = {ACM},
  series    = {PADS},
  abstract  = {The share-everything PDES (Parallel Discrete Event Simulation) paradigm is based on fully sharing the possibility to process any individual event across concurrent threads, rather than binding Logical Processes (LPs) and their events to threads. It allows concentrating, at any time, the computing power—the CPU-cores on board of a shared-memory machine—towards the unprocessed events that stand closest to the current commit horizon of the simulation run. This fruitfully biases the delivery of the computing power towards the hot portion of the model execution trajectory. In this article we present an innovative share-everything PDES system that provides (1) fully non-blocking coordination of the threads when accessing shared data structures and (2) fully speculative processing capabilities—Time Warp style processing—of the events. As we show via an experimental study, our proposal can cope with hard workloads where both classical Time Warp systems—based on LPs to threads binding—and previous share-everything proposals—not able to exploit fully speculative processing of the events—tend to fail in delivering adequate performance.},
  doi       = {10.1145/3200921.3200931},
  location  = {Rome, Italy},
  badges    = {available,reusable,reproduced},
}

@InProceedings{Con18b,
  author    = {Conoci, Stefano and Cingolani, Davide and Di~Sanzo, Pierangelo and Pellegrini, Alessandro and Ciciani, Bruno and Quaglia, Francesco},
  booktitle = {Proceedings of the 2018 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
  title     = {A Power Cap Oriented Time Warp Architecture},
  year      = {2018},
  month     = may,
  pages     = {97--100},
  publisher = {ACM},
  series    = {PADS},
  abstract  = {Controlling power usage has become a core objective in modern computing platforms. In this article we present an innovative Time Warp architecture oriented to efficiently run parallel simulations under a power cap. Our architectural organization considers power usage as a foundational design principle, as opposed to classical power-unaware Time Warp design. We provide early experimental results showing the potential of our proposal.},
  doi       = {10.1145/3200921.3200930},
  location  = {Rome, Italy},
  badges    = {available,reusable,reproduced},
}

@InProceedings{Pri18,
  author    = {Principe, Matteo and Tocci, Tommaso and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 2018 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
  title     = {Porting Event \& Cross-State Synchronization to the Cloud},
  year      = {2018},
  month     = may,
  note      = {Shortlisted for the Best Paper Award},
  pages     = {177--188},
  publisher = {ACM},
  series    = {PADS},
  abstract  = {Along the years, Parallel Discrete Event Simulation (PDES) has been enriched with programming facilities to bypass state disjointness across the concurrent Logical Processes (LPs). New supports have been proposed, offering the programmer approaches alternative to message passing to code complex LPs’ relations. Along this path we find Event & Cross-State (ECS), which allows writing event handlers which can perform in-place accesses to the state of any LP, by simply relying on pointers. This programming model has been shipped with a runtime support enabling concurrent speculative execution of LPs limited to shared-memory machines. In this paper, we present the design of a middleware layer that allows ECS to be ported to distributed-memory clusters of machines. A core application of our middleware is to let ECS-coded models be hosted on top of (low-cost) resources from the Cloud. Overall, ECS-coded models no longer demand for powerful shared-memory machines to execute in reasonable time. Thanks to our solution, we retain indeed the possibility to rely on the enriched ECS programming model while still enabling deployments of PDES models on convenient (Cloudbased) infrastructures. An experimental assessment of our proposal is also provided.},
  doi       = {10.1145/3200921.3200929},
  location  = {Rome, Italy},
}

@InProceedings{Eco17,
  author    = {Economo, Simone and Silvestri, Emiliano and Di Sanzo, Pierangelo and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 16th IEEE International Symposium on Network Computing and Applications},
  title     = {Prompt Application-Transparent Transaction Revalidation in Software Transactional Memory},
  year      = {2017},
  month     = oct,
  pages     = {114--119},
  publisher = {IEEE Computer Society},
  series    = {NCA},
  abstract  = {Software Transactional Memory (STM) allows encapsulating shared-data accesses within transactions, executed with atomicity and isolation guarantees. The assessment of the consistency of a running transaction is performed by the STM layer at specific points of its execution, such as when a read or write access to a shared object occurs, or upon a commit attempt. However, performance and energy efficiency issues may arise when no shared-data read/write operation occurs for a while along a thread running a transaction. In this scenario, the STM layer may not regain control for a considerable amount of time, thus not being able to early detect if such transaction has become inconsistent in the meantime. To tackle this problem we present an STM architecture that, thanks to a lightweight operating system support, is able to perform a fine-grain periodic (hence prompt) revalidation of running transactions. Our proposal targets Linux and x86 systems and has been integrated with the open source TinySTM package. Experimental results with a port of the TPC-C benchmark to STM environments show the effectiveness of our solution.},
  doi       = {10.1109/NCA.2017.8171349},
  location  = {Cambridge, MA, USA},
}

@InProceedings{Avr17,
  author    = {Avresky, Dimiter R. and Pellegrini, Alessandro and Di Sanzo, Pierangelo},
  booktitle = {Proceedings of the 16th IEEE International Symposium on Network Computing and Applications},
  title     = {Machine Learning-based Management of Cloud Applications in Hybrid Clouds: a Hadoop Case Study},
  year      = {2017},
  month     = oct,
  pages     = {114--119},
  publisher = {IEEE Computer Society},
  series    = {NCA},
  abstract  = {This paper illustrates the effort to integrate a machine learning-based framework which can predict the remaining time to failure of computing nodes with Hadoop applications. This work is part of a larger effort targeting the development of a cloud-oriented autonomic framework to increase the availability of applications subject to software anomalies, and to jointly improve their performance. The framework uses machine-learning, software rejuvenation, and load distribution techniques to proactively prevent failures. We believe that this work allows to set a possible path towards the definition of best practices for the development of systems to support autonomic management of cloud applications, illustrating what are the issues that should be addressed by the research community. Indeed, given the scale and the complexity of modern computing infrastructures, effective autonomic management approaches of cloud applications are becoming mandatory.},
  doi       = {10.1109/NCA.2017.8171352},
  location  = {Cambridge, MA, USA},
}

@InProceedings{Toc17,
  author    = {Tocci, Tommaso and Pellegrini, Alessandro and Quaglia, Francesco and Casanovas-García, Josep and Suzumura, Toyotaro},
  booktitle = {Proceedings of the 21st IEEE/ACM International Symposium on Distributed Simulation and Real Time Applications},
  title     = {ORCHESTRA: An Asynchronous Wait-Free Distributed GVT Algorithm},
  year      = {2017},
  month     = oct,
  pages     = {51--58},
  publisher = {IEEE Computer Society},
  series    = {DS-RT},
  abstract  = {Taking advantage of computing capabilities oered by modern parallel and distributed architectures is fundamental to run large-scale simulation models based on the Parallel Discrete Event Simulation (PDES) paradigm. By relying on this computing organization, it is possible to eectively overcome both the power and the memory wall, which are core limiting aspects to deliver high-performance simulations. This is even more the case when relying on the speculative Time Warp synchronization protocol, which could be particularly memory greedy. At the same time, some form of coordination, such as the computation of the Global Virtual Time (GVT), is required by Time Warp Systems. These coordination points could easily become the bottleneck of large-scale simulations, hindering an efficient exploitation of the computing power oered by large supercomputing facilities. In this dissertation is presented ORCHESTRA, a coordination algorithm which is both wait-free and asynchronous. The nature of this algorithm allows any computing node to carry on simulation activities while the global agreement is reached, thus oering an eective building block to achieve scalable PDES. The general organization of ORCHESTRA could be adopted by different high-performance computing applications, thus paving the way to a more effective usage of modern computing infrastructures.},
  doi       = {10.1109/DISTRA.2017.8167666},
  location  = {Rome, Italy},
}

@InProceedings{Ian17c,
  author    = {Ianni, Mauro and Marotta, Romolo and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 21st IEEE/ACM International Symposium on Distributed Simulation and Real Time Applications},
  title     = {Towards a Fully Non-blocking Share-everything PDES Platform},
  year      = {2017},
  month     = oct,
  pages     = {25--32},
  publisher = {IEEE Computer Society},
  series    = {DS-RT},
  abstract  = {Shared-memory multi-core platforms are changing the nature of Parallel Discrete Event Simulation (PDES) because of the possibility to fully share the workload of events to be processed across threads. In this context, one rising PDES paradigm - referred to as share-everything PDES - is no longer based on the concept of (temporary) biding of simulation objects to worker threads. Rather, each worker threads can - at any time - pick from a fully shared event pool an event to process which can be destined to whatever simulation object. While attention has been posed on the design of concurrent shared pools, allowing non-blocking parallel operations, the scenario where two (or more) threads pick events destined to the same simulation object still lacks adequate synchronization support. In fact, these events are currently sequentialized and processed in a critical section touching the simulation object state, thus leading threads to mutually block each other. In this article we present the design of a share-everything speculative PDES engine that prevents mutual thread blocks because of the access to a same object state. In our design, the non-blocking property is seen as a vertical attribute of the engine (not only of the event pool). This vertical view demands for innovative event-dispatching schemes and, at the same time, innovative interactions with (and management of) the fully-shared event pool, which are features that we embed in our innovative design.},
  doi       = {10.1109/DISTRA.2017.8167663},
  location  = {Rome, Italy},
  name      = {ds-rt17c},
}

@InProceedings{Ian17b,
  author    = {Ianni, Mauro and Marotta, Romolo and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 21st IEEE/ACM International Symposium on Distributed Simulation and Real Time Applications},
  title     = {A Non-blocking Global Virtual Time Algorithm with Logarithmic Number of Memory Operations},
  year      = {2017},
  month     = oct,
  note      = {Shortlisted for the Best Paper Award},
  pages     = {17--24},
  publisher = {IEEE Computer Society},
  series    = {DS-RT},
  abstract  = {The increasing diffusion of shared-memory multi-core machines has given rise to a change in the design of Parallel Discrete Event Simulation (PDES) platforms. In particular, the possibility to share large amounts of memory by many worker threads has lead to a boost in the adoption of non-blocking coordination algorithms, which have been proven to offer higher scalability when compared to their blocking counterparts based on critical sections. In this article we present an innovative non-blocking algorithm for computing Global Virtual Time (GVT)---namely, the current commit horizon---in multi-thread PDES engines to be run on top of multi-core machines. Beyond being non-blocking, our proposal has the advantage of providing a logarithmic (rather than linear) number of per-thread memory operations---read/write operations of values involved in the reduction for computing the GVT value---vs the amount of threads participating in the GVT computation. This allows for keeping low the actual CPU time that is required for determining the new GVT value. We compare our algorithm with a literature solution, still based on the non-blocking approach, but entailing a linear number of memory operations, quantifying the advantages from our proposal especially for very large numbers of threads participating in the GVT computation.},
  doi       = {10.1109/DISTRA.2017.8167662},
  location  = {Rome, Italy},
  name      = {ds-rt17b},
}

@InProceedings{Ian17,
  author    = {Ianni, Mauro and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 2017 IEEE Cluster Conference},
  title     = {A Wait-free Multi-word Atomic (1,N) Register for Large-scale Data Sharing on Multi-core Machines},
  year      = {2017},
  month     = sep,
  pages     = {188--192},
  publisher = {IEEE Computer Society},
  series    = {CLUSTER},
  abstract  = {We present a multi-word atomic (1,N) register for multi-core machines exploiting Read-Modify-Write (RMW) instructions to coordinate the writer and the readers in a waitfree manner. Our proposal, called Anonymous Readers Counting (ARC), enables large-scale data sharing by admitting up to $2^{32} - 2$ concurrent readers on off-the-shelf 64-bit machines, as opposed to the most advanced RMW-based approach which is limited to 58 readers. Further, ARC avoids multiple copies of the register content while accessing it—this affects classical register’s algorithms based on atomic read/write operations on single words. Thus, ARC allows for higher scalability with respect to the register size.},
  doi       = {10.1109/CLUSTER.2017.84},
  location  = {Honolulu, HI, USA},
}

@InProceedings{Cin17,
  author    = {Cingolani, Davide and Pellegrini, Alessandro and Schordan, Markus and Quaglia, Francesco and Jefferson, David R.},
  booktitle = {Proceedings of the 2017 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
  title     = {Dealing with Reversibility of Shared Libraries in PDES},
  year      = {2017},
  month     = may,
  publisher = {ACM},
  series    = {PADS},
  abstract  = {State recoverability is a crucial aspect of speculative Time Warp-based Parallel Discrete Event Simulation. In the literature, we can identify three major classes of techniques to support the correct restoration of a previous simulation state upon the execution of a rollback operation: state checkpointing/restore, manual reverse computation and automatic reverse computation. The latter class has been recently supported by relying either on binary code instrumentation or on source-to-source code transformation. Nevertheless, both solutions are not intrinsically meant to support a reversible execution of third-party shared libraries, which can be pretty useful when implementing complex simulation models.
               In this paper, we present an architectural solution (realized as a static C library) which allows to transparently instrument at runtime any third party shared library, with no need for any modification to the model's code. We also present a preliminary experimental evaluation, based on the integration of our library with the ROOT-Sim simulation engine.},
  location  = {Singapore},
  name      = {pads17b},
}

@InProceedings{Mar17,
  author    = {Marotta, Romolo and Ianni, Mauro and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 2017 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
  title     = {A Conflict-Resilient Lock-Free Calendar Queue for Scalable Share-Everything PDES Platforms},
  year      = {2017},
  month     = may,
  pages     = {41--52},
  publisher = {ACM},
  series    = {PADS},
  abstract  = {Emerging share-everything Parallel Discrete Event Simulation (PDES) platforms rely on worker threads fully sharing the workload of events to be processed. These platforms require efficient event pool data structures enabling high concurrency of extraction/insertion operations. Non-blocking event pool algorithms are raising as promising solutions for this problem. However, the classical non-blocking paradigm leads concurrent conflicting operations, acting on a same portion of the event pool data structure, to abort and then retry. In this article we present a conflict-resilient non-blocking calendar queue that enables conflicting dequeue operations, concurrently attempting to extract the minimum element, to survive, thus improving the level of scalability of accesses to the hot portion of the data structure---namely the bucket to which the current locality of the events to be processed is bound. We have integrated our solution within an open source share-everything PDES platform and report the results of an experimental analysis of the proposed concurrent data structure compared to some literature solutions.},
  doi       = {10.1145/3064911.3064927},
  location  = {Singapore},
}

@InProceedings{Sil17,
  author    = {Silvestri, Emiliano and Economo, Simone and Di Sanzo, Pierangelo and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing},
  title     = {Preemptive Software Transactional Memory},
  year      = {2017},
  month     = may,
  publisher = {IEEE Computer Society},
  series    = {CCGrid},
  abstract  = {In state-of-the-art Software Transactional Memory (STM) systems, threads carry out the execution of transactions as non-interruptible tasks. Hence, a thread can react to the injection of a higher priority transactional task and take care of its processing only at the end of the currently executed transaction. In this article we pursue a paradigm shift where the execution of an in-memory transaction is carried out as a preemptable task, so that a thread can start processing a higher priority transactional task before finalizing its current transaction. We achieve this goal in an application-transparent manner, by only relying on Operating System facilities we include in our preemptive STM architecture. With our approach we are able to re-evaluate CPU assignment across transactions along a same thread every few tens of microseconds. This is mandatory for an effective priority-aware architecture given the typically finer-grain nature of in-memory transactions compared to their counterpart in database systems. We integrated our preemptive STM architecture with the TinySTM package, and released it as open source. We also provide the results of an experimental assessment of our proposal based on running a port of the TPC-C benchmark to the STM environment.},
  location  = {Madrid, Spian},
}

@Article{Pell17,
  author    = {Pellegrini, Alessandro and Di Sanzo, Pierangelo},
  journal   = {Wseas Transactions On Environment And Development},
  title     = {On the Optimization of Collaborative Kerbside Waste Collection},
  year      = {2017},
  month     = jan,
  abstract  = {In this paper, we target collaborative kerbside collection from a planning and real-time monitoring point of view. This is a non-trivial problem, where several vehicles are set on streets to finish a task—the collection of all waste—by a certain maximum amount of time. While deciding upon a collaborative strategy is a well-studied and complex problem by itself, we focus as well on re-planning, whenever live data collected by the vehicles suggest that the current scenario has deviated from the provisional plan, due to changes in external environmental factors. To this end, we propose a global mission-management architecture, which tries to optimize at once the time required to finish the waste collection, the distance traveled by the vehicles, the amount of fuel burnt (accounting as well for idle time at collection points), and the impact of pollutants emissions.},
  location  = {Rome, Italy},
  publisher = {WSEAS},
  series    = {EEESD},
}

@InProceedings{Pell16d,
  author    = {Pellegrini, Alessandro and Montañola-Sales, Cristina and Quaglia, Francesco and Casanovas-Garcia, Josep},
  booktitle = {Proceedings of the 2016 Winter Simulation Conference},
  title     = {Programming Agent-Based Demographic Models with Cross-State and Message-Exchange Dependencies: A Study with Speculative PDES and Automatic Load-Sharing},
  year      = {2016},
  month     = dec,
  publisher = {IEEE Computer Society},
  series    = {WSC},
  abstract  = {Agent-based modeling and simulation is a versatile and promising methodology to capture complex interactions among entities and their surrounding environment. A great advantage is its ability to model phenomena at a macro scale by exploiting simpler descriptions at a micro level. It has been proven effective in many fields, and it is rapidly becoming a de-facto standard in the study of population dynamics. In this article we study programmability and performance aspects of the last-generation ROOT-Sim speculative PDES environment for multi/many-core shared-memory architectures. ROOT-Sim transparently offers a programming model where interactions can be based on both explicit message passing and in-place state accesses. We introduce programming guidelines for systematic exploitation of these facilities in agent-based simulations, and we study the effects on performance of an innovative load-sharing policy targeting these types of dependencies. An experimental assessment with synthetic and real-world applications is provided, to assess the validity of our proposal.},
  location  = {Washington, D.C., USA},
}

@InProceedings{Mar16c,
  author    = {Marotta, Romolo and Ianni, Mauro and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 20th IEEE/ACM International Symposium on Distributed Simulation and Real Time Applications},
  title     = {A Lock-Free O(1) Event Pool and its Application to Share-Everything PDES Platforms},
  year      = {2016},
  month     = sep,
  note      = {Winner of the Best Paper Award},
  publisher = {IEEE Computer Society},
  series    = {DS-RT},
  abstract  = {The large diffusion of highly-parallel shared-memory multi-core machines has led Parallel Discrete Event Simulation (PDES) platforms to a shift towards a share-everything model. This model is based on loose coupling between simulation objects and threads, lasting (as an extreme) no more than the lifetime of individual events. Concurrent threads can therefore CPU-dispatch events destined to any object at any point in time, thus fully sharing the workload of events to be processed on a fine grain basis. This demands for efficient mechanisms to share the overall pool of pending events by enabling parallelism in insertion and extraction operations. In this article we present a lock-free event pool which also provides amortized O(1) time complexity for both insertions and extractions. It can sustain highly concurrent accesses, while not leading to noticeable performance degradation when scaling up the thread count. Experimental results demonstrate that our solution stands as a core facility capable of further raising up the pragmatical impact of such an emerging share-everything PDES paradigm.},
  doi       = {10.1109/DS-RT.2016.33},
  location  = {London, UK},
}

@InProceedings{Eco16,
  author    = {Economo, Simone and Cingolani, Davide and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 24th IEEE Internation Symposium on Modelling, Analysis and Simulation of Computer and Telecommunication Systems},
  title     = {Configurable and Efficient Memory Access Tracing via Selective Expression-based x86 Binary Instrumentation},
  year      = {2016},
  month     = sep,
  publisher = {IEEE Computer Society},
  series    = {MASCOTS},
  abstract  = {Memory access tracing is a program analysis technique with many different applications, ranging from architectural simulation to (on-line) data placement optimization and security enforcement. In this article we propose a memory access tracing approach based on static x86 binary instrumentation. Unlike non-selective schemes, which instrument all the memory access instructions, our proposal selectively instruments a subset of those instructions that are the most (or fully) representative of the actual memory access pattern. The selection of the memory access instructions to be instrumented is based on a new method, which clusters instructions on the basis of their compile/link-time observable address expressions and selects representatives of these clusters. This allows for reducing the runtime cost for running instrumented code, while still enabling high accuracy in the determination of memory accesses. The trade-off between overhead and precision of the tracing process is user-tunable, so that it can be set depending on the final objective of memory access tracing (say on-line vs off-line exploitation). Additionally, our approach can track memory access at different granularity (e.g., virtual-pages or cache line-sized buffers), thus having applications in a variety of different contexts. The effectiveness of our proposal is demonstrated via experiments with applications taken from the PARSEC benchmark suite.},
  doi       = {10.1109/MASCOTS.2016.69},
  location  = {London, UK},
}

@InProceedings{Pell16e,
  author    = {Pellegrini, Alessandro and Montañola-Sales, Cristina and Quaglia, Francesco and Casanovas-Garcia, Josep},
  booktitle = {Proceedings of the 4th Workshop on Parallel and Distributed Agent-Based Simulations},
  title     = {Load-Sharing Policies in Parallel Simulation of Agent-Based Demographic Models},
  year      = {2016},
  month     = aug,
  pages     = {334--346},
  publisher = {LNCS, Springer-Verlag},
  series    = {PADABS},
  abstract  = {Execution parallelism in agent-Based Simulation (ABS) allows to deal with complex/large-scale models. This raises the need for runtime environments able to fully exploit hardware parallelism, while jointly offering ABS-suited programming abstractions. In this paper, we target last-generation Parallel Discrete Event Simulation (PDES) platforms for multicore systems. We discuss a programming model to support both implicit (in-place access) and explicit (message passing) interactions across concurrent Logical Processes (LPs). We discuss different load-sharing policies combining event rate and implicit/explicit LPs’ interactions. We present a performance study conducted on a synthetic test case, representative of a class of agent-based models.},
  doi       = {10.1007/978-3-319-58943-5_27},
  location  = {Grenoble, France},
}

@InProceedings{Mar16b,
  author    = {Marotta, Romolo and Ianni, Mauro and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 9th EAI International Conference on Simulation Tools and Techniques},
  title     = {A Non-Blocking Priority Queue for the Pending Event Set},
  year      = {2016},
  month     = aug,
  pages     = {46--55},
  publisher = {ICST},
  series    = {SIMUTools},
  abstract  = {The large diffusion of shared-memory multi-core machines has impacted the way Parallel Discrete Event Simulation (PDES) engines are built. While they were originally conceived as data-partitioned platforms, where each thread is in charge of managing a subset of simulation objects, nowadays the trend is to shift towards share-everything settings. In this scenario, any thread can (in principle) take care of CPU-dispatching pending events bound to whichever simulation object, which helps to fully share the load across the available CPU-cores. Hence, a fundamental aspect to be tackled is to provide an efficient globally-shared pending events' set from which multiple worker threads can concurrently extract events to be processed, and into which they can concurrently insert new produced events to be processed in the future. To cope with this aspect, we present the design and implementation of a concurrent non-blocking pending events' set data structure, which can be seen as a variant of a classical calendar queue. Early experimental data collected with a synthetic stress test are reported, showing excellent scalability of our proposal on a machine equipped with 32 CPU-cores.},
  location  = {Prague, Czech Republic},
}

@InProceedings{Pell16c,
  author    = {Pellegrini, Alessandro},
  booktitle = {Proceedings of the 2016 International Conference on High Performance Computing \& Simulation Workshops},
  title     = {Optimizing Memory Management for Optimistic Simulation with Reinforcement Learning},
  year      = {2016},
  month     = jul,
  pages     = {26--33},
  publisher = {IEEE Computer Society},
  series    = {HPCS},
  abstract  = {Simulation is a powerful technique to explore complex scenarios and analyze systems related to a wide range of disciplines. To allow for an efficient exploitation of the available computing power, speculative Time Warp-based Parallel Discrete Event Simulation is universally recognized as a viable solution. In this context, the rollback operation is a fundamental building block to support a correct execution even when causality inconsistencies are a posteriori materialized. If this operation is supported via checkpoint/restore strategies, memory management plays a fundamental role to ensure high performance of the simulation run. With few exceptions, adaptive protocols targeting memory management for Time Warp-based simulations have been mostly based on a pre-defined analytic models of the system, expressed as a closed-form functions that map system's state to control parameters. The underlying assumption is that the model itself is optimal. In this paper, we present an approach that exploits reinforcement learning techniques. Rather than assuming an optimal control strategy, we seek to find the optimal strategy through parameter exploration. A value function that captures the history of system feedback is used, and no a-priori knowledge of the system is required. An experimental assessment of the viability of our proposal is also provided for a mobile cellular system simulation.},
  doi       = {10.1109/HPCSim.2016.7568312},
  location  = {Innsbruck, Austria},
}

@InProceedings{Cin16,
  author    = {Cingolani, Davide and Ianni, Mauro and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 8th Conference on Reversible Computation},
  title     = {Mixing Hardware and Software Reversibility for Speculative Parallel Discrete Event Simulation},
  year      = {2016},
  month     = jul,
  pages     = {137--152},
  publisher = {Springer-Verlag},
  series    = {RC},
  abstract  = {Speculative parallel discrete event simulation requires a support for reversing processed events, also called state recovery, when causal inconsistencies are revealed. In this article we present an approach where state recovery relies on a mix of hardware- and software-based techniques. We exploit the Hardware Transactional Memory (HTM) support, as offered by Intel Haswell CPUs, to process events as in-memory transactions, which are possibly committed only after their causal consistency is verified. At the same time, we exploit an innovative software-based reversibility technique, fully relying on transparent software instrumentation targeting x86/ELF objects, which enables undoing side effects by events with no actual backward re-computation. Each thread within our speculative processing engine dynamically (on a per-event basis) selects which recovery mode to rely on (hardware vs software) depending on varying runtime dynamics. The latter are captured by a lightweight analytic model indicating to what extent the HTM support (not paying any instrumentation cost) is efficient, and after what level of events’ parallelism it starts degrading its performance, e.g., due to excessive data conflicts while manipulating causality meta-data within HTM-based transactions. We released our implementation as open source software and provide experimental results for an assessment of its effectiveness.},
  doi       = {10.1007/978-3-319-40578-0_9},
  location  = {Bologna, Italy},
}

@InProceedings{LaR16,
  author    = {La Rizza, Andrea and Casarano, Giuseppe and Castellani, Gilberto and Ciciani, Bruno and Passalacqua, Luca and Pellegrini, Alessandro},
  booktitle = {Proceedings of the 2016 IEEE 36th International Conference on Distributed Computing Systems Workshops},
  title     = {Machine Learning-based Elastic Cloud Resource Provisioning in the Solvency II Framework},
  year      = {2016},
  month     = jun,
  pages     = {44--48},
  publisher = {IEEE Computer Society},
  series    = {ICDCS},
  abstract  = {The Solvency II Directive (Directive 2009/138/EC) is a European Directive issued in November 2009 and effective from January 2016, which has been enacted by the European Union to regulate the insurance and reinsurance sector through the discipline of risk management. Solvency II requires European insurance companies to conduct consistent evaluation and continuous monitoring of risks-a process which is computationally complex and extremely resource-intensive. To this end, companies are required to equip themselves with adequate IT infrastructures, facing a significant outlay. In this paper we present the design and the development of a Machine Learning-based approach to transparently deploy on a cloud environment the most resource-intensive portion of the Solvency II-related computation. Our proposal targets DISAR(R), a Solvency II-oriented system initially designed to work on a grid of conventional computers. We show how our solution allows to reduce the overall expenses associated with the computation, without hampering the privacy of the companies' data (making it suitable for conventional public cloud environments), and allowing to meet the strict temporal requirements required by the Directive. Additionally, the system is organized as a self-optimizing loop, which allows to use information gathered from actual (useful) computations, thus requiring a shorter training phase. We present an experimental study conducted on Amazon EC2 to assess the validity and the efficiency of our proposal.},
  doi       = {10.1109/ICDCSW.2016.31},
  location  = {Nara, Japan},
}

@InProceedings{Pell16,
  author    = {Pellegrini, Alessandro and Di Sanzo, Pierangelo and Avresky, Dimiter R.},
  booktitle = {Proceedings of the 21st IEEE Workshop on Dependable Parallel, Distributed and Network-Centric Systems},
  title     = {Proactive Cloud Management for Highly Heterogeneous Multi-Cloud Infrastructures},
  year      = {2016},
  month     = may,
  pages     = {1311--1318},
  publisher = {IEEE Computer Society},
  series    = {DPDNS},
  abstract  = {Various literature studies demonstrated that the cloud computing paradigm can help to improve availability and performance of applications subject to the problem of software anomalies. Indeed, the cloud resource provisioning model enables users to rapidly access new processing resources, even distributed over different geographical regions, that can be promptly used in the case of, e.g., crashes or hangs of running machines, as well as to balance the load in the case of overloaded machines. Nevertheless, managing a complex geographically-distributed cloud deploy could be a complex and time-consuming task. Autonomic Cloud Manager (ACM) Framework is an autonomic framework for supporting proactive management of applications deployed over multiple cloud regions. It uses machine learning models to predict failures of virtual machines and to proactively redirect the load to healthy machines/cloud regions. In this paper, we study different policies to perform efficient proactive load balancing across cloud regions in order to mitigate the effect of software anomalies. These policies use predictions about the mean time to failure of virtual machines. We consider the case of heterogeneous cloud regions, i.e regions with different amount of resources, and we provide an experimental assessment of these policies in the context of ACM Framework.},
  doi       = {10.1109/IPDPSW.2016.124},
  location  = {Chicago, IL, USA},
}

@InProceedings{Mar16,
  author    = {Marziale, Nazzareno and Nobilia, Francesco and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 2016 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
  title     = {Granular Time Warp Objects},
  year      = {2016},
  month     = may,
  pages     = {57--68},
  publisher = {ACM},
  series    = {PADS},
  abstract  = {A recent trend has shown the relevance of PDES paradigms where simulation objects are no longer seen as fully disjoint entities only interacting via events' scheduling. Particularly, mutual cross-state access (as a form of state sharing) can represent an approach enabling the simplification of the programmer's job. In this article, we present a multi-core oriented Time Warp platform supporting so called granular objects, where cross-state access is transparently enabled jointly with the dynamic clustering (granulation) of objects into groups depending on the volume of mutual state accesses along phases of the model execution. Each group represents an island where activities are sequentially dispatched in timestamp order. Concurrency is still preserved by enabling the optimistic execution of the different islands. Granulated objects do not pay synchronization costs due to mutual causal inconsistencies. Also, the underlying Time Warp platform does not pay memory management (e.g. memory access tracing) overheads to determine that mutual accesses are taking place within a group. Overall, the platform transparently (and dynamically) determines a well-suited granulation of the overall model state, and a corresponding level of concurrency, depending on the actual state access pattern by the simulation code. As far as we know, this is the first study where the problem of clustering Time Warp simulation objects is addressed for the case of in-place cross-object state accesses by the application code, and where dynamic granulation of multiple objects in a larger one is supported in a fully transparent manner. We integrated our proposal in the open source ROOT-Sim platform.},
  doi       = {10.1145/2901378.2901390},
  location  = {Banff, Canada},
}

@InProceedings{DiG16,
  author    = {Di Gennaro, Ilaria and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 16th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing},
  title     = {OS-based NUMA Optimization: Tackling the Case of Truly Multi-thread Applications with Non-Partitioned Virtual Page Accesses},
  year      = {2016},
  month     = may,
  pages     = {292--300},
  publisher = {IEEE Computer Society},
  series    = {CCGrid},
  abstract  = {A common approach to improve memory access in NUMA machines exploits operating system (OS) page protection mechanisms to induce faults to determine which pages are accessed by what thread, so as to move the thread and its working-set of pages to the same NUMA node. However, existing proposals do not fully fit the requirements of truly multi-thread applications with non-partitioned accesses to virtual pages. In fact, these proposals exploit (induced) faults on a same page-table for all the threads of a same process to determine the access pattern. Hence, the fault by one thread (and the consequent re-opening of the access to the corresponding page) would mask those by other threads on the same page. This may lead to inaccuracy in the estimation of the working-set of individual threads. We overcome this drawback by presenting a lightweight operating system support for Linux, referred to as multi-view address space, explicitly targeting accuracy of per-thread working-set estimation in truly multi-thread applications with non-partitioned accesses, and an associated thread/data migration policy. Our solution is fully transparent to user-space code. It is embedded in a Linux/x86_64 module that installs any required modification to the original kernel image by solely relying on dynamic patching. A motivated case study in the context of HPC is also presented for an assessment of our proposal.},
  doi       = {10.1109/CCGrid.2016.91},
  location  = {Cartagena, Colombia},
}

@InProceedings{Bus15,
  author    = {Büsing-Menses, Vanessa and Montañola-Sales, Cristina and Casanovas-Garcia, Josep and Pellegrini, Alessandro},
  booktitle = {Proceedings of the 2015 Winter Simulation Conference},
  title     = {Analysis and Optimization of a Demographic Simulator for Parallel Environments (poster paper)},
  year      = {2015},
  month     = dec,
  pages     = {3218--3219},
  publisher = {IEEE Computer Society},
  series    = {WSC},
  abstract  = {In the past years, the advent of multi-core machines has led to the need for adapting current simulation solutions to modern hardware architectures. In this poster, we present a solution to exploit multicore shared-memory capacities in Yades, a parallel tool for running socio-demography dynamic simulations. We propose to abandon the single-threaded programming approach addresses in Yades by using ROOT-Sim, a library which allows to apply discrete event simulation to parallel environments profiting share-memory capabilities. As a result of this new approach, our results show the improvement in Yades' performance and scalability.},
  doi       = {10.1109/WSC.2015.7408478},
  location  = {Huntington Beach, CA, USA},
}

@InProceedings{San15,
  author    = {Santini, Emanuele and Ianni, Mauro and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 22nd International Conference on High Performance Computing},
  title     = {Hardware-Transactional-Memory Based Speculative Parallel Discrete Event Simulation of Very Fine Grain Models},
  year      = {2015},
  month     = dec,
  pages     = {145--154},
  publisher = {IEEE Computer Society},
  series    = {HiPC},
  abstract  = {This article presents an innovative runtime support for speculative parallel processing of discrete event simulation models on multi-core architectures, which exploits Hardware-Transactional-Memory (HTM) facilities for the purpose of state recoverability. In this proposal, the speculative updates on the state of the simulation model are executed as concurrent HTM-based transactions that are also in charge of detecting whether the update is consistent with the advancement of logical-time along model execution. Our proposal is fully transparent to the application code. Hence, our HTM-based run-time support can host conventionally developed discrete event models relying on the concept of event-handlers to be dispatched by an underlying simulation engine. Experimental data show that our proposal provides 75% to 92% of the ideal speedup on an Intel Haswell based platform (equipped with 4 physical cores and HTM support) for discrete event models with event granularity ranging between 2 and 12 microseconds. The data also show that these same models cannot be executed efficiently on top of a last generation parallel discrete event simulation platform employing software-based recoverability.},
  doi       = {10.1109/HiPC.2015.45},
  location  = {Bengaluru, India},
}

@InProceedings{Avr15,
  author    = {Avresky, Dimiter R. and Di Sanzo, Pierangelo and Pellegrini, Alessandro and Ciciani, Bruno and Forte, Luca},
  booktitle = {Proceedings of the 14th IEEE International Symposium on Network Computing and Applications},
  title     = {Proactive Scalability and Management of Resources in Hybrid Clouds via Machine Learning (short paper)},
  year      = {2015},
  month     = sep,
  pages     = {114--119},
  publisher = {IEEE Computer Society},
  series    = {NCA},
  abstract  = {In this paper, we present a novel framework for supporting the management and optimization of application subject to software anomalies and deployed on large scale cloud architectures, composed of different geographically distributed cloud regions. The framework uses machine learning models for predicting failures caused by accumulation of anomalies. It introduces a novel workload balancing approach and a proactive system scale up/scale down technique. We developed a prototype of the framework and present some experiments for validating the applicability of the proposed approaches.},
  doi       = {10.1109/NCA.2015.36},
  location  = {Boston, MA, USA},
}

@InProceedings{Cin15b,
  author    = {Cingolani, Davide and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 3rd Workshop on Parallel and Distributed Agent-Based Simulations},
  title     = {{RAMSES}: Reversibility-based Agent Modeling and Simulation Environment with Speculation support},
  year      = {2015},
  month     = aug,
  pages     = {466--478},
  publisher = {LNCS, Springer-Verlag},
  series    = {PADABS},
  abstract  = {This paper presents RAMSES, a framework for easily specifying agent-based discrete event models entailing both environment and agent entities. RAMSES offers parallel execution capabilities based on speculative event processing and an innovative software reversibility technique that copes with state restore in case the run slides along a non-consistent speculative path. Reversibility in RAMSES relies on transparent static software instrumentation, thus allowing the model developer to concentrate on the actual forward-execution logic of the simulation events occurring in the system. An experimental assessment of RAMSES is also presented, which is aimed at determining its run-time effectiveness and its potential for simplifying the development of agent-based models when compared to other (general purpose) speculative frameworks for parallel discrete event simulation.},
  doi       = {10.1007/978-3-319-27308-2_38},
  isbn      = {978-3-319-27307-5},
  location  = {Vienna, Austria},
}

@InProceedings{DiS15b,
  author    = {Di Sanzo, Pierangelo and Pellegrini, Alessandro and Avresky, Dimiter R.},
  booktitle = {Proceedings of the Fourth IEEE Symposium on Network Cloud Computing and Applications},
  title     = {Machine Learning for Achieving Self-* Properties and Seamless Execution of Applications in the Cloud},
  year      = {2015},
  month     = jun,
  pages     = {51--58},
  publisher = {IEEE Computer Society},
  series    = {NCCA},
  abstract  = {Software anomalies are recognized as a major problem affecting the performance and availability of many computer systems. Accumulation of anomalies of different nature, such as memory leaks and unterminated threads, may lead the system to both fail or work with suboptimal performance levels. This problem particularly affects web servers, where hosted applications are typically intended to continuously run, thus incrementing the probability, therefore the associated effects, of accumulation of anomalies. Given the unpredictability of occurrence of anomalies, continuous system monitoring would be required to detect possible system failures and/or excessive performance degradation in order to timely start some recovering procedure. In this paper, we present a Machine Learning-based framework for proactive management of client-server applications in the cloud. Through optimized Machine Learning models and continually measuring system features, the framework predicts the remaining time to the occurrence of some unexpected event (system failure, service level agreement violation, etc.) of a virtual machine hosting a server instance of the application. The framework is able to manage virtual machines in the presence of different types anomalies and with different anomaly occurrence patterns. We show the effectiveness of the proposed solution by presenting results of a set of experiments we carried out in the context of a real world-inspired scenario.},
  doi       = {10.1109/NCCA.2015.18},
  isbn      = {978-1-4673-7741-6},
  location  = {Munich, Germany},
}

@InProceedings{Cin15,
  author    = {Cingolani, Davide and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 2015 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
  title     = {Transparently Mixing Undo Logs and Software Reversibility for State Recovery in Optimistic PDES},
  year      = {2015},
  month     = jun,
  pages     = {211--222},
  publisher = {ACM},
  series    = {PADS},
  abstract  = {The rollback operation is a fundamental building block to support the correct execution of a speculative Time Warp-based Parallel Discrete Event Simulation. In the literature, several solutions to reduce the execution cost of this operation have been proposed, either based on the creation of a checkpoint of previous simulation state images, or on the execution of negative copies of simulation events which are able to undo the updates on the state. In this paper, we explore the practical design and implementation of a state recoverability technique which allows to restore a previous simulation state either relying on checkpointing or on the reverse execution of the state updates occurred while processing events in forward mode. Differently from other proposals, we address the issue of executing backward updates in a fully-transparent and event granularity-independent way, by relying on static software instrumentation (targeting the x86 architecture and Linux systems) to generate at runtime reverse update code blocks (not to be confused with reverse events, proper of the reverse computing approach). These are able to undo the effects of a forward execution while minimizing the cost of the undo operation. We also present experimental results related to our implementation, which is released as free software and fully integrated into the open source ROOT-Sim (ROme OpTimistic Simulator) package. The experimental data support the viability and effectiveness of our proposal.},
  doi       = {10.1145/2769458.2769482},
  location  = {London, UK},
  name      = {pads15m},
}

@InProceedings{Pell15c,
  author    = {Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 2015 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
  title     = {NUMA Time Warp},
  year      = {2015},
  month     = jun,
  pages     = {59--70},
  publisher = {ACM},
  series    = {PADS},
  abstract  = {It is well known that Time Warp may suffer from large usage of memory, which may hamper the efficiency of the memory hierarchy. To cope with this issue, several approaches have been devised, mostly based on the reduction of the amount of used virtual memory, e.g., by the avoidance of checkpointing and the exploitation of reverse computing. In this article we present an orthogonal solution aimed at optimizing the latency for memory access operations when running Time Warp systems on Non-Uniform Memory Access (NUMA) multi-processor/multi-core computing systems. More in detail, we provide an innovative Linux-based architecture allowing per simulation-object management of memory segments made up by disjoint sets of pages, and supporting both static and dynamic binding of the memory pages reserved for an individual object to the different NUMA nodes, depending on what worker thread is in charge of running that simulation object along a given wall-clock-time window. Our proposal not only manages the virtual pages used for the live state image of the simulation object, rather, it also copes with memory pages destined to keep the simulation object's event buffers and any recoverability data. Further, the architecture allows memory access optimization for data (messages) exchanged across the different simulation objects running on the NUMA machine. Our proposal is fully transparent to the application code, thus operating in a seamless manner. Also, a free software release of our NUMA memory manager for Time Warp has been made available within the open source ROOT-Sim simulation platform. Experimental data for an assessment of our innovative proposal are also provided in this article.},
  doi       = {10.1145/2769458.2769479},
  isbn      = {978-1-4503-3583-6},
  location  = {London, UK},
  name      = {pads15n},
}

@InProceedings{Pell15b,
  author    = {Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 2015 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
  title     = {Time-Sharing Time Warp via Lightweight Operating System Support},
  year      = {2015},
  month     = jun,
  pages     = {47--58},
  publisher = {ACM},
  series    = {PADS},
  abstract  = {The order according to which the different tasks are carried out within a Time Warp platform has a direct impact on performance, given that event processing is speculative, thus being subject to the possibility of being rolled-back. It is typically recognized that not-yet-executed events having lower timestamps should be given higher CPU-schedule priority, since this contributes to keep low the amount of rollbacks. However, common Time Warp platforms usually execute events as atomic actions. Hence control is bounced back to the underlying simulation platform only at the end of the current event processing routine. In other words, CPU-scheduling of events resembles classical batch-multitasking scheduling, which is recognized not to promptly react to variations of the priority of pending tasks (e.g. associated with the injection of new events in the system). In this article we present the design and implementation of a time-sharing Time Warp platform, to be run on multi-core machines, where the platform-level software is allowed to take back control on a periodical basis (with fine grain period), and to possibly preempt any ongoing event processing activity in favor of dispatching (along the same thread) any other event that is revealed to have higher priority. Our proposal is based on an ad-hoc kernel module for Linux, which implements a fine grain timer-interrupt mechanism with lightweight management, which is fully integrated with the modern top/bottom-half timer-interrupt Linux architecture, and which does not induce any bias in terms of relative CPU-usage planning across Time Warp vs non-Time Warp threads running on the machine. Our time-sharing architecture has been integrated within the open source ROOT-Sim optimistic simulation package, and we also report some experimental data for an assessment of our proposal.},
  doi       = {10.1145/2769458.2769478},
  location  = {London, UK},
  name      = {pads15t},
}

@InProceedings{Pell15,
  author    = {Pellegrini, Alessandro and Di Sanzo, Pierangelo and Avresky, Dimiter R.},
  booktitle = {Proceedings of the 20th IEEE Workshop on Dependable Parallel, Distributed and Network-Centric Systems},
  title     = {A Machine Learning-based Framework for Building Application Failure Prediction Models},
  year      = {2015},
  month     = may,
  pages     = {1072--1081},
  publisher = {IEEE Computer Society},
  series    = {DPDNS},
  abstract  = {In this paper, we present the Framework for building Failure Prediction Models (F2PM), a Machine Learning-based Framework to build models for predicting the Remaining Time to Failure (RTTF) of applications in the presence of software anomalies. F2PMuses measurements of a number of system features in order to create a knowledge base, which is then used to build prediction models. F2PM is application-independent, i.e. It solely exploits measurements of system-level features. Thus, it can be used in differentiated contexts, without the need for any manual modification or intervention to the running applications. To generate optimized models, F2PM can perform a feature selection to identify, among all the measured system features, which have a major impact in the prediction of the RTTF. This allows to produce different models, which use different set of input features. Generated models can be compared by the user by using a set of metrics produced by F2PM, which are related to the model prediction accuracy, as well as to the model building time. We also present experimental results of a successful application of F2PM, using the standard TPC-W e-commerce benchmark.},
  doi       = {10.1109/IPDPSW.2015.110},
  location  = {Hyderabad, India},
}

@InProceedings{Pell14c,
  author    = {Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 26th International Conference on Computer Architecture and High Performance Computing},
  title     = {Wait-Free {Global Virtual Time} Computation in Shared Memory {Time-Warp} Systems},
  year      = {2014},
  month     = oct,
  pages     = {9--16},
  publisher = {IEEE Computer Society},
  series    = {SBAC-PAD},
  abstract  = {Global Virtual Time (GVT) is a powerful abstraction used to discriminate what events belong (and what do not belong) to the past history of a parallel/distributed computation. For high performance simulation systems based on the Time Warp synchronization protocol, where concurrent simulation objects are allowed to process their events speculatively and causal consistency is achieved via rollback/recovery techniques, GVT is used to determine which portion of the simulation can be considered as committed. Hence it is the base for actuating memory recovery (e.g. of obsolete logs that were taken in order to support state recoverability) and nonrevocable operations (e.g. I/O). For shared memory implementations of simulation platforms based on the Time Warp protocol, the reference GVT algorithm is the one presented by Fujimoto and Hybinette [1]. However, this algorithm relies on critical sections that make it non-wait-free, and which can hamper scalability. In this article we present a waitfree shared memory GVT algorithm that requires no critical section. Rather, correct coordination across the processes while computing the GVT value is achieved via memory atomic operations, namely compare-and-swap. The price paid by our proposal is an increase in the number of GVT computation phases, as opposed to the single phase required by the proposal in [1]. However, as we show via the results of an experimental study, the wait-free nature of the phases carried out in our GVT algorithm pays-off in reducing the actual cost incurred by the proposal in [1].},
  doi       = {10.1109/SBAC-PAD.2014.38},
  location  = {Paris, France},
}

@InProceedings{Pell14b,
  author    = {Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 2nd Workshop on Parallel and Distributed Agent-Based Simulations},
  title     = {Programmability and Performance of Parallel {ECS}-based Simulation of Multi-Agent Exploration Models},
  year      = {2014},
  month     = aug,
  pages     = {395--406},
  publisher = {LNCS, Springer-Verlag},
  series    = {PADABS},
  abstract  = {While the traditional objective of parallel/distributed simulation techniques has been mainly in improving performance and making very large models tractable, more recent research trends targeted complementary aspects, such as the “ease of programming”. Along this line, a recent proposal called Event and Cross State (ECS) synchronization, stands as a solution allowing to break the traditional programming rules proper of Parallel Discrete Event Simulation (PDES) systems, where the application code processing a specific event is only allowed to access the state (namely the memory image) of the target simulation object. In fact with ECS, the programmer is allowed to write ANSI-C event-handlers capable of accessing (in either read or write mode) the state of whichever simulation object included in the simulation model. Correct concurrent execution of events, e.g., on top of multi-core machines, is guaranteed by ECS with no intervention by the programmer, who is in practice exposed to a sequential-style programming model where events are processed one at a time, and have the ability to access the current memory image of the whole simulation model, namely the collection of the states of any involved object. This can strongly simplify the development of specific models, e.g., by avoiding the need for passing state information across concurrent objects in the form of events. In this article we investigate on both programmability and performance aspects related to developing/supporting a multi-agent exploration model on top of the ROOT-Sim PDES platform, which supports ECS.},
  doi       = {10.1007/978-3-319-14325-5_34},
  location  = {Porto, Portugal},
}

@InProceedings{Pell14,
  author    = {Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 2014 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
  title     = {Transparent Multi-Core Speculative Parallelization of {DES} Models with Event and Cross-State Dependencies},
  year      = {2014},
  month     = may,
  pages     = {105--116},
  publisher = {ACM},
  series    = {PADS},
  abstract  = {In this article we tackle transparent parallelization of Discrete Event Simulation (DES) models to be run on top of multi-core machines according to speculative schemes. The innovation in our proposal lies in that we consider a more general programming and execution model, compared to the one targeted by state of the art PDES platforms, where the boundaries of the state portion accessible while processing an event at a specific simulation object do not limit access to the actual object state, or to shared global variables. Rather, the simulation object is allowed to access (and alter) the state of any other object, thus causing what we term cross-state dependency. We note that this model exactly complies with typical (easy to manage) sequential-style DES programming, where a (dynamically-allocated) state portion of object A can be accessed by object B in either read or write mode (or both) by, e.g., passing a pointer to B as the payload of a scheduled simulation event. However, while read/write memory accesses performed in the sequential run are always guaranteed to observe (and to give rise to) a consistent snapshot of the state of the simulation model, consistency is not automatically guaranteed in case of parallelization and concurrent execution of simulation objects with cross-state dependencies. We cope with such a consistency issue, and its application-transparent support, in the context of parallel and optimistic executions. This is achieved by introducing an advanced memory management architecture, able to efficiently detect read/write accesses by concurrent objects to whichever object state in an application transparent manner, together with advanced synchronization mechanisms providing the advantage of exploiting parallelism in the underlying multi-core architecture while transparently handling both cross-state and traditional event-based dependencies. Our proposal targets Linux and has been integrated with the ROOT-Sim open source optimistic simulation platform, although its design principles, and most parts of the developed software, are of general relevance.},
  doi       = {10.1145/2601381.2601398},
  location  = {Denver, Colorado, USA},
}

@InProceedings{Rug14,
  author    = {Rughetti, Diego and Di Sanzo, Pierangelo and Pellegrini, Alessandro},
  booktitle = {Proceedings of the Third IEEE Symposium on Network Cloud Computing and Applications},
  title     = {Adaptive Transactional Memories: Performance and Energy Consumption Tradeoffs},
  year      = {2014},
  month     = feb,
  pages     = {105--112},
  publisher = {IEEE Computer Society},
  series    = {NCCA},
  abstract  = {Energy efficiency is becoming a pressing issue, especially in large data centers where it entails, at the same time, a non-negligible management cost, an enhancement of hardware fault probability, and a significant environmental footprint. In this paper, we study how Software Transactional Memories (STM)can provide benefits on both power saving and the overall applications' execution performance. This is related to the fact that encapsulating shared-data accesses within transactions gives the freedom to the STM middleware to both ensure consistency and reduce the actual data contention, the latter having been shown to affect the overall power needed to complete the application's execution. We have selected a set of self-adaptive extensions to existing STM middle wares (namely, TinySTM and R-STM) to prove how self-adapting computation can capture the actual degree of parallelism and/or logical contention on shared data in a better way, enhancing even more the intrinsic benefits provided by STM. Of course, this benefit comes at a cost, which is the actual execution time required by the proposed approaches to precisely tune the execution parameters for reducing power consumption and enhancing execution performance. Nevertheless, the results hereby provided show that adaptively is a strictly necessary requirement to reduce energy consumption in STM systems: Without it, it is not possible to reach any acceptable level of energy efficiency at all.},
  doi       = {10.1109/NCCA.2014.25},
  location  = {Rome, Italy},
}

@InProceedings{Pell13d,
  author    = {Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 1st Workshop on Parallel and Distributed Agent-Based Simulations},
  title     = {The {ROme OpTimistic Simulator}: A Tutorial},
  year      = {2013},
  month     = aug,
  pages     = {501--512},
  publisher = {LNCS, Springer-Verlag},
  series    = {PADABS},
  abstract  = {In this tutorial we present the ROme OpTimistic Simulator (ROOT-Sim), a general-purpose Parallel Discrete Event simulation platform built according to the optimistic synchronization scheme, which allows—via the adoption of a simple/reduced API—to implement simulation models via event handlers relying on standard ANSI-C. We present the set of paradigms which ROOT-Sim is built on, and its internal design, along with the offered facilities. We also explain the simulation-model programming paradigm, and give an example of a basic simulation model, which stands as a building block for more complex ones.},
  comment   = {Invited tutorial},
  doi       = {10.1007/978-3-642-54420-0_49},
  location  = {Aachen, Germany},
  name      = {padabs13-tutorial},
}

@InProceedings{Pell13c,
  author    = {Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 1st Workshop on Parallel and Distributed Agent-Based Simulations},
  title     = {A Study on the Parallelization of Terrain-Covering Ant Robots Simulations},
  year      = {2013},
  month     = aug,
  pages     = {585--594},
  publisher = {LNCS, Springer-Verlag},
  series    = {PADABS},
  abstract  = {Agent-based simulation is used as a tool for supporting (time-critical) decision making in differentiated contexts. Hence, techniques for speeding up the execution of agent-based models, such as Parallel Discrete Event Simulation (PDES), are of great relevance/benefit. On the other hand, parallelism entails that the final output provided by the simulator should closely match the one provided by a traditional sequential run. This is not obvious given that, for performance and efficiency reasons, parallel simulation engines do not allow the evaluation of global predicates on the simulation model evolution with arbitrary time-granularity along the simulation time-axis. In this article we present a study on the effects of parallelization of agent-based simulations, focusing on complementary aspects such as performance and reliability of the provided simulation output. We target Terrain Covering Ant Robots (TCAR) simulations, which are useful in rescue scenarios to determine how many agents (i.e., robots) should be used to completely explore a certain terrain for possible victims within a given time.},
  doi       = {10.1007/978-3-642-54420-0_57},
  location  = {Aachen, Germany},
}

@InProceedings{Por13,
  author    = {Porfirio, Alice and Pellegrini, Alessandro and Di Sanzo, Pierangelo and Quaglia, Francesco},
  booktitle = {Proceedings of the International Euro-Par 2013 Conference},
  title     = {Transparent Support for Partial Rollback in Software Transactional Memories},
  year      = {2013},
  month     = aug,
  pages     = {583–-594},
  publisher = {LNCS, Springer-Verlag},
  series    = {Euro-Par},
  abstract  = {The Software Transactional Memory (STM) paradigm has gained momentum thanks to its ability to provide synchronization transparency in concurrent applications. With this paradigm, accesses to data structures that are shared among multiple threads are carried out within transactions, which are properly handled by the STM layer with no intervention by the application code. In this article we propose an enhancement of typical STM architectures which allows supporting partial rollback of active transactions, as opposed to the typical case where a rollback of a transaction entails squashing all the already-performed work. Our partial rollback scheme is still transparent to the application programmer and has been implemented for x86-64 architectures and for the ELF format, thus being largely usable on POSIX-compliant systems hosted on top of off-the-shelf architectures. We integrated it within the TinySTM open-source library and we present experimental results for the STAMP STM benchmark run on top of a 32-core HP ProLiant server.},
  doi       = {10.1007/978-3-642-40047-6_59},
  location  = {Aachen, Germany},
}

@InProceedings{Pell13b,
  author    = {Pellegrini, Alessandro},
  booktitle = {Proceedings of the 2013 International Conference on High Performance Computing \& Simulation},
  title     = {Hijacker: Efficient Static Software Instrumentation with Applications in High Performance Computing (poster paper)},
  year      = {2013},
  month     = jul,
  note      = {Shortlisted for the Outstanding Poster Paper Award},
  pages     = {650--655},
  publisher = {IEEE Computer Society},
  series    = {HPCS},
  abstract  = {Static Binary Instrumentation is a technique that allows compile-time program manipulation. In particular, by relying on ad-hoc tools, the end user is able to alter the program's execution flow without affecting its overall semantic. This technique has been effectively used, e.g., to support code profiling, performance analysis, error detection, attack detection, or behavior monitoring. Nevertheless, efficiently relying on static instrumentation for producing executables which can be deployed without affecting the overall performance of the application still presents technical and methodological issues. In this paper, we present Hijacker, an open-source customizable static binary instrumentation tool which is able to alter a program's execution flow according to some user-specified rules, limiting the execution overhead due to the code snippets inserted in the original program, thus enabling for the exploitation in high performance computing. The tool is highly modular and works on an internal representation of the program which allows to perform complex instrumentation tasks efficiently, and can be additionally extended to support different instruction sets and executable formats without any need to modify the instrumentation engine. We additionally present an experimental assessment of the overhead induced by the injected code in real HPC applications.},
  comment   = {Poster paper},
  doi       = {10.1109/HPCSim.2013.6641486},
  location  = {Helsinki, Finland},
}

@InProceedings{Ant13,
  author    = {Antonacci, Francesco and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 2013 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
  title     = {Consistent and Efficient Output-Stream Management in Optimistic Simulation Platform},
  year      = {2013},
  month     = may,
  pages     = {315--326},
  publisher = {ACM},
  series    = {PADS},
  abstract  = {Optimistic synchronization is considered an effective means for supporting Parallel Discrete Event Simulations. It relies on a speculative approach, where concurrent processes execute simulation events regardless of their safety, and consistency is ensured via proper rollback mechanisms, upon the a-posteriori detection of causal inconsistencies along the events' execution path. Interactions with the outside world (e.g. generation of output streams) are a well-known problem for rollback-based systems, since the outside world may have no notion of rollback. In this context, approaches for allowing the simulation modeler to generate consistent output rely on either the usage of ad-hoc APIs (which must be provided by the underlying simulation kernel) or temporary suspension of processing activities in order to wait for the final outcome (commit/rollback) associated with a speculatively-produced output.
               In this paper we present design indications and a reference implementation for an output streams' management subsystem which allows the simulation-model writer to rely on standard output-generation libraries (e.g. stdio) within code blocks associated with event processing. Further, the subsystem ensures that the produced output is consistent, namely associated with events that are eventually committed, and system-wide ordered along the simulation time axis.
               The above features jointly provide the illusion of a classical (simple to deal with) sequential programming model, which spares the developer from being aware that the simulation program is run concurrently and speculatively. We also show, via an experimental study, how the design/development optimizations we present lead to limited overhead, giving rise to the situation where the simulation run would have been carried out with near-to-zero or reduced output management cost. At the same time, the delay for materializing the output stream (making it available for any type of audit activity) is shown to be fairly limited and constant, especially for good mixtures of I/O-bound vs CPU-bound behaviors at the application level. Further, the whole output streams' management subsystem has been designed in order to provide scalability for I/O management on clusters.},
  doi       = {10.1145/2486092.2486133},
  location  = {Montréal, Canada},
}

@InProceedings{Pell13,
  author    = {Pellegrini, Alessandro and Piro, Giuseppe},
  booktitle = {Proceedings of the 8th IEEE International Workshop on the Performance Analysis and Enhancement of Wireless Networks},
  title     = {Multi-threaded Simulation of {4G} Cellular Systems within the {LTE-Sim} Framework},
  year      = {2013},
  month     = mar,
  pages     = {101--106},
  publisher = {IEEE Computer Society},
  series    = {PAEWN},
  abstract  = {Nowadays, an always increasing number of researchers and industries are putting a large effort in the design and the implementation of protocols, algorithms, and network architectures targeted at the the emerging 4G cellular technology. In this context, multi-core/multi-processor simulation tools can accelerate their activities by drastically reducing the time required to simulate complex scenarios. Unfortunately, today's available tools are mostly single-threaded and they cannot exploit the performance gain offered by parallel programming approaches. To bridge this gap, we have significantly upgraded the LTE-Simframework by implementing a concurrent scheduling algorithm, namely the Multi-Master Scheduler, aimed at efficiently handling events in a parallel manner, while guaranteeing the correct execution of the simulation itself. Experimental results will demonstrate the effectiveness of our proposal and the performance gain that can be achieved with respect to other classical event scheduling algorithms.},
  doi       = {10.1109/WAINA.2013.202},
  location  = {Barcelona, Spain},
}

@InProceedings{Dis13,
  author    = {Di Sanzo, Pierangelo and Antonacci, Francesco and Ciciani, Bruno and Palmieri, Roberto and Pellegrini, Alessandro and Peluso, Sebastiano and Quaglia, Francesco and Rughetti, Diego and Vitali, Roberto},
  booktitle = {Proceedings of the 6th ICST Conference of Simulation Tools and Techniques},
  title     = {A Framework for High Performance Simulation of Transactional Data Grid Platforms},
  year      = {2013},
  month     = mar,
  pages     = {63--72},
  publisher = {ICST},
  series    = {SIMUTools},
  abstract  = {One reason for the success of in-memory (transactional) data grids lies on their ability to fit elasticity requirements imposed by the cloud oriented pay-as-you-go cost model. In fact, by relying on in-memory data maintenance, these platforms can be dynamically resized by simply setting up (or shutting down) instances of so called data cache servers. However, defining the well suited amount of cache servers to be deployed, and the degree of in-memory replication of slices of data, in order to optimize reliability/availability and performance tradeoffs, is far from being a trivial task. To cope with this issue, in this article we present a framework for high performance simulation of in-memory data grid systems, which can be employed as a support for timely what-if analysis and exploration of the effects of reconfiguration strategies. The framework consists of a discrete event simulation library modeling differentiated data grid components in a modular fashion, which allows easy (re)-modeling of different data grid architectures (e.g. characterized by different concurrency control schemes). Also, the library has been designed to be layered on top of the open source ROOT-Sim parallel simulation engine, natively offering facilities for optimized resource usage in the context of model execution on top of multi-core and cluster based architectures. Finally, instances of data-grid models supported by the framework have been validated against real measurements obtained by deploying the Infinispan data grid onto Amazon EC2 virtual clusters, and running the well known TPC-C benchmark. By the experiments we demonstrate closeness of simulation outputs and real measurements, while jointly showing extreme scalability of the framework, in terms of speedup and ability to manage extremely large data grid models.},
  location  = {Nice, France},
}

@InProceedings{Vit12d,
  author    = {Vitali, Roberto and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 19th International Conference on High Performance Computing},
  title     = {A Load Sharing Architecture for Optimistic Simulations on Multi-Core Machines},
  year      = {2012},
  month     = dec,
  publisher = {IEEE Computer Society},
  series    = {HiPC},
  abstract  = {In Parallel Discrete Event Simulation (PDES), the simulation model is partitioned into a set of distinct Logical Processes (LPs) which are allowed to concurrently execute simulation events. In this work we present an innovative approach to load-sharing on multi-core/multiprocessor machines, targeted at the optimistic PDES paradigm, where LPs are speculatively allowed to process simulation events with no preventive verification of causal consistency, and actual consistency violations (if any) are recovered via rollback techniques. In our approach, each simulation kernel instance, in charge of hosting and executing a specific set of LPs, runs a set of worker threads, which can be dynamically activated/deactivated on the basis of a distributed algorithm. The latter relies in turn on an analytical model that provides indications on how to reassign processor/core usage across the kernels in order to handle the simulation workload as efficiently as possible. We also present a real implementation of our load-sharing architecture within the ROme OpTimistic Simulator (ROOT-Sim), namely an open-source C-based simulation platform implemented according to the PDES paradigm and the optimistic synchronization approach. Experimental results for an assessment of the validity of our proposal are presented as well.},
  doi       = {10.1109/HiPC.2012.6507510},
  location  = {Pune, India},
}

@InProceedings{Vit12c,
  author    = {Vitali, Roberto and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 2012 Winter Simulation Conference},
  title     = {Assessing Load Sharing within Optimistic Simulation Platforms (invited paper)},
  year      = {2012},
  month     = dec,
  pages     = {1--13},
  publisher = {Society for Computer Simulation},
  series    = {WSC},
  abstract  = {The advent of multi-core machines has lead to the need for revising the architecture of modern simulation platforms. One recent proposal we made attempted to explore the viability of load-sharing for optimistic simulators run on top of these types of machines. In this article, we provide an extensive experimental study for an assessment of the effects on run-time dynamics by a load-sharing architecture that has been implemented within the ROOT-Sim package, namely an open source simulation platform adhering to the optimistic synchronization paradigm. This experimental study is essentially aimed at evaluating possible sources of overheads when supporting load-sharing. It has been based on differentiated workloads allowing us to generate different execution profiles in terms of, e.g., granularity/locality of the simulation events.},
  location  = {Berlin, Germany},
}

@InProceedings{Pell12,
  author    = {Pellegrini, Alessandro and Vitali, Roberto and Peluso, Sebastiano and Quaglia, Francesco},
  booktitle = {Proceedings 20th International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems},
  title     = {Transparent and Efficient Shared-State Management for Optimistic Simulations on Multi-core Machines},
  year      = {2012},
  month     = aug,
  pages     = {134--141},
  publisher = {IEEE Computer Society},
  series    = {MASCOTS},
  abstract  = {Traditionally, Logical Processes (LPs) forming a simulation model store their execution information into disjoint simulations states, forcing events exchange to communicate data between each other. In this work we propose the design and implementation of an extension to the traditional Time Warp (optimistic) synchronization protocol for parallel/distributed simulation, targeted at shared-memory/multicore machines, allowing LPs to share parts of their simulation states by using global variables. In order to preserve optimism's intrinsic properties, global variables are transparently mapped to multi-version ones, so to avoid any form of safety predicate verification upon updates. Execution's consistency is ensured via the introduction of a new rollback scheme which is triggered upon the detection of an incorrect global variable's read. At the same time, efficiency in the execution is guaranteed by the exploitation of non-blocking algorithms in order to manage the multi-version variables' lists. Furthermore, our proposal is integrated with the simulation model's code through software instrumentation, in order to allow the application-level programmer to avoid using any specific API to mark or to inform the simulation kernel of updates to global variables. Thus we support full transparency. An assessment of our proposal, comparing it with a traditional message-passing implementation of variables' multi-version is provided as well.},
  doi       = {10.1109/MASCOTS.2012.25},
  location  = {Arlington, VA, USA},
}

@InProceedings{Vit12b,
  author    = {Vitali, Roberto and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 26th International Workshop on Principles of Advanced and Distributed Simulation},
  title     = {Towards Symmetric Multi-threaded Optimistic Simulation Kernels},
  year      = {2012},
  month     = aug,
  pages     = {211--220},
  publisher = {IEEE Computer Society},
  series    = {PADS},
  abstract  = {In this article we address the reshuffle of the design of optimistic simulation kernels in order to fit multi-core/multi-processor machines. This is done by providing a reference optimistic simulation architecture based on the symmetric multi-threaded paradigm, where each simulation kernel instance is allowed to run a dynamically changing set of worker threads that share the whole load of LPs hosted by that kernel, and that can run both application-level event handlers and kernel-level housekeeping tasks. With this organization, CPU-cores can be dynamically reassigned to the different kernels depending on fluctuations of the workload, so to maximize productivity in an orthogonal manner with respect to traditional load balancing schemes, typically employed in the context of single-threaded simulation kernels. In order to optimize efficiency and reduce wait-for-lock-release phases while synchronizing worker threads running in kernel mode, we borrow from Operating Systems' theory by readapting the top/bottom-halves paradigm to the design of optimistic simulation systems. We also present a real implementation of our multi-threaded architecture within the ROme OpTimistic Simulator (ROOT-Sim), namely an open-source C-based simulation platform implemented according to the PDES paradigm and the optimistic synchronization approach. Experimental results for an assessment of the validity of our proposal are presented as well.},
  doi       = {10.1109/PADS.2012.46},
  location  = {Zhangjiajie, China},
}

@InProceedings{Vit12,
  author    = {Vitali, Roberto and Pellegrini, Alessandro and Cerasuolo, Gionata},
  booktitle = {Proceedings of the 5th ICST Conference of Simulation Tools and Techniques},
  title     = {Cache-Aware Memory Manager for Optimistic Simulations},
  year      = {2012},
  month     = mar,
  note      = {Winner of the Best Paper Award},
  pages     = {192--138},
  publisher = {ICST},
  series    = {SIMUTools},
  abstract  = {Parallel Discrete Event Simulation is a well known technique for executing complex general-purpose simulations where models are described as objects the interaction of which is expressed through the generation of impulsive events. In particular, Optimistic Simulation allows full exploitation of the available computational power, avoiding the need to compute safety properties for the events to be executed. Optimistic Simulation platforms internally rely on several data structures, which are meant to support operations aimed at ensuring correctness, inter-kernel communication and/or event scheduling. These housekeeping and management operations access them according to complex patterns, commonly suffering from misuse of memory caching architectures. In particular, operations like log/restore access data structures on a periodic basis, producing the replacement of in-cache buffers related to the actual working set of the application logic, producing a non-negligible performance drop.

In this work we propose generally-applicable design principles for a new memory management subsystem targeted at Optimistic Simulation platforms which can face this issue by wisely allocating memory buffers depending on their actual future access patterns, in order to enhance event-execution memory locality. Additionally, an application-transparent implementation within ROOT-Sim, an open-source general-purpose optimistic simulation platform, is presented along with experimental results testing our proposal.},
  location  = {Desenzano del Garda, Italy},
}

@InProceedings{Pell11b,
  author    = {Pellegrini, Alessandro and Vitali, Roberto and Quaglia, Francesco},
  booktitle = {Proceedings of the 4th International {ICST} Conference on Simulation Tools and Techniques},
  title     = {The {ROme OpTimistic Simulator}: Core Internals and Programming Model},
  year      = {2011},
  pages     = {96--98},
  publisher = {ICST},
  series    = {SIMUTools},
  abstract  = {In this article we overview the ROme OpTimistic Simulator (ROOT-Sim), an open source C/MPI-based simulation package targeted at POSIX systems, which implements a general-purpose parallel/distributed simulation environment relying on the optimistic (i.e., rollback based) synchronization paradigm. It offers a very simple programming model based on the classical notion of simulation-event handlers, to be implemented according to the ANSI-C standard, and transparently supports all the services required to parallelize the execution. It also offers a set of optimized protocols (e.g. CPU scheduling and state log/restore protocols) aimed at minimizing the run-time overhead of the platform, thus allowing for high performance and scalability. Here we overview the core internal mechanisms provided by ROOT-Sim, together with the offered APIs and the programming model that is expected to be agreed in order to produce simulation software that can be transparently run, in a concurrent fashion, on top of the ROOT-Sim layer.},
  journal   = {Proceedings of the 4th ICST Conference of Simulation Tools and Techniques},
  location  = {Barcelona, Spain},
  name      = {simutools11b},
}

@InProceedings{Pell11,
  author    = {Pellegrini, Alessandro and Vitali, Roberto and Quaglia, Francesco},
  booktitle = {Proceedings of the 4th International {ICST} Conference on Simulation Tools and Techniques},
  title     = {An Evolutionary Algorithm to Optimize Log/Restore Operations within Optimistic Simulation Platforms},
  year      = {2011},
  pages     = {206--215},
  publisher = {SIGSIM},
  series    = {SIMUTools},
  abstract  = {In this work we address state recoverability in advanced optimistic simulation systems by proposing an evolutionary algorithm to optimize at run-time the parameters associated with state log/restore activities. Optimization takes place by adaptively selecting for each simulation object both (i) the best suited log mode (incremental vs non-incremental) and (ii) the corresponding optimal value of the log interval. Our performance optimization approach allows to indirectly cope with hidden effects (e.g., locality) as well as cross-object effects due to the variation of log/restore parameters for different simulation objects (e.g., rollback thrashing). Both of them are not captured by literature solutions based on analytical models of the overhead associated with log/restore tasks. More in detail, our evolutionary algorithm dynamically adjusts the log/restore parameters of distinct simulation objects as a whole, towards a well suited configuration. In such a way, we prevent negative effects on performance due to the biasing of the optimization towards individual simulation objects, which may cause reduced gains (or even decrease) in performance just due to the aforementioned hidden and/or cross-object phenomena. We also present an application-transparent implementation of the evolutionary algorithm within the ROme OpTimistic Simulator (ROOT-Sim), namely an open source, general purpose simulation environment designed according to the optimistic synchronization paradigm. Further, we provide the results of an experimental study testing our proposal on a suite of simulation models for wireless communication systems.},
  location  = {Barcelona, Spain},
}

@InProceedings{Vit10,
  author    = {Vitali, Roberto and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems},
  title     = {Autonomic Log/Restore for Advanced Optimistic Simulation Systems},
  year      = {2010},
  pages     = {319--327},
  publisher = {IEEE Computer Society},
  series    = {MASCOTS},
  abstract  = {In this paper we address state recoverability in optimistic simulation systems by presenting an autonomic log/restore architecture. Our proposal is unique in that it jointly provides the following features: (i) log/restore operations are carried out in a completely transparent manner to the application programmer, (ii) the simulation-object state can be scattered across dynamically allocated non-contiguous memory chunks, (iii) two differentiated operating modes, incremental vs non-incremental, coexist via transparent, optimized run-time management of dual versions of the same application layer, with dynamic selection of the best suited operating mode in different phases of the optimistic simulation run, and (iv) determination of the best suited mode for any time frame is carried out on the basis of an innovative modeling/optimization approach that takes into account stability of each operating mode vs variations of the model execution parameters.},
  doi       = {10.1109/MASCOTS.2010.40},
  issn      = {1526-7539},
  location  = {Miami Beach, Florida, USA},
}

@InProceedings{Vit09,
  author    = {Vitali, Roberto and Pellegrini, Alessandro and Quaglia, Francesco},
  booktitle = {Proceedings of the 13th {IEEE/ACM} International Symposium on Distributed Simulation and Real Time Applications},
  title     = {Benchmarking Memory Management Capabilities within ROOT-Sim},
  year      = {2009},
  pages     = {33--40},
  publisher = {IEEE Computer Society},
  series    = {DS-RT},
  abstract  = {In parallel discrete event simulation techniques, the simulation model is partitioned into objects, concurrently executing events on different CPUs and/or multiple CPU-Cores.In such a context, run-time supports for logical time synchronization across the different simulation objects play a central role in determining the effectiveness of the specific parallel simulation environment. In this paper we present an experimental evaluation of the memory management capabilities offered by the ROme OpTimistic Simulator (ROOT-Sim). This is an open source parallel simulation environment transparently supporting optimistic synchronization via recoverability (based on incremental log/restore techniques) of any type of memory operation affecting the state of simulation objects, i.e., memory allocation, deallocation and update operations. The experimental study is based on a synthetic benchmark which mimics different read/write patterns inside the dynamic memory map associated with the state of simulation objects. This allows sensibility analysis of time and space effects due to the memory management subsystem while varying the type and the locality of the accesses associated with event processing.},
  doi       = {10.1109/DS-RT.2009.15},
  location  = {Singapore},
}

@InProceedings{Pell09,
  author    = {Pellegrini, Alessandro and Vitali, Roberto and Quaglia, Francesco},
  booktitle = {Proceedings of the 2009 ACM/IEEE/SCS 23rd Workshop on Principles of Advanced and Distributed Simulation},
  title     = {{Di-DyMeLoR}: Logging only Dirty Chunks for Efficient Management of Dynamic Memory Based Optimistic Simulation Objects},
  year      = {2009},
  note      = {Shortlisted for the Best Paper Award},
  pages     = {45--53},
  publisher = {IEEE Computer Society},
  series    = {PADS},
  abstract  = {A recent work has presented the design and implementation of a software library, named DyMeLoR, supporting transparent log/restore facilities for optimistic simulation objects with generic memory layout. This library offers the possibility to allocate/deallocate memory chunks via standard API, and performs log/restore of the object state via pack/unpack techniques,exploiting ad-hoc meta-data concisely identifying the object state layout at each point in simulation time. In this paper we complement such a library with a software architecture offering the following additional advantages: (i) run-time identification of chunk updates within the dynamic memory map,(ii) reduced checkpoint latency and increased effectiveness in memory usage thanks to log/restore facilities based on (periodic) snapshots of the whole simulation object state, taken via the incremental copy of the modified (dirty) chunks only.Our approach is based on software instrumentation techniques (suited for LINUX and the ELF format), targeting memory update references performed by the application level software, and on a lightweight run-time monitoring mechanism providing minimal overhead while tracking the exact memory addresses and the size of memory areas dirtied by the execution of each event. Also,our design has been oriented to portability across 32-bit and 64-bit Intel compliant architectures, thus covering a wide spectrum of off-the-shelf machines.},
  doi       = {10.1109/PADS.2009.24},
  isbn      = {978-0-7695-3713-9},
  location  = {Lake Placid, NY, USA},
}


%%%%% Technical Reports %%%%%

@TechReport{Pell21,
  author   = {Pellegrini, Alessandro},
  title    = {Reproducibility Report for the Paper: QN-based Modeling and Analysis of Software Performance Antipatterns for Cyber-Physical Systems},
  year     = {2021},
  month    = apr,
  note     = {Workshop di Informatica Quantitativa (InfQ) 2014},
  abstract = {The authors have uploaded their artifact to Zenodo, which ensures a long-term retention of the artifact. The artifact allows to re-run the experiments very smoothly, and the dependencies are well documented. The process to regenerate data for the figures and tables in the paper completes, and all results are reproducible.
This paper can thus receive the Artifacts Available badge. The software in the artifact runs correctly with no trouble, and is relevant to the paper, thus deserving the Artifacts Evaluated -- Functional badge. Given the successful reproduction of all figures and tables, the Results Reproduced badge can be assigned.},
  journal  = {CoRR},
  eprint={2104.10030},
  archivePrefix={arXiv},
  primaryClass={cs.SE},
  url           = {http://arxiv.org/abs/2104.10030},
  volume        = {abs/2104.10030},
}

@TechReport{Pell20b,
  author   = {Pellegrini, Alessandro and Quaglia, Francesco},
  title    = {On the Relevance of Wait-free Coordination Algorithms in Shared-Memory HPC: The Global Virtual Time Case},
  year     = {2020},
  month    = apr,
  note     = {Workshop di Informatica Quantitativa (InfQ) 2014},
  abstract = {High-performance computing on shared-memory/multi-core architectures could suffer from non-negligible performance bottlenecks due to coordination algorithms, which are nevertheless necessary to ensure the overall correctness and/or to support the execution of housekeeping operations, e.g. to recover computing resources (e.g., memory). Although more complex in design/development, a paradigm switch from classical coordination algorithms to 
wait-free ones could significantly boost the performance of HPC applications.
In this paper we explore the relevance of this paradigm shift in shared-memory architectures, by focusing on the context of Parallel Discrete Event Simulation, where the Global Virtual Time (GVT) represents a fundamental coordination algorithm. It allows to compute the lower bound on the value  of the logical time passed through by all the entities participating in a parallel/distributed computation.  Hence it can be used to discriminate what events belong to the past history of the computation---thus being considered as committed---and allowing for memory recovery (e.g. of obsolete  logs that were taken in order to support state recoverability) and non-revokable operations (e.g. I/O). 
We compare the reference (blocking) algorithm for shared memory, the one proposed by by Fujimoto and Hybinette \cite{Fuj97}, with an innovative wait-free implementation, emphasizing on what design choices must be made to enforce this paradigm shift, and what are the performance implications of removing critical sections in coordination algorithms.},
  archiveprefix = {arXiv},
  eprint        = {2004.10033},
  journal       = {CoRR},
  url           = {http://arxiv.org/abs/2004.10033},
  volume        = {abs/2004.10033},
  location = {Torino, Italy},
  series   = {InfQ 2014},
}

@TechReport{Pell20,
  author   = {Pellegrini, Alessandro},
  title    = {Reproducibility Report for the Paper: Modeling of Request Cloning in Cloud Server Systems using Processor Sharing},
  year     = {2020},
  month    = {2},
  abstract = {The authors have uploaded their artifact on Zenodo, which ensures a long-term retention of the artifact. The code is suitably documented, and some examples are given. A minimalistic overall description of the engine is provided. The artifact allows to setup the environment quite quickly, and the dependencies are well documented. The process to regenerate data for the gures in the paper completes, and all results are reproducible.
This paper can thus receive the Artifacts Available badge and the Artifacts Evaluated—Functional. Given
the high quality of the artifact, also the Artifacts Evaluated—Reusable badge can be assigned.},
  journal  = {CoRR},
}

@TechReport{Mar19b,
  author        = {Marotta, Romolo and Tiriticco, Davide and Di~Sanzo, Pierangelo and Pellegrini, Alessandro and Ciciani, Bruno and Quaglia, Francesco},
  institution   = {CoRR},
  title         = {Mutable Locks: Combining the Best of Spin and Sleep Locks},
  year          = {2019},
  abstract      = {In this article we present Mutable Locks, a synchronization construct with the same execution semantic of traditional locks (such as spin locks or sleep locks), but with a self-tuned optimized trade off between responsiveness—in the access to a just released critical section—and CPU-time usage during threads’ wait phases. It tackles the need for modern synchronization supports, in the era of multi-core machines, whose runtime behavior should be optimized along multiple dimensions (performance vs resource consumption) with no intervention by the application programmer. Our proposal is intended for exploitation in generic concurrent applications where scarce or none knowledge is available about the underlying software/hardware stack and the actual workload, an adverse scenario for static choices between spinning and sleeping faced by mutable locks just thanks to their hybrid waiting phases and self-tuning capabilities.},
  archiveprefix = {arXiv},
  eprint        = {1906.00490},
  url           = {http://arxiv.org/abs/1906.00490},
  volume        = {abs/1906.00490},
}

@TechReport{Pri17,
  author      = {Principe, Matteo and Pellegrini, Alessandro and Quaglia, Francesco and Ciciani, Bruno},
  institution = {Sapienza, University of Rome},
  title       = {Transparent Distributed Cross-State Synchronization in Optimistic Parallel Discrete Event Simulation},
  year        = {2017},
  month       = dec,
  abstract    = {In this report we tackle transparent deploy and seamless execution of sequentially-coded Parallel Discrete Event Simulation (PDES) models on distributed computing architectures. We present an innovative distributed synchronization protocol which allows, in conjunction with ad-hoc Operating System memory management facilities, to access the simulation state of any concurrent Logical Process (LP) running on any node of the distributed computing environment, as if it were locally hosted by a unique node—more specifically, by a unique address space. By relying on our facilities, the simulation model developer is not required to implement neither explicit message passing, nor to rely on annotations or specific programming constructs. He can simply code the accesses to the LPs’ states in place (e.g. via pointers), which significantly simplifies the software development process. The burden of synchronization and correct handling of these accesses is demanded from our user-space and kernel-space runtime environment. Our proposal targets Linux on x86 64 systems and has been integrated within the ROOT-Sim open-source optimistic simulation platform, although its design principles, and most parts of the developed software, are of general relevance.},
}

@TechReport{Ian17a,
  author        = {Mauro Ianni and Alessandro Pellegrini and Francesco Quaglia},
  institution   = {CoRR},
  title         = {A Wait-free Multi-word Atomic (1, N) Register for Large-scale Data Sharing on Multi-core Machines},
  year          = {2017},
  abstract      = {We present a multi-word atomic (1,N) register for multi-core machines exploiting Read-Modify-Write (RMW) instructions to coordinate the writer and the readers in a wait-free manner. Our proposal, called Anonymous Readers Counting (ARC), enables large-scale data sharing by admitting up to $2^{32}-2$ concurrent readers on off-the-shelf 64-bits machines, as opposed to the most advanced RMW-based approach which is limited to 58 readers. Further, ARC avoids multiple copies of the register content when accessing it---this affects classical register's algorithms based on atomic read/write operations on single words. Thus it allows for higher scalability with respect to the register size. Moreover, ARC explicitly reduces improves performance via a proper limitation of RMW instructions in case of read operations, and by supporting constant time for read operations and amortized constant time for write operations. A proof of correctness of our register algorithm is also provided, together with experimental data for a comparison with literature proposals. Beyond assessing ARC on physical platforms, we carry out as well an experimentation on virtualized infrastructures, which shows the resilience of wait-free synchronization as provided by ARC with respect to CPU-steal times, proper of more modern paradigms such as cloud computing.},
  archiveprefix = {arXiv},
  eprint        = {1707.07478},
  journal       = {CoRR},
  url           = {http://arxiv.org/abs/1707.07478},
  volume        = {abs/1707.07478},
}

@Unpublished{Rug14b,
  author   = {Pellegrini, Alessandro},
  note     = {Euro-TM Workshop on Transactional Memory},
  title    = {Adaptive Transactional Memories: Performance and Energy Consumption Tradeoffs (poster + talk)},
  month    = apr,
  year     = {2014},
  abstract = {Energy efficiency is a pressing issue, especially in large data centers:
- non-negligible management cost
- enhancement of hardware fault probability
- significant environmental footprint
Can Software Transactional Memory (STM) provide benefits on both power saving and the overall applications’ execution performance? Encapsulating shared-data accesses within transactions gives the freedom to the STM middleware to both ensure consistency and reduce the actual data contention, the latter having been shown to affect the overall power needed to complete the application’s execution.},
  location = {Amsterdam, The Netherlands},
  series   = {WTM},
}

@TechReport{Vit12f,
  author      = {Vitali, Roberto and Pellegrini, Alessandro and Quaglia, Francesco},
  institution = {Sapienza, University of ROme},
  title       = {A Symmetric Multi-threaded Architecture for Load-sharing in Multi-core Optimistic Simulations},
  year        = {2012},
  month       = jul,
  note        = {Workshop di Informatica Quantitativa},
  abstract    = {Parallel Discrete Event Simulation (PDES) is based on a simulation model partitioned into distinct Logical Processes (LPs) which are allowed to execute simulation events concurrently.
We present here an innovative approach to load sharing on multi-core/multiprocessor machines for the optimistic PDES paradigm, where LPs can speculatively process simulation events with no a-priori verification of causal consistency, and violations (if any) are recovered via rollback techniques. Each simulation kernel instance, in charge of hosting and executing a specific set of LPs, runs a set of symmetric worker threads, which can be dynamically activated/deactivated on the basis of a distributed algorithm, which relies in turn on an analytical model providing indications on how to reassign processor/core usage across the kernels in order to efficiently handle the simulation workload. In order to optimize efficiency and reduce lock-release phases used to synchronize the threads when running in kernel mode, we propose to borrow from operating systems theory and readapt the top/bottom-halves paradigm to the design of load-sharing oriented optimistic simulation systems. We also present a real implementation of the our load sharing architecture within the ROme OpTimistic Simulator (ROOT-Sim), namely an open-source C-based simulation platform implemented according to the PDES paradigm and the optimistic synchronization approach. Experimental results for an assessment of our proposal are presented as well.},
  location    = {Lucca, Italy},
  series      = {InfQ},
}






%%%%% THESES %%%%%

@MastersThesis{tBauc24,
  author   = {Bauco, Simone},
  school   = {University of Rome ``Tor Vergata''},
  title    = {Una metodologia Model-Driven Engineering per lo sviluppo di Domain-Specific Languages},
  year     = {2024},
  month    = oct,
  type     = {mathesis},
  comment  = {Supervisor: A. Pellegrini},
}

@PhdThesis{tPimp24,
  author   = {Pimpini, Adriano},
  school   = {Sapienza, University of Rome},
  title    = {Techniques for Accurate and Scalable Simulation of Spiking Neural Networks using Speculative Discrete Event Simulation},
  year     = {2024},
  month    = sep,
  type     = {phdthesis},
  comment  = {Supervisor: A. Pellegrini},
}

@MastersThesis{tAnto24,
  author   = {Antonangeli, Mattia},
  school   = {University of Rome ``Tor Vergata''},
  title    = {4SweepTron: B5G Portable Spectrum Monitoring based on Micro-Service Architecture},
  year     = {2024},
  month    = apr,
  type     = {mathesis},
  comment  = {Supervisor: A. Pellegrini, Co-Supervisor: Luca Chiaraviglio},
}

@MastersThesis{tBaba24,
  author   = {Baba, Adrian Petru},
  school   = {University of Rome ``Tor Vergata''},
  title    = {Miglioramento dell'accuratezza e dell'efficienza energetica delle reti neurali ad impulso tramite tempistiche accurate: un caso di studio},
  year     = {2024},
  month    = apr,
  type     = {mathesis},
  comment  = {Supervisor: A. Pellegrini},
}

@MastersThesis{tDell23,
  author   = {Dell'Orco, Danilo},
  school   = {University of Rome ``Tor Vergata''},
  title    = {Unmasking Android Malware: A Comprehensive Study of Evasion Techniques and Detection Strategies},
  year     = {2023},
  month    = apr,
  type     = {mathesis},
  comment  = {Supervisor: A. Pellegrini},
}

@MastersThesis{tCicc23,
  author   = {Ciccaglione, Matteo},
  school   = {University of Rome ``Tor Vergata''},
  title    = {Metamorphic transformations: Safeguarding software IP with Generative Grammars},
  year     = {2023},
  month    = apr,
  type     = {mathesis},
  comment  = {Supervisor: A. Pellegrini},
}

@MastersThesis{tPepe23,
  author   = {Pepe, Andrea},
  school   = {University of Rome ``Tor Vergata''},
  title    = {Engine Metamorfico per la Protezione della Proprietà Intellettuale},
  year     = {2023},
  month    = apr,
  type     = {mathesis},
  comment  = {Supervisor: A. Pellegrini},
}

@PhdThesis{tPicc23,
  author   = {Piccione, Andrea},
  school   = {Sapienza, University of Rome},
  title    = {On Techniques to Handle Risk in Speculative Pallel Discrete-Event Simulation},
  year     = {2023},
  month    = may,
  type     = {phdthesis},
  comment  = {Supervisor: A. Pellegrini},
}

@MastersThesis{tCali23,
  author   = {Caliandro, Pierciro},
  school   = {University of Rome ``Tor Vergata''},
  title    = {Protezione della proprietà intellettuale mediante offuscamento basato su virtualizzazione},
  year     = {2023},
  month    = apr,
  type     = {mathesis},
  comment  = {Supervisor: A. Pellegrini},
}

@MastersThesis{tTibe23,
  author   = {Tiberi, Simone},
  school   = {University of Rome ``Tor Vergata''},
  title    = {Meccanismo d’autorizzazione per accedere ad oggetti critici del kernel basato sul percorso d’esecuzione},
  year     = {2023},
  month    = feb,
  type     = {mathesis},
  comment  = {Supervisors: F. Quaglia, A. Pellegrini},
}

@PhdThesis{tPrin22,
  author   = {Principe, Matteo},
  school   = {University of Rome ``Tor Vergata''},
  title    = {New methods for the effectiveness of speculative parallel discrete event simulation},
  year     = {2022},
  month    = sep,
  type     = {phdthesis},
  comment  = {Supervisor: F. Quaglia - Co-Supervisor: A. Pellegrini},
}

@PhdThesis{tCarn22,
  author   = {Carnà, Stefano},
  school   = {Sapienza, University of Rome},
  title    = {Methodologies and techniques for on-line exploitation of Performance Monitor Units in modern computing systems},
  year     = {2022},
  month    = jan,
  type     = {phdthesis},
  comment  = {Supervisor: F. Quaglia - Co-Supervisor: A. Pellegrini},
}


@MastersThesis{tIzz21,
  author   = {Izzillo, Alessio},
  school   = {Sapienza, University of Rome},
  title    = {Graph and Flow-based Distributed Detection and Mitigation of Botnet Attacks},
  year     = {2021},
  month    = jan,
  type     = {mathesis},
  abstract = {Nowadays, many organizations are constantly victims of several security threats which may cause economic and reputation damages. Among the large varietyof malware which affects several systems and online services, we can found software such as worms, viruses, spyware, trojans, key-loggers and botnets. Botnets are one of the most dangerous type of cyber-attacks, which are used in a variety of malicious campaigns such as email spam, financial theft, click fraud, distributed denial-of-service (DDoS) attacks for taking online services offline, and for committing cryptocurrency scams (using users’ processing power to mine cryptocurrency).
According to the Federal Bureau of Investigation, "Botnets have caused over $9 billion in losses to U.S. victims and over $110 billion in losses globally. Approximately 500 million computers are infected globally each year, translating into 18 victims per second". The first official recognized Botnet named "EarthLink Spammer" appeared in 2000: it was created to send phishing emails in large numbers, masked as communications from legitimate websites. Over 1.25 million malicious emails were sent to collect sensitive information. The botnet had downloaded viruses on victims’ computers when they clicked on the links in the emails, and these viruses remotely fed the information to the sender. In 2016, there was one of the largest and most lucrative digital ad malware ever devised: Methbot. It acquired thousands of IP addresses with US-based ISPs. The operators first created more than 6000 domains and 250267 distinct URLs that appeared to be from premium publishers (such as ESPN and Vogue), and then, video ads from malicious advertisers were posted on these websites which sent their bots “watch” around 30 million ads daily.
Over the years, the Botnet technology has evolved making the detection and mitigation of botnet attacks a very challenging problem. Many approaches have been proposed: signature-based, anomaly-based, DNS-based and mining-based. As it will be discussed, each approach presents advantages and disadvantages. The goal of this thesis is to use a hybrid analysis that relies on data mining flow and graph based patterns which can identify malicious external hosts which communicate with our hosts on which a distributed application of an online service is deployed. The hybrid analysis of this approach is performed online in order to mitigate the attacks. The process starts by capturing, in kernel space, some fields of the packets by means of an eBPF filter and passing them to userspace for grouping them in "batches" of a certain size, on which the hybrid analysis is carried out.
The eBPF filter in kernel space allows to inspect in real-time the packets in an unobtrusive and effective way. In fact, in addition to collecting packets characteristics, it is able to reject the packets coming from external hosts having IPs labeled as malicious by the userspace analysis.},
  comment  = {Supervisor: A. Pellegrini.},
}

@MastersThesis{tSilv21,
  author   = {Silvestri, Emiliano},
  school   = {Sapienza, University of Rome},
  title    = {Micro-Threading: Effective Management of Tasks in Parallel Applications},
  year     = {2021},
  month    = jan,
  type     = {phdthesis},
  abstract = {Modern parallel applications, to be run on top of multi-core systems, are ever more characterized by the presence of many differentiated activities, which can be (re-)dispatched on different elaboration units—at disparate wall-clock-times—in order to make parallelism effective. Consequently, several programming models (or environments) for multi-core shared-memory architectures give to developers the capability to indicate what portions of the application must be treated as tasks, which can then be run in parallel. However, once these tasks have been CPU- dispatched they are executed in a non-preemptible manner until they spontaneously re-interact with the specific runtime layer hosting the application, a possibility for which there is no guarantee on when it will occur again at run-time. In the meantime, sudden program state changes can always arise as a consequence of the effects that each of these tasks can have on the program evolution throughout its execution. Operating System classical preemption does not fully cope with this problem—given that the timeline for this preemption procedure is general purpose and not necessarily suited for a given application context—and may be attempted to be exploited limited to scenarios where multiple tasks are assigned for being processed to different threads, which is not the optimal case for most application domains. Also, in some application fields we also have the exploitation of speculation (giving rise to potential causality inconsistencies), which is something not dealt with by the Operating System. As a result, whenever one of such (speculative) changes in the application state occurs, the application’s current execution dynamics may already be far from the optimal ones, which is a condition that can affect its performance in a significant manner. This must be addressed through timely re-assessments of the work assigned to the underlying computing resources regardless of whether the application tasks were intended to release the CPU at that time. To cope with this problem, we propose a new execution model for tasks, called Micro-Threading model, which provides for application-transparent task interruptions at arbitrary points of their executions. These interruptions are aimed at re-evaluating the current task-to-CPU assignments, in a manner fully alternative with respect to the thread-to-CPU assignment established by the Operating System. Also, we provide an implementation of this model to support task-preemptive execution in a wide range of applications contexts deployed on top of x86 machines with Unix-like Operating Systems. These include Transactional Memory, OpenMP and speculative Parallel Discrete Event Simulation. Clearly, the exploitation of micro-threads in these contexts has also led us to introduce new algorithms and solutions suited for optimizing the linkage of the micro-thread based execution to application level specific features. These proposals form a kind of reference to be considered for the exploitation of micro-threads in application scenarios related to the specific ones considered in this thesis. The results obtained by the experiments we carried out confirm the capability of our proposal to provide better run-time dynamics thanks to higher reactivity to program state changes, which is reflected in promptly renewing the overall scheduling of tasks to CPU-cores and/or in re-assessing the execution trajectory of each single task whenever is deemed counterproductive for the performance of the application as a whole.},
  comment  = {Supervisor: F. Quaglia.},
}

@MastersThesis{tPimp20,
  author   = {Pimpini, Adriano},
  school   = {Sapienza, University of Rome},
  title    = {High Performance Simulation of Spiking Neural Networks},
  year     = {2020},
  month    = oct,
  type     = {mathesis},
  abstract = {Spiking Neural Networks (SNNs) are a class of Artificial Neural Networks that closely mimic biological neural networks. They are particularly interesting for the scientific community because of their potential to advance research in a number of fields, both because of better insights on neural behaviour, benefitting medicine, neuroscience, psychology, and because of the potential in Artificial Intelligence. Their ability to run on a very low energy budget once implemented in hardware makes them even more appealing. However, because of their behaviour that evolves with time, when a hardware implementation is not available, their output cannot simply be computed with a one-shot function—however large—, but rather they need to be simulated.
Simulating Spiking Neural Networks is extremely costly, mainly due to their sheer size. Current simulation methods have trouble scaling up on more powerful systems because of their use of conservative global synchronization methods. In this work, Parallel Discrete Event Simulation (PDES) with Time Warp is proposed as a highly scalable solution to simulate Spiking Neural Networks, thanks to the optimistic approach to synchronization.
The main problem of PDES is the complexity of implementing a model on it, especially of a system that is continuous in time, as time in PDES “jumps” from one event to the next. This greatly increases friction towards adoption of PDES to simulate SNNs. As such, current simulation-based work on SNNs is relegated to worse-scaling approaches. In order to foster the adoption of PDES and further the work on simulation of SNNs on larger scales, in this work a solution is developed and presented that hides the underlying complexity of PDES.},
  comment  = {Supervisor: A. Pellegrini.},
}

@MastersThesis{tAlta20,
  author   = {Altamura, Lorenzo},
  school   = {Sapienza, University of Rome},
  title    = {Asymmetric Runtime Environments for Increased-Performance Speculative PDES},
  year     = {2020},
  month    = jan,
  type     = {mathesis},
  abstract = {Future exascale systems will require runtime environments able to manage the complexity of the underlying heterogeneus hardware. This thesis discusses about asymmetric features in existing high performance applications to obtain consistent increase in terms of performance by properly exploiting the asymmetry shown by current pre-exascale systems. In particular, the focus is on parallel discrete events simulation (PDES) and possible solutions to best exploit asymmetry in threads by limiting the drawbacks in terms of the overhead brought by the time warp optimistic synchronization protocol.
Experimental data show how relevant the gain in terms of performance is when self-adjusting algorithms autonomically manage the balance between asymmetric thread incarnations.},
  comment  = {Supervisor: A. Pellegrini. Co-Supervisor: S. Conoci},
}

@MastersThesis{tCarn18,
  author   = {Carnà, Stefano},
  school   = {Sapienza, University of Rome},
  title    = {HOP - Hardware-based Online Profiling of multi-threaded applications via AMD Instruction-Based Sampling},
  year     = {2018},
  type     = {mathesis},
  abstract = {Simple computing architectures are just memories. The Moore’s law is the empirical rule that predicts the electronic development for over 40 years, so accurately, that lays the "roadmap" foundations for most of the semiconductor manufacturers. Until a few decades ago, the computer architecture evolution was mainly based on the operating frequency growth, namely the speed of the processor. However, in 2003 the gap between the performance achieved by processors and the Moore’s law came up, diverting the com-
puter progression to other ways. Moore’s law is still sound. The more and more availability of transistors has been exploited to implement more sophisticated architectures, able to take advantage of polished capabilities rather than simple brute force.
Nowadays, processors are based on supercalar architectures as well as out-of-order execution engines. These not only allows achieving better instructions per clock (IPC) than scalar solutions, but also optimize the code execution through the employment of further mechanisms such as speculative computation.
Besides these core improvements, companies walks the road toward the process parallelism. This led to multi-core processors, which include more computing cores on the same chip. However, the increasing power capability on processors and the memory speed did not go hand in hand. Accessing the memory still represents a bottleneck during computation because CPU-core processing is far faster than memory operations. To overcome this speed limitation, memory elements have been directly implemented on chip such that the communication with the processing units is subjected to smaller latency. These memories are know as cache memories which are so pervasive that their structure have been further enhanced by providing several layers, resulting, along with the main memory, in a sophisticated hierarchy. 
The high number of cores sharing memory in a single system bumped in another memory issue. As a matter of fact, the memory cannot easily handle the concurrent requests by all the cores thus becoming the main performance bottleneck in different scenarios. Non Uniform Memory Access (NUMA) systems were born from the need of coping with this ineptitude. Such systems are formed by a set of nodes which cooperate, sharing computational power and memory resources to carry out advanced system management and problem resolution.
Heterogeneous computing refers to systems that take advantage of dedicated cores to carry out specific tasks. An example of such solution is the combined work of CPUs and GPUs. They are suitable for different kinds of calculations and mixing their capabilities allows achieving several goals such as efficiency, higher performance and less power consumption. In such a complex world, modern software, for its part, tries to benefit—in the best possible way— from the underlying hardware facilities without exposing too many hardware-level details to developers.  Yet, how is it possible to find out the reason of a program behaviour when it does not act as we expected? Simple: use a profiler!
Profilers are tools specially designed for observing the execution of an application or the entire system with the aim of a profile creation. Such a profile holds the information gathered during the investigation and can be fed to external tools for further analysis. Most of the profilers are based on software techniques which, though capable of revealing a lot of execution information, may just observe high-level events also incurring in a significant overhead.
Most of the modern processors include within their architecture some specialized elements used to gather information about what is going on, atthe hardware level, during code execution. Such elements are known as Performance Monitor Units and allow to understand the reasons of several issues that may not directly recognized at higher level. Enhancing profiling tools with this support may lead to a low-overhead and more transparent software analysis.},
  comment  = {Supervisor: F. Quaglia - Co-Supervisor: S. Economo},
}

@PhdThesis{tMaro20,
  author   = {Marotta, Romolo},
  school   = {Sapienza, University of Rome},
  title    = {Innovative Algorithms for Shared Data Structures in Multi-core Platforms},
  year     = {2020},
  month    = nov,
  type     = {phdthesis},
  comment  = {Supervisor: F. Quaglia - Co-Supervisor: A. Pellegrini},
}

@PhdThesis{tEcon20,
  author   = {Economo, Simone},
  school   = {Sapienza, University of Rome},
  title    = {Techniques and tools for program tracing and analysis with applications to parallel programming},
  year     = {2020},
  month    = nov,
  type     = {phdthesis},
  comment  = {Supervisor: F. Quaglia - Co-Supervisor: A. Pellegrini},
}

@MastersThesis{tMazz20,
  author   = {Mazziotta, Umberto},
  school   = {Sapienza, University of Rome},
  title    = {Parallel Priorities: Optimizing Priority Queues for NUMA Machines},
  year     = {2020},
  month    = jan,
  type     = {mathesis},
  abstract = {This thesis is organized as follows. In the next chapter we make an overview of the main covered concepts, and we describe the Conflict Resilient Calendar Queue, which is the priority queue we used as starting point for our solutions. Then, we provide different solutions to optimize the priority queue, showing also the results obtained in the performance evaluation, and the results against similar approaches that are found in literature. Finally, we conclude with some remarks on the work done, and other possible steps that can be done toward a further improvement of these solutions.},
  comment  = {Supervisor: A. Pellegrini - Co-Supervisor: R. Marotta},
}

@PhdThesis{tCing19,
  author   = {Cingolani, Davide},
  school   = {Sapienza, University of Rome},
  title    = {A new approach to reversible computing with applications to speculative parallel simulation},
  year     = {2019},
  type     = {phdthesis},
  abstract = {In this thesis, we propose an innovative approach to reversible computing that shifts the focus from the operations to the memory outcome of a generic program. This choice allows us to overcome some typical challenges of “plain” reversible computing. Our methodology is to instrument a generic application with the help of an instrumentation tool, namely Hijacker, which we have redesigned and developed for the purpose. Through compile-time instrumentation, we enhance the program’s code to keep track of the memory trace it produces until the end. Regardless of the complexity behind the generation of each computational step of the program, we can build inverse machine instructions just by inspecting the instruction that is attempting to write some value to memory. Therefore from this information, we craft an ad-hoc instruction that conveys this old value and the knowledge of where to replace it. This instruction will become part of a more comprehensive structure, namely the reverse window. Through this structure, we have sufficient information to cancel all the updates done by the generic program during its execution.
              In this writing, we will discuss the structure of the reverse window, as the building block for the whole reversing framework we designed and finally realized. Albeit we settle our solution in the specific context of the parallel discrete event simulation (PDES) adopting the Time Warp synchronization protocol, this framework paves the way for further general-purpose development and employment. We also present two additional innovative contributions coming from our innovative reversibility approach, both of them still embrace traditional state savingbased rollback strategy. The first contribution aims to harness the advantages of both the possible approaches. We implement the rollback operation combining state saving together with our reversible support through a mathematical model. This model enables the system to choose in autonomicity the best rollback strategy, by the mutable runtime dynamics of programs. The second contribution explores an orthogonal direction, still related to reversible computing aspects. In particular, we will address the problem of reversing shared libraries. Indeed, leading from their nature, shared objects are visible to the whole system and so does every possible external modification of their code. As a consequence, it is not possible to instrument them without affecting other unaware applications. We propose a different method to deal with the instrumentation of shared objects.
              All our innovative proposals have been assessed using the last generation of the open source ROOT-Sim PDES platform, where we integrated our solutions. ROOTSim is a C-based package implementing a general purpose simulation environment based on the Time Warp synchronization protocol.},
  comment  = {Supervisor: F. Quaglia - Co-Supervisor: A. Pellegrini},
}

@PhdThesis{tIann19,
  author   = {Ianni, Mauro},
  school   = {Sapienza, University of Rome},
  title    = {Share-everything Parallel Discrete Event Simulation on Multi-core Machines},
  year     = {2019},
  type     = {phdthesis},
  abstract = {Speculative parallel processing is a well known means to deliver high performance and scalability when executing discrete event simulation models. Nevertheless, it requires the runtime support to restore the application’s state to some past (consistent) image. Traditionally, the recoverability support has been realized via proper software layers. However, although a lot of optimizations have been provided in literature for making software-based recoverability highly efficient, its relative overhead may still represent an impairment to performance in case of (very) fine grain applications. This work presents an innovative runtime support for speculative parallel processing of discrete event simulation models on multi-core architectures, which exploits Hardware-Transactional-Memory (HTM) facilities, nowadays offered by off-the-shelf processors, for the purpose of state recoverability. In this thesis, the speculative updates on the state of the simulation model are executed as concurrent HTM-based transactions that are also in charge of detecting whether the update is consistent with the advancement of logical-time along model execution. This is achieved by including in the HTM-based transactional code-block both the activation of the application layer in charge of processing the simulation event, and the execution of housekeeping tasks aimed at determining the safety (in terms of causal consistency) of the executed transaction. This proposal is fully transparent to the application code. Hence, this HTM-based run-time support can host conventionally developed discrete event models relying on the concept of event-handlers to be dispatched by an underlying simulation engine. Experimental data show that this proposal provides 75% to 92% of the ideal speedup on an Intel Haswell based platform (equipped with 4 physical cores and HTM support) for discrete event models with event granularity ranging between 2 and 12 microseconds. The data also show that these same models cannot be executed efficiently on top of a last generation parallel discrete event simulation platform employing software-based recoverability.},
  comment  = {Supervisor: F. Quaglia - Co-Supervisor: A. Pellegrini},
}

@MastersThesis{tFerr19,
  author   = {Ferracci, Serena},
  school   = {Sapienza, University of Rome},
  title    = {Detecting Cache-based Side Channel Attacks using Hardware Performance Counters},
  year     = {2019},
  type     = {mathesis},
  abstract = {The remainder of this thesis is organized as follows. Chapter 2 provides an overview of optimization techniques introduced in order to speed up executions. The advantages and the disadvantages implicated by the optimization and the families of attacks that exploit them to read and/or write memory of the victim process are also discussed. Chapter 3 presents the hardware facilities used to detect the described attacks. Chapter 4 explains the methodology used to detect the attack techniques presented and how PMCs can be used for this purpose. Chapter 5 describes a possible implementation of the methodology. Finally, Chapter 6 concludes and sums up this thesis and discusses some possible future works. It discloses how our proposal can be enhanced for an extended support and possible directions for future work.},
  comment  = {Supervisor: A. Pellegrini - Co-Supervisor: S. Carnà},
}

@MastersThesis{tPicc19,
  author   = {Piccione, Andrea},
  school   = {Sapienza, University of Rome},
  title    = {An Agent-Based Simulation API for Speculative PDES Runtime Environments},
  year     = {2019},
  type     = {mathesis},
  abstract = {
		  Agent-Based Modeling and Simulation is an effective paradigm to model systems which exhibit complex interactions. The goal is studying them in the hope of devising their emergent behavior, if it exists. Applications of this methodology range from modeling agent decisions in the stock market, supply chains, and consumer markets, to predicting the spread of epidemics, the threat of bio-warfare, and the factors responsible for the fall of ancient civilizations.
		  While Agent-Based Modeling and Simulation has been effectively used in many disciplines, most successful models are still run only sequentially, causing a potential waste of the computing resources offered by modern multi-core architectures. The high reliance of the model developers community on simple and easy-to-use languages such as NetLogo places a limit on the possibility to benefit from more effective runtime paradigms, such as Parallel Discrete Event Simulation (PDES). This is a significant problem since the required size of Agent-Based Models simulations is increasing everyday: traditional implementations are not up to the challenge.
		  The aim of this thesis is to somewhat bridge the gap between efficient simulation runtime paradigms, in particular Speculative PDES, and AgentBased Modeling and Simulation. For this purpose we propose a semanticallyrich API which allows to implement Agent-Based Models in a simple and effective way.
		  We also describe the critical points which should be taken into account when implementing this API in a speculative Parallel Discrete Event Simulation environment, in order to scale up simulations on distributed massively-parallel clusters. We include in this thesis a description of the implementation we developed, with a focus on the various optimizations we devised.
		  Our experimental assessment, carried on our reference implementation, shows that our API allows to implement complex interactions between agents and the surrounding environment with a reduced complexity, while delivering a non-negligible performance increase. This is a first important step in finally making powerful simulation tools accessible to the practitioners, independently of their computer science knowledge.},
  comment  = {Supervisor: A. Pellegrini},
}

@MastersThesis{tPrin18,
  author   = {Principe, Matteo},
  school   = {Sapienza, University of Rome},
  title    = {Transparent Distributed Cross-State Synchronization in Optimistic Parallel Discrete Event Simulation},
  year     = {2018},
  type     = {mathesis},
  abstract = {Parallel Discrete Event Simulation (PDES) is a powerful technique to simulate real world complex models. In fact, by sharing the workload over different machines, thus parallelizing it over different entities it is possible to satisfy the high amount of computational power and resources needed by such a kind of models. Indeed, taking advantage of this sort of organization allows to overcome both the power wall ([Sut05]) and the memory wall ([McK04]), which represent the main aspects limiting the delivery of high performance executions.
		In particular, this thesis directly faces the disadvantages given by distributed memory accesses arising between Logical Processes (LPs, which are the main simulation entities representing real world objects evolving over time, [Fuj90]) while synchronizing between each other. In fact, those LPs are continuously communicating and often requesting access to portions of memory owned by
		others. This scenario needs the involved (two or more) LPs to synchronize in order to ensure that the requested operation will be correctly reflected in their memory. This could lead of course to a degradation of performance, given the distributed nature of the system on top of which the  simulations are executed. The innovative technique presented in this document exploits the new kernel-level facilities in order to detect, manage and optimize the aforementioned situation, which is known as Event Cross State Synchronization (ECS).
		Also, an important result reached in this work is represented by the fact that the provided solution is transparent to the final model developer in the sense that the whole job is handled by the underlying run-time environment, leveraging shared-memory accesses of the simulation state by relying on the data-sharing paradigm and executing and deploying in a seamless manner on distributed memory within clusters of multicore machines.
		The whole work was developed on top of an open source, optimistic simulation platform provided by the High Performance and Dependable Computing Systems (HPDCS) research group at Sapienza, University of Rome, called ROme OpTimistic Simulator (ROOT-Sim).
		The remainder of this thesis is organized as follows. In the first chapter, an overview and an explanation of the main topics of simulation and PDES is presented, focusing in particular on the environment and the choices made in this work. In Chapter 2, an introduction to the programming models of PDES is given, going through what literature proposes. Then, in Chapter 3, the proposed solution is discussed, concentrating on the specific implementation and design choices that were made in order to get the best results. Finally, Chapter 4 shows the experimental data for an assessment of the proposed solution.},
  comment  = {Supervisor: F. Quaglia - Co-Supervisor: A. Pellegrini},
}

@MastersThesis{tSilv17,
  author   = {Silvestri, Emiliano},
  school   = {Sapienza, University of Rome},
  title    = {Fine-Grain Time-Shared Execution of In-Memory Transactions},
  year     = {2017},
  type     = {mathesis},
  abstract = {In the early years of the past decade, the exponential growth of the sequential computing performance that has characterized the previous fifty years suffered a setback. Although the quantity of transistors on a chip continues to follow Moore’s law, it has become increasingly difficult to continue to improve the performance of sequential processors by simply raising the clock frequency, mainly due to power and cooling motivations. To remedy this situation, the industry released the so-called “multicore”, or “chip multiprocessors” systems, which provide for the presence of multiple processing units on a single chip and connected through a shared memory. In subsequent years the number of processors on a chip will increase at the Moore’s law rate, as well as the peak number of instructions executed per seconds, allowing this architecture to be the potential solution to the problem of stalled performance growth.
		On the other hand, a parallel program is far more difficult to design than an equivalent sequential program, and rarely offers a significant performance increase which may be attributable to the nature of the program and the impossibility to structure it in a set of parallel independent tasks. The most real-world computational problems cannot be effectively parallelized without incurring the cost of inter-processor communication and coordination because, while parts of the program mandatory need to be performed in a serial manner, the parallel parts may also need to access shared data, which in turn require particular synchronization techniques. Parallelization and synchronization can have therefore a dominant effect on performance resulting in this way in an extremely non-linear speed-up curve tending to stall or worse. Thus, parallel programming makes more complex the programmer work with respect to the sequential one; a simple task requires much more attention in order to guarantee fundamental properties such as “safety” and “liveness”, and an approach that seems to be very good in solving a problem could give rise to bad outcomes in solving another one.
		While parallelism has been a difficult problem for general-purpose programming, database systems have successfully exploited parallel hardware for decades by executing many queries concurrently on multiple processors. The author of the query does not care anymore about parallelism and has only to focus on the correctness of the query itself, leaving the hard task of ensuring atomicity, consistency, isolation and durability (A.C.I.D.) to the transactional engine that is part of the database management system (DBMS). The transaction is indeed the heart of the programming model for databases and can be expressed as a group of read and write operations performed on shared objects which must appear to be executed atomically at a single point in time, before and after the effect of other transactions running or not concurrently, in a serial one-at-a-time order. Transactions offer therefore a proven abstraction mechanism in database systems for constructing reusable parallel computations, and the advent of multicore processors has renewed interest in an old idea, that of incorporating transactions into the programming model used to write parallel programs.
		This is the approach followed in Transactional Memory (TM), a paradigm that enables programmers of concurrent applications to rely on atomicity and isolation guarantees provided by some TM layer. In this thesis I will present a fully innovative mechanism enabling in-memory transactions to be executed as preemptable tasks, with preemption actuated according to very fine grain intervals. This in turn enables a single thread to exploit one CPU-core in the most effective manner with respect to different priority levels of the transactions to be processed, an issue that as not yet been tackled by any literature study.},
  comment  = {Supervisor: F. Quaglia - Co-Supervisors: S. Economo, A. Pellegrini, P. Di Sanzo},
}

@MastersThesis{tCono17,
  author   = {Conoci, Stefano},
  school   = {Sapienza, University of Rome},
  title    = {Efficient Software Transactional Memory via Thread Scheduling and Dynamic Voltage and Frequency Scaling},
  year     = {2017},
  type     = {mathesis},
  abstract = {Transactional memory is a interesting parallel programming paradigm that offers the scalability of fine-grained locking without the need of handcrafted synchronization. It relies on the concept of atomic transactions that might commit or abort depending on the interleaving of operations on shared data. However, an excessive number of aborts could lead to performance degradation and wasted energy. Recently, there has been interest in the performance and energy optimization of transactional memory with techniques like thread scheduling [1, 2]. However, there are not yet studies that explore the energy efficiency and performance trade-offs obtainable when running transactional applications at lower energy CPU states. In this work we investigate the performance and energy efficiency of two current generation systems executing transactional applications with different configurations of parallel threads and CPU frequency and voltage. The results of this investigation are exploited to develop an architecture for the efficient execution of transactional applications. It is based on exploration heuristics that can efficiently select at run-time the configuration that provide the highest performance while operating withing user defined constraints on power and energy consumption. This thesis is organized as follows. In Chapter 1 we provide an overview of concurrent programming, transactional memories and we characterize the energy consumption of modern computing system. Chapter 2 contains a brief summary of the present state of the art of the performance and energy optimization of transactional memories. In Chapter 3 we perform an in-depth analysis of the performance and energy efficiency of transactional applications running with different configurations of parallel threads and CPU energy states. In Chapter 4 we present the proposed architecture, the exploration heuristics and we show the trade-offs obtainable with different constraints on power and energy consumption. Chapter 5 concludes this work with a brief summary of the achieved results},
  comment  = {Supervisor: F. Quaglia - Co-Supervisor: P. Di Sanzo},
}

@MastersThesis{tRivi17,
  author   = {Rivieccio, Salvatore},
  school   = {Sapienza, University of Rome},
  title    = {Energy Efficient Spin-Locking in Multi-Core Machines},
  year     = {2017},
  type     = {mathesis},
  abstract = {In this thesis I will show an implementation of spin-locks that works in an energy efficient fashion, exploiting the capability of last generation hardware and new software components in order to rise or reduce the CPU frequency when running spinlock operation. In particular this work consists in a linux kernel module and a user-space program that make possible to run with the lowest frequency admissible when a thread is spin-locking, waiting to enter a critical section. These changes are thread-grain, which means that only interested threads are affected whereas the system keeps running as usual. Standard libraries’ spinlocks do not provide energy efficiency support, those kind of optimizations are related to the application behaviors or to kernel-level solutions, like governors.},
  comment  = {Supervisor: F. Quaglia - Co-Supervisor: P. Di Sanzo},
}

@MastersThesis{tScar17,
  author   = {Scarselli, Andrea},
  school   = {Sapienza, University of Rome},
  title    = {A Lock-Free Buddy System for Scalable Memory Allocation},
  year     = {2017},
  type     = {mathesis},
  abstract = {In the last years the time of easy performance gaining is ended due to a physical constraint called Power Wall. In this scenario, the large diffusion of shared-memory multi-core machines offers a new opportunities to face the increasing demand for improved performance. Anyhow, common lock-based synchronization techniques could be deleterious for performances and frustrate the presence of the increasing number of cores.
		In order to optimize parallel execution, the non-blocking synchronization paradigm, based on the exploitation of Read-Modify-write (RMW) instructions, was born. This new technique requires a deep knowledge of the underlying hardware capabilities and on the assumptions that can be made on it.
		On the other hand, the memory allocation problem is still relevant to support fast execution of both system and user applications.
		An efficient allocator is required to avoid memory requests to become a bottleneck in high-performance scenarios characterized by large amount of processes. Moreover, requests could be very different depending on the target application; a good memory allocator has to works well in as many as possible scenarios.
		In this work I present the design and the implementation of a lock-free buddy system memory allocator based on a binary tree structure. The proposed algorithm offers great performances in highly parallel machines and it is very memory efficient, producing low data overhead to work.
		The results obtained in the experiments confirm the actual scalability of this proposal and the effectiveness of the lock-free synchronization.},
  comment  = {Supervisor: B. Ciciani - Co-Supervisor: F. Quaglia, M. Ianni, R. Marota},
}

@MastersThesis{tTocc17,
  author   = {Tocci, Tommaso},
  school   = {Sapienza, University of Rome},
  title    = {ORCHESTRA: An Asynchronous Wait-Free Distributed GVT Algorithm},
  year     = {2017},
  type     = {mathesis},
  abstract = {Taking advantage of computing capabilities oered by modern parallel and distributed architectures is fundamental to run large-scale simulation models based on the Parallel Discrete Event Simulation (PDES) paradigm. By relying on this computing organization, it is possible to eectively overcome both the power and the memory wall, which are core limiting aspects to deliver high-performance simulations. This is even more the case when relying on the speculative Time Warp synchronization protocol, which could be particularly memory greedy. At the same time, some form of coordination, such as the computation of the Global Virtual Time (GVT), is required by Time Warp Systems. These coordination points could easily become the bottleneck of large-scale simulations, hindering an efficient exploitation of the computing power oered by large supercomputing facilities. In this dissertation is presented ORCHESTRA, a coordination algorithm which is both wait-free and asynchronous. The nature of this algorithm allows any computing node to carry on simulation activities while the global agreement is reached, thus oering an eective building block to achieve scalable PDES. The general organization of ORCHESTRA could be adopted by different high-performance computing applications, thus paving the way to a more effective usage of modern computing infrastructures.},
  comment  = {Supervisor: B. Ciciani - Co-Supervisor: A. Pellegrini},
}

@MastersThesis{tMaro16,
  author  = {Marotta, Romolo},
  school  = {Sapienza, University of Rome},
  title   = {A Lock-Free O(1) Priority Queue for Pending Event Set Management},
  year    = {2016},
  type    = {mathesis},
  comment = {Supervisor: F. Quaglia - Co-Supervisors: P. Di Sanzo, A. Pellegrini},
}

@MastersThesis{tMarz16,
  author   = {Marziale, Nazzareno},
  school   = {Sapienza, University of Rome},
  title    = {Dynamic Clustering of Simulation Objects in Speculative Parallel Simulation Systems},
  year     = {2016},
  type     = {mathesis},
  abstract = {This thesis is organized as follow: Chapter 2 presents all works related to the one discussed in the thesis and the different implementations developed to solve this problem. Chapter 3, we explain more in detail the simulator on which the solution is implemented. The work conducted in this thesis is explained thoroughly in Chapter 4 and Chapter 5 we expose the results of tests and the improvements observed. Finally, in Chapter 6 we explain the conclusions that have been reached.},
  comment  = {Supervisor: F. Quaglia - Co-Supervisor: A. Pellegrini},
}

@MastersThesis{tNobi16,
  author   = {Nobilia, Francesco},
  school   = {Sapienza, University of Rome},
  title    = {Runtime Management of Simulation Objects Cross-State Dependencies in NUMA-oriented Parallel Simulation Platforms},
  year     = {2016},
  type     = {mathesis},
  abstract = {Nowadays, the well acceptable solution for speeding-up and making very large and complex simulation models tractable is the parallelDES (PDES) paradigm. In a speculative environment two simulation entities with different simulation times can reach the same portion of simulation state at the same wall-clock time. In this case the system has to manage their accesses always guaranteeing state coherence. For copying with this issue the entire model has been partitioned into distinct Logical Processes (LPs): each LP handles and models a portion of the whole simulated environment/phenomenon, and interacts with others by means of time-stamped event messages (local causality constraint). The reasons behind this disjunction are only technical. They impose a coding style that prevents the possibility that some LP can directly manage more than one state at a time. The purpose of this work is answering to the question raised by Fujimoto whether building a shared state system by using messages only is the natural way to program simulation. Our solution is based over the concept that each LP can directly access the state of any other LP by means of synchronization phase. This behaviour is achieved setting-up each simulation object over a parallel memory view. Further, given that modern parallel machines are organized according to the Non-Uniform-Memory-Accesss (NUMA) model, we also provide approaches for making the access to memory slices associated with the parallel memory view efficient in NUMA systems. We augment the ROme OpTimistic Simulator (ROOTSim) with our proposal and we use this environment as test-bed. Finally, we demonstrate how our approach improves the simulation performance.},
  comment  = {Supervisor: F. Quaglia - Co-Supervisor: A. Pellegrini},
}

@MastersThesis{tIann15,
  author   = {Ianni, Mauro},
  school   = {Sapienza, University of Rome},
  title    = {Transactional Memory Based Speculative Parallel Execution of Discrete Event Applications},
  year     = {2015},
  type     = {mathesis},
  abstract = {Speculative parallel processing is a well known means to deliver high performance and scalability when executing discrete event simulation models. Nevertheless, it requires the runtime support to restore the application’s state to some past (consistent) image. Traditionally, the recoverability support has been realized via proper software layers. However, although a lot of optimizations have been provided in literature for making software-based recoverability highly efficient, its relative overhead may still represent an impairment to performance in case of (very) fine grain applications. This work presents an innovative runtime support for speculative parallel processing of discrete event simulation models on multi-core architectures, which exploits Hardware-Transactional-Memory (HTM) facilities, nowadays offered by offthe-shelf processors, for the purpose of state recoverability. In this thesis, the speculative updates on the state of the simulation model are executed as concurrent HTM-based transactions that are also in charge of detecting whether the update is consistent with the advancement of logical-time along model execution. This is achieved by including in the HTM-based transactional code-block both the activation of the application layer in charge of processing the simulation event, and the execution of housekeeping tasks aimed at determining the safety (in terms of causal consistency) of the executed transaction. This proposal is fully transparent to the application code. Hence, this HTM-based run-time support can host conventionally developed discrete event models relying on the concept of event-handlers to be dispatched by an underlying simulation engine. Experimental data show that this proposal provides 75% to 92% of the ideal speedup on an Intel Haswell based platform (equipped with 4 physical cores and HTM support) for discrete event models with event granularity ranging between 2 and 12 microseconds. The data also show that these same models cannot be executed efficiently on top of a last generation parallel discrete event simulation platform employing software-based recoverability},
  comment  = {Supervisor: F. Quaglia - Co-Supervisor: A. Pellegrini},
}

@MastersThesis{tEcon15,
  author   = {Economo, Simone},
  school   = {Sapienza, University of Rome},
  title    = {Lightweight approximate virtual page access tracing of multi-threaded applications via static binary instrumentation},
  year     = {2015},
  type     = {mathesis},
  abstract = {This thesis is structured as follows. Chapter 2 provides an overview of instrumentation techniques and existing tools. It will then focus on static binary instrumentation and Hijacker, a C toolkit designed to achieve general-purpose static instrumentation through lightweight and non-intrusive injection techniques. Chapter 3 builds on the concepts presented in the previous chapter to give a general perspective on the memory access tracing problem, as well as the most important techniques employed in the literature. Chapter 4 is the heart of this thesis and explains how one can solve the problem of tracing virtual pages by leveraging on finergrained memory tracing techniques. Chapter 5 provides the reader with an experimental and quantitative justification of the goodness of my approach in terms of instrumentation overhead and tracing accuracy. Finally, chapter 6 lays out the conclusions of this thesis and anticipates possible directions for future work.},
  comment  = {Supervisor: F. Quaglia - Co-Supervisor: A. Pellegrini},
}

@MastersThesis{tRizz15,
  author   = {La Rizza, Andrea},
  school   = {Sapienza, University of Rome},
  title    = {Elastic cloud resources provisioning for life insurance undertaking applications},
  year     = {2015},
  type     = {mathesis},
  abstract = {The Solvency II Directive (Directive 2009/138/EC) [14] is a European law adopted in November 2009, and amended by Directive 2014/51/EU of the European Parliament and of the Council of 16 April 2014 (the so-called "Omnibus II Directive"). It was enacted by the European Union to regulate the insurance sector through risk management. Solvency II requires that European insurance companies conduct consistent evaluations and constant monitoring of risk. The main regulation requires the insurance undertaking to compute the SCR (Solvency Capital Requirement) and the pdf (Probability Distribution Forecast). The SCR is the capital amount that should hedge the losses up to a given level. To calculate the SCR the directive allows the company to choose between two different computational methodology: the standard formula and the internal model. The pdf is a mathematical function that assigns to an exhaustive set of mutually exclusive future events a probability of realisation. Its computation relies on non closed form calculus based on several Monte Carlo simulations and different hypothesis.
		To fulfill the directives, companies should equip themselves with particular computational systems which, due to their complexity, require for their execution significant underlying IT infrastructures. This IT equipments represent a significant outlay for the company, not only for what concerns their direct costs due to the purchase, but also those for power consumption, cooling, maintenance and upgrades. Moreover, the technological progress that characterizes the IT field makes these computing resources become obsolete quickly. On the other hand, we face the risk that such resources become underused since these procedures could be used only periodically (at most monthly). If for the insurance company the utilization of "on premises" resources may not be advantageous, for a cloud services provider, increasing steadily its resources, leads to reduce the costs and consequently reduce the rates charged to the user.
		The idea of this work is to put together the needs arising from Solvency II accomplishment with the always more advantageous scenario of cloud services. Within the project, as a case study, the focus is on a particular "module" of a more complex system named DISAR® 1, that deals with the calculation of the pdf and other significant items for an insurance company. This procedure relies on a Monte Carlo simulation algorithm developed on parallel MPI environment. The goal of the project is to develop a framework that, by exploiting a learning algorithm is able to: calculate the computational power and the size of the IT infrastructure necessary for the execution of the procedure for a given input, deploy and make it available in a few minutes on the cloud, transfer to the grid the data necessary to the simulation, execute it and retrieve the output in a fully automated way transparent to the final user. The latter has the only task of choosing the segregated funds the to work on. Moreover after each elaboration, the data relative to it are stored and subsequently utilized to improve the model for the next simulation. The cloud services provider adopted for this project is Amazon Web Services (AWS), however the core algorithm as the methodology can be applied independently of the provider.},
  comment  = {Supervisor: B. Ciciani - Co-Supervisors: A. Pellegrini},
}

@MastersThesis{tFort15,
  author   = {Forte, Luca},
  school   = {Sapienza, University of Rome},
  title    = {Proactive Workload Management in Cloud Environments in the Presence of Software Aging},
  year     = {2015},
  type     = {mathesis},
  abstract = {This work is structured as follows. In Chapter 2 it will be discussed related work. Chapter 3 presents the problems related to the software aging. Chapter 4 discusses the ML-based frameworks used in this works. The design and the  umplementation choices of this framework are discussed Chapter 5. Chapter 6 shows the experimental evaluation and the Chapter 7 draws the conclusions.},
  comment  = {Supervisor: B. Ciciani - Co-Supervisors: P. Di Sanzo, A. Pellegrini},
}

@MastersThesis{tScar15,
  author   = {Scarselli, Andrea},
  school   = {Sapienza, University of Rome},
  title    = {Gestione ottimizzata della delivery e del buffering dei messaggi in piattaforme multi-thread in architetture NUMA},
  year     = {2015},
  type     = {bathesis},
  abstract = {In questo lavoro presento l’ideazione e la realizzazione in C di un allocatore e gestore di memoria finalizzato allo scambio di messaggi in un software di tipo Parallel Discrete Event Simulation (PDES). L’allocatore è stato progettato e realizzato per essere eseguito su una macchina con architettura di tipo Non Uniform Memory Access (NUMA).},
  comment  = {Supervisor: F. Quaglia - Co-Supervisor: A. Pellegrini},
}

@PhdThesis{tPell14,
  author   = {Pellegrini, Alessandro},
  school   = {Sapienza, University of Rome},
  title    = {Techniques for Transparent Parallelization of Discrete Event Simulation Models},
  year     = {2014},
  type     = {phdthesis},
  abstract = {Simulation is a powerful technique to represent the evolution of real-world phenomena or systems over time. It has been extensively used in different research fields (from medicine to biology, to economy, and to disaster rescue) to study the behaviour of complex systems during their evolution (symbiotic simulation) or before their actual realization (what-if analysis). A traditional way to achieve high performance simulations is the employment of Parallel Discrete Event Simulation (PDES) techniques, which are based on the partitioning of the simulation model into Logical Processes (LPs) that can execute events in parallel on different CPUs and/or different CPU cores, and rely on synchronization mechanisms to achieve causally consistent execution of simulation events. As it is well recognized, the optimistic synchronization approach, namely the Time Warp protocol, which is based on rollback for recovering possible timestamporder violations due to the absence of block-until-safe policies for event processing, is likely to favour speedup in general application/architectural contexts.
		However, the optimistic PDES paradigm implicitly relies on a programming model that shifts from traditional sequential-style programming, given that there is no notion of global address space (fully accessible while processing events at any LP). Furthermore, there is the underlying assumption that the code associated with event handlers cannot execute unrecoverable operations given their speculative processing nature. Nevertheless, even though no unrecoverable action is ever executed by event handlers, a means to actually undo the action if requested needs to be devised and implemented within the software stack.
		On the other hand, sequential-style programming is an easy paradigm for the development of simulation code, given that it does not require the programmer to reason about memory partitioning (and therefore message passing) and speculative (concurrent) processing of the application. In this thesis, we present methodological and technical innovations which will show how it is possible, by developing innovative runtime mechanisms, to allow a programmer to implement his simulation model in a fully sequential way, and have the underlying simulation framework to execute it in parallel according to speculative processing techniques. Some of the approaches we provide show applicability in either shared- or distributed-memory systems, while others will be specifically tailored to multi/many-core architectures.
		We will clearly show, during the development of these supports, what is the effect on performance of these solutions, which will nevertheless be negligible, allowing a fruitful exploitation of the available computing power. In the end, we will highlight which are the clear benefits on the programming model that the model developer will experience by relying on these innovative solutions.},
  comment  = {Supervisor: F. Quaglia},
}

@PhdThesis{tPelu14,
  author   = {Peluso, Sebastiano},
  school   = {Sapienza, University of Rome},
  title    = {Efficient Protocols for Replicated Transactional Systems},
  year     = {2014},
  type     = {phdthesis},
  abstract = {Over the last years several relevant technological trends have significantly increased the relative impact that the inter-replica synchronization costs have on the performance of transactional systems. Indeed, the emergence of technologies like Transactional Memory, Solid-State Drives and Cloud computing has exacerbated the ratio between the latencies of replication coordination and transaction processing. The requirements of these environments harshly challenge state of the art techniques for replication of transactional systems, raising the need for rethinking existing approaches to this problem.
		This dissertation advances the state of the art on replicated transactional systems by presenting a set of innovative replication protocols designed to achieve high efficiency even in such challenging scenarios. 
		More in detail, four transactional replication protocols are proposed, which tackle the aforementioned issues from various angles. The first two cope with full replication scenarios, and exploit orthogonal techniques, such as speculation and transaction migration, which allow for amortizing, in different ways, the impact of distributed coordination on system performance. The other two proposals explicitly cope with the issue of scalability, by introducing the first genuine partial replication techniques that support abort-free read-only transactions while ensuring, respectively, One-Copy Serializability and Extended Update Serializability. The core of these protocols is a distributed multi-version concurrency control algorithm, which relies on a novel logical clock synchronization mechanism to track, in a totally decentralized (and consequently scalable) way, both data and causal dependency relations among transactions. The trade-offs arising across the different presented solutions are also discussed and experimentally evaluated by integrating them into state of the art academic and industrial transactional platforms.},
  comment  = {Supervisors: F. Quaglia, P. Romano},
}

@PhdThesis{tRugh14,
  author   = {Rughetti, Diego},
  school   = {Sapienza, University of Rome},
  title    = {Autonomic Concurrency Regulation in Software Transactional Memories},
  year     = {2014},
  type     = {phdthesis},
  abstract = {Software Transactional Memory (STM) has emerged as a powerful programming paradigm for concurrent applications. It allows encapsulating the access to data shared across concurrent threads within transactions, thus avoiding the need for synchronization mechanisms to be explicitly coded by the programmer. On the other hand, synchronization transparency must not come the expense of performance. Hence, STM-based systems must be enriched with mechanisms providing optimized run-time efficiency. Among the issues to be tackled, a core one is related to determining the optimal level of concurrency (number of threads) to be employed for running the application on top of the STM layer. For too low levels of concurrency, parallelism can be hampered. On the other hand, overdimensioning the concurrency level may give rise to thrashing phenomena caused by excessive data contention and consequent transaction aborts.
		In this thesis we propose a set of techniques in order to build “application specific” performance models allowing to dynamically tune the level of concurrency to the best suited value depending of the specific execution phase of the application. We will present three different approaches: a) one based on a pure Machine Learning (ML) model that doesn’t require a detailed knowledge of the application internals to predict the optimal concurrency level, b) one based on a parametric analytical performance model customized for a specific application/platform through regression analysis that, respect to the previous one, requires a lighter training phase and c) one based on a combination of analytical and Machine Learning techniques, that allows to combine the strengths of the previous
		two approaches, that is it has the advantage of reducing the training time of pure machine learning methods avoiding the approximation errors typically affecting pure analytical approaches. Hence it allows very fast construction of highly reliable performance models, which can be promptly and effectively exploited for optimizing actual application runs.
		We also present real implementations of concurrency regulation architectures, based on our performance predictions approaches, which have been integrated within the open source TinySTM package, together with experimental data related to runs of application profiles taken from the STAMP benchmark suite demonstrating the effectiveness of our proposals. The experimental data confirm how our self-adjusting concurrency schemes constantly provides optimal performance, thus avoiding performance loss phases caused by non-suited selection of the amount of concurrent threads and associated with the above depicted phenomena.
		Moreover we present a mechanism that allows to dynamically shrinks or enlarges the set of input features to be exploited by the performance predictors. This allows for tuning the concurrency level while also minimizing the overhead for input-features sampling, given that the cardinality of the input-feature set is always tuned to the minimum value that still guarantees reliability of workload characterization. We also present a fully fledged implementation of this solution again within the TinySTM open source framework, and we provide the results of an experimental study relying on the STAMP benchmark suite, which show significant reduction of the application execution time with respect to proposals based on static feature selection.},
  comment  = {Supervisor: B. Ciciani},
}

@MastersThesis{tCing14,
  author   = {Cingolani, Davide},
  school   = {Sapienza, University of Rome},
  title    = {Application Transparent and Efficient Mixed State-Saving in Speculative Simulation Platforms},
  year     = {2014},
  type     = {mathesis},
  abstract = {In this thesis we focus on devising a reverse code generator and on its integration with speculative simulation platforms, and specifically for Parallel Discrete Event Simulation (PDES). Speculative simulation platforms usually require a considerable storage allocation to model the reality and to store partial results, which further experience several update per time; nonetheless, the optimistic slant increases the likelihood of rollbacks. Simulation processes exhibit CPU-intensive burst loads too, representing a perfect field of application to test our approach in all the possible cases at once. Simulation is a problem-solving technique to cope with complex mathematical models generally conceived from real (or hypothetical) phenomena, which are non-trivially reproducible otherwise. Simulation applications handle a considerable number of parallel/distributed objects interacting together by message passing. Each object is a logical entity which relies on the virtual time concept, processing the incoming messages. The event-based simulation enforces equivalency between those messages and the relative triggered events. Unlike other structured processes, speculative simulation adopts optimistic heuristics, which allow to perform scheduled events even if they are not safe. Event safety straightway depends on actual processing events order with respect to global causality relationship they have been sent with. Optimistic approach looses event processing constraints and exploits much better computational resources, nevertheless it might bring the system to violate the causal order, bringing the simulation to an inconsistent state. The more complex simulation model is, the more likely it requires to rollback out-of-order events. So far the most consolidated way is to employ checkpointing techniques, which though exhibit considerable memory overhead and time latency as the simulation model gets more complex.},
  comment  = {Supervisor: F. Quaglia - Co-Supervisor: A. Pellegrini},
}

@PhdThesis{tVita13,
  author   = {Vitali, Roberto},
  school   = {Sapienza, University of Rome},
  title    = {Design of Software Support Structures for High Performance Optimistic Simulations with Special Focus on Multi-Core Hosting Environment},
  year     = {2013},
  type     = {phdthesis},
  abstract = {In this dissertation we cope with performance of PDES systems, with special focus on deploys of the PDES platform onto multi-core architectures. These architectures represent the current CPU trend and nowadays it is common to have chips with a significant number of cores, sometimes enough for effectively performing parallel computations within a single chip. By design, these architectures share most of the CPU internal components across different cores, and physical memory across the different CPUs. This implies several drawbacks, mainly due to the contention, but at the same time, such a sharing can become a resource, if well exploited through sector specific software design. The base building block for our work is the optimistic PDES synchronization paradigm, which has been shown to be highly promising in terms of potential for fruitful parallelism exploitation},
  comment  = {Supervisor: F. Quaglia},
}

@PhdThesis{tDiSa12,
  author   = {Di Sanzo, Pierangelo},
  school   = {Sapienza, University of Rome},
  title    = {Performance Models of Concurrency Control Protocols for Transaction Processing Systems},
  year     = {2012},
  type     = {phdthesis},
  abstract = {In this dissertation we present performance models of CCPs for transaction processing systems. Primarily, we use an analytical approach. Further, we also use detailed simulation models to evaluate the accuracy of the analytical models we propose, and to analyze some features of the protocols we deal with. We preferred to focus mainly on the analytical approach for two main reasons: (1) analytical modeling can be a practical approach for building cost-effective computer system performance models and, in particular, (2) the analytical approach enables to quantitatively describe the complex dynamics characterizing the concurrency control, allowing us to analyze and understand existing dependencies between system performance indicators and other system configuration parameters, and to reason about their implications. In this work, we deal with both Database Systems (DBS) and Software Transactional Memories (STMs), which represent traditional and emerging transaction processing systems, respectively},
  comment  = {Supervisor: B. Ciciani},
}

@PhdThesis{tPalm12,
  author   = {Palmieri, Roberto},
  school   = {Sapienza, University of Rome},
  title    = {Speculative Protocols for Actively Replicated Transactional Systems},
  year     = {2012},
  type     = {phdthesis},
  abstract = {Nowadays, the role of transactions has become twofold:
- they are used in order to guarantee consistency and atomicity in applications manipulating data;
- they are used as a means to synchronize the activities of threads working concurrently within any software layer.
Overall, the concept of transaction, historically related to support data manipulation in the context of database systems, has been widened so to encapsulate synchronization aspects in the context of parallel and concurrent applications. The latter aspect found its expression via Software Transactional Memory (STM) technologies, which have been oriented to mask the complexity of synchronization to the application programmers, thus moving along the path of bringing the power of multi/many-core architectures into the hand of ordinary, non-specialized, software developers. Such a widened scope of transactions, together with significant technological innovations possibly impacting the execution profile/cost of traditional database transactions (e.g. the advent of SSD storage systems) and the level of transaction parallelism (e.g. the advent of many-core architectures), raise the need for reconsidering the design of protocols supporting fault tolerance.
In this thesis, I focus on fault tolerant protocols based on the active replication paradigm, which is done by systematically exploiting speculative computation approaches. More in detail, I worked on innovative speculative transactional replication protocols relying on Optimistic Atomic Broadcast group communication primitives, which have been used as a building block for replicas coordination. Some proposed results are mostly oriented to theory, while others have a more strict relation with pragmatic aspects associated with the design/implementation of replicated transactional systems.},
  comment  = {Supervisor: F. Quaglia},
}

@MastersThesis{tStro12,
  author   = {Stroia, Pietro},
  school   = {Sapienza, University of Rome},
  title    = {Securing the IDT and the System Call Table from malicious LKMs},
  year     = {2012},
  type     = {mathesis},
  abstract = {Provided that loadable kernel modules (LKMs) run at ring 0, is it really possible to prevent kernel-level attacks once the evil code has started its execution? Without a hypervisor, or some kind of virtualization technology (e.g. VT-x), results in general have not been proved very successful, as Microsoft’s Patchguard technology has shown in the past years.

My thesis, which provides a patch for the Linux kernel version 3.2.51, aims at providing a security mechanism against synchronous malicious LKMs, or, in other words, LKMs that execute their attack in their initialization phase, without deferring any work. Although the patch code is for an IA-32 compatible Linux system only, there are no major obstacles in porting the code to other operating systems that support LKMs and run at least on the 80386 architecture. The rationale behind this work is that I personally had the “feeling” I could puzzle simple evil LKMs and let them believe they had successfully executed their attack, without using any kind of virtualization technology. The work, named the “YASI patch”, is to be intended as a small “proof-of-concept” running on top of an already secured system.},
  comment  = {Supervisor: F. Quaglia - Co-Supervisor: A. Pellegrini},
}

@MastersThesis{tPorf11,
  author   = {Porfirio, Alice},
  school   = {Sapienza, University of Rome},
  title    = {Progettazione e implementazione di un meccanismo di rollback parziale per memorie software transazionali},
  year     = {2011},
  type     = {mathesis},
  abstract = {L’obiettivo di questo lavoro è la progettazione e l’implementazione di un meccanismo che permetta il rollback parziale di transazioni nell’ambito delle memorie software transazionali. Per rollback parziale dopo l’abort di una transazione si intenda la ripresa dell’esecuzione del codice non dall’inizio di essa, bensì dal punto in cui è avvenuta l’incoerenza. Questo permetterebbe di salvare la parte del lavoro eseguita prima dell’occorrenza del problema, avendo potenziali effetti positivi sui costi in termini di tempo.},
  comment  = {Supervisor: F. Quaglia - Co-Supervisors: P. Di Sanzo, A. Pellegrini},
}

@MastersThesis{tCera11,
  author  = {Cerasuolo, Gionata},
  school  = {Sapienza, University of Rome},
  title   = {Cache-Aware Memory Manager for Optimistic Simulations},
  year    = {2011},
  type    = {mathesis},
  comment = {Supervisor: F. Quaglia - Co-Supervisors: A. Pellegrini, R. Vitali},
}

@MastersThesis{tVisc11,
  author   = {Visca, Fernando},
  school   = {Sapienza, University of Rome},
  title    = {Tecniche di instrumentazione statica per il supporto alla trasparenza verso il programmatore nelle STM},
  year     = {2011},
  type     = {bathesis},
  abstract = {Il presente lavoro riguarda la trasparenza al programmatore nel progetto di applicazioni basate su sistemi Software Transactional Memory (STM). Più in dettaglio, si vuol far sì che, durante la scrittura di applicazioni basate su STM, sia possibile, per le operazioni su memoria (i.e., letture e scritture), utilizzare i costrutti messi a disposizione dal linguaggio di programmazione scelto astraendo da qualsiasi riferimento alle funzioni di lettura/scrittura messe a disposizione dall’implementazione STM e dalla loro logica di funzionamento.},
  comment  = {Supervisor: F. Quaglia - Co-Supervisors: A. Pellegrini, R. Palmieri},
}

@MastersThesis{tPell10,
  author   = {Pellegrini, Alessandro},
  school   = {Sapienza, University of Rome},
  title    = {Salvataggio e Ripristino Autonomico dello Stato degli Oggetti nei Sistemi di Simulazione Ottimistici},
  year     = {2010},
  type     = {mathesis},
  abstract = {In questo lavoro viene affrontato il problema del ripristino dello stato nei sistemi di simulazione ottimistica, con la proposta di un’architettura di gestione dei checkpoint, progettata secondo il paradigma del calcolo autonomico. La proposta `e unica, nel senso che affronta contemporaneamente le questioni di trasparenza e performance, offrendo allo stesso tempo le seguenti caratteristiche:
1. le operazioni di salvataggio e ripristino dello stato vengono condotte in maniera del tutto trasparente al programmatore del livello applicativo;
2. lo stato degli oggetti di simulazione pu`o essere distribuito su frammenti di memoria non contigui;
3. il salvataggio ed il ripristino dello stato possono essere eseguiti secondo uno schema incrementale o non incrementale;
4. la selezione dello schema migliore viene effettuata a tempo d’esecuzione, utilizzando un approccio innovativo di modellazione ed ottimizzazione, che si basa sulla capacit`a di catturare fluttuazioni nelle dinamiche d’esecuzione},
  comment  = {Supervisor: F. Quaglia},
}

@MastersThesis{tPelu10,
  author  = {Peluso, Sebastiano},
  school  = {Sapienza, University of Rome},
  title   = {missing record},
  year    = {2010},
  type    = {mathesis},
  comment = {Supervisor: F. Quaglia},
}

@MastersThesis{tDido10,
  author  = {Didona, Diego},
  school  = {Sapienza, University of Rome},
  title   = {missing record},
  year    = {2010},
  type    = {mathesis},
  comment = {Supervisor: F. Quaglia},
}

@MastersThesis{tVita08,
  author  = {Vitali, Roberto},
  school  = {Sapienza, University of Rome},
  title   = {missing record},
  year    = {2008},
  type    = {mathesis},
  comment = {Supervisor: F. Quaglia},
}

@MastersThesis{tRugh08,
  author   = {Rughetti, Diego},
  school   = {Sapienza, University of Rome},
  title    = {Raccolta ed elaborazione di dati provenienti da reti di sensori distribuiti},
  year     = {2008},
  type     = {mathesis},
  abstract = {La tesi risulta essere così strutturata: nel capitolo 2 viene data una descrizione approfondita della tecnologia rfid e vengono illustrati alcuni casi di studio relativi al suo utilizzo; nel capitolo 3 vengono presentate una serie di astrazioni per sistemi distribuiti; nel capitolo 4 vengono descritti una serie di strumenti/framework utilizzate durante il processo di progettazione e sviluppo del middleware; il capitolo 5 fornisce una descrizione dettagliata dell'architettura di quest'ultimo e descrive il suo modello di programmazione; nel capitolo 6 vengono studiate le possibili tecniche di replicazione basate su active replication utilizzabili per rendere il middleware fault tolerant e viene illustrato approfonditamente un protocollo innovativo Post Synchronized Active Replication Protocol, per la sincronizzazione dello stato delle repliche; infine nel capitolo 7 forniamo una serie di conclusioni basate sui risultati sperimentali.},
  comment  = {Supervisor: B. Ciciani - Co-Supervisor: P. Romano},
}

@MastersThesis{tPalm08,
  author   = {Palmieri, Roberto},
  school   = {Sapienza, University of Rome},
  title    = {Modellazione e valutazione di DBMS relazionali basati su lock e pattern di accesso non uniformi},
  year     = {2008},
  type     = {mathesis},
  abstract = {In questo lavoro verranno analizzati i protocolli basati su strategie di locking ed in particolare sul protocollo del 2PL (Two Phase Locking). In letteratura questa famiglia di protocolli basata su locking è stata molto trattata in vari studi, ma in questo lavoro la modellazione di tali protocolli verrà specializzata e quindi approfondita nella caratterizzazione del carico di lavoro (workload) del DBMS. Il carico di lavoro è un insieme di parametri che descrivono le condizioni di funzionamento di un sistema. In letteratura non è attualmente presente un lavoro che considera come parametro fondamentale del carico di lavoro il pattern di accesso ai dati da parte delle transazioni. In questo lavoro si cercherà di dimostrare come la caratterizzazione della modalità con la quale le transazioni accedono ai dati influenza pesantemente i tempi di risposta del sistema e quindi un degrado delle prestazioni. Questo tipo di caratterizzazione del carico è già presente all’interno di alcuni benchmark di riferimento per sistemi transazionali come TCP-C, quindi un possibile terreno fertile per l’applicazione del modello studiato nei capitoli successivi},
  comment  = {Supervisor: B. Ciciani},
}

@MastersThesis{tPell08,
  author   = {Pellegrini, Alessandro},
  school   = {Sapienza, University of Rome},
  title    = {Tracciamento trasparente ed efficiente di scritture su memoria dinamica con granularità arbitraria in architetture per il calcolo ottimistico},
  year     = {2008},
  type     = {bathesis},
  abstract = {In questo lavoro presento l’ideazione, il progetto e l’implementazione in linguaggio C ed Assembly di un sistema di tracciamento di accessi su memoria dinamica in architetture per il calcolo ottimistico. Questo progetto si pone l’obiettivo di sviluppare una metodologia per l’identificazione a run-time di quali aree di memoria siano soggette ad operazioni di scrittura con granularità e dimensione arbitraria, in maniera disgiunta da qualsiasi libreria. In questo modo è possibile operare anche in contesti di memoria allocata dinamicamente, tramite librerie standard (quali malloc). Scopo parallelo del progetto è quello di realizzare un'implementazione di questa metodologia, che permetta un'esecuzione del software applicativo soggetta ad un overhead minimo rispetto a quello che normalmente avrebbe.},
  comment  = {Supervisor: F. Quaglia},
}

@PhdThesis{tRoma07,
  author   = {Romano, Paolo},
  school   = {Sapienza, University of Rome},
  title    = {Protocols for End-To-End Reliability in Multi-Tier Systems},
  year     = {2007},
  type     = {phdthesis},
  abstract = {Modern Internet services exhibit the strong trend to be structured according to a three-tier, and in general multi-tier, system organization, which allows reflecting at both the software and hardware level the logical decomposition of applications. Even though the partitioning of the application into multiple tiers provides the potentialities to achieve high modularity and flexibility, the multiplicity and diversity of the employed components, and their interdependencies, make reliability a complex issue to tackle. As an example, in classical client-server environments, database systems represented the reliability backbone of mission critical services, ensuring consistent evolution of the state trajectory of business applications through the notion of atomic transactions. However, the fault-tolerance capabilities provided by transactional components, and, in broader sense, by traditional approaches to reliability, address issues restricted to specific subsystems involved in the end-to-end interaction. Hence, they are unable to tackle the wide spectrum of failure scenarios that can arise along the whole chain of components constituting a multi-tier system.
The design of reliability solutions for Internet services is made even more challenging by the open, heterogeneous and inherently asynchronous nature of the Internet itself, which dramatically reduces the possibility to monitor and control the distributed components involved in a multi-tier application. Further, coupled with global access enabled by the Internet and with widespread diffusion of complex services, the urge for achieving high scalability and minimizing response times has accordingly grown. This has imposed stringent performance requirements on the underlying reliability mechanisms.
This is precisely the focus of this thesis. Specifically, we introduce innovative protocols ensuring the e-Transaction (exactly-once Transaction) guarantees, namely a recent formalization of desirable end-to-end reliability properties for multi-tier systems in presence of crash failures. These protocols advance the state of the art in a twofold direction. From a practical perspective, they achieve unparalleled scalability levels, exhibit very limited overhead, thus revealing particularly attractive in the context of emerging large scale service delivery platforms. From a theoretical standpoint, our solutions can cope with purely asynchronous systems, where no assumption on the accuracy of the failure detection mechanism can be guaranteed.
As we will show, some of the building blocks underlying the previous fault tolerant protocols can also be used to construct distributed protocols allowing the treatment of a more general class of failures, which we can refer to as “performance failures”. These model situations of reduced system responsiveness due to both crashes and overloads/congestions on some component.},
  comment  = {Supervisor: F. Quaglia},
}

@MastersThesis{tPalm06,
  author  = {Palmieri, Roberto},
  school  = {Sapienza, University of Rome},
  title   = {MicroOpGen tool and developing extensions for DisSimulator, a simulator for PD32 educational-processor},
  year    = {2006},
  type    = {bathesis},
  comment = {Supervisor: B. Ciciani},
}

@PhdThesis{tSant03,
  author  = {Santoro, Andrea},
  school  = {Sapienza, University of Rome},
  title   = {Semi-Asynchronous Checkpointing for Optimistic Parallel Simulation},
  year    = {2003},
  type    = {phdthesis},
  comment = {Supervisor: B. Ciciani},
}

@PhdThesis{tQuag99,
  author   = {Quaglia, Francesco},
  school   = {Sapienza, University of Rome},
  title    = {Consistent Checkpointing in Distributed Computations: Theoretical Results and Protocols},
  year     = {1999},
  type     = {phdthesis},
  abstract = {This thesis is focused on the study of consistent checkpointing in distributed computations. The model of the computation is asynchronous. The investigated checkpointing approach is known as communication-induced. In this approach, processes of the distributed computation take checkpoints at their own pace (namely basic checkpoints) and some additional checkpoints (namely forced checkpoints) are induced by a lazy coordination scheme, in order to guarantee consistency of global checkpoints. The lazy coordination is realized by piggybacking control information on application messages. Upon the receipt of a message, the recipient process evaluates a predicate basing on the incoming control information and on its local context; if the predicate is evaluated to TRUE, a forced checkpoint is taken. The thesis reports both theoretical results on this issue and protocols derived from those results.},
  comment  = {Supervisor: B. Ciciani},
}

@PhdThesis{tRome99,
  author  = {Romero, Milton},
  school  = {Sapienza, University of Rome},
  title   = {Disparity/Motion Estimation for Stereoscopic Video Processing},
  year    = {1999},
  type    = {phdthesis},
  comment = {Supervisor: B. Ciciani},
}

@PhdThesis{tBatt98,
  author  = {Battaglini, Gianluca},
  school  = {Sapienza, University of Rome},
  title   = {Analysis of Manufacturing Yields Evaluation of VLSI/WSI Systems: Methods and Methodologies},
  year    = {1998},
  type    = {phdthesis},
  comment = {Supervisor: B. Ciciani},
}

@MastersThesis{tQuag95,
  author  = {Quaglia, Francesco},
  school  = {Sapienza, University of Rome},
  title   = {Passo ottimo del salvataggio dello stato nel tool SIMCOR},
  year    = {1995},
  type    = {mathesis},
  comment = {Supervisor: B. Ciciani},
}
